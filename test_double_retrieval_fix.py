#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Test per verificare la correzione del doppio recupero parametri clustering

Autore: Valerio Bignardi
Data: 05/09/2025
Ultima modifica: 05/09/2025 - Valerio Bignardi
"""

import sys
import os
from datetime import datetime

def test_no_double_data_retrieval():
    """
    Test per verificare che il doppio recupero dati sia stato corretto.
    
    Verifica che:
    1. supervised_training NON carichi piÃ¹ i parametri clustering
    2. Solo get_all_clustering_parameters_for_tenant() carichi i parametri
    3. Non ci sia codice duplicato
    
    Scopo: Validare che la correzione del doppio recupero funzioni
    Input: Analisi del codice sorgente
    Output: Report di validazione
    
    Ultima modifica: 05/09/2025 - Valerio Bignardi
    """
    print("ğŸ§ª TEST CORREZIONE DOPPIO RECUPERO PARAMETRI")
    print("=" * 60)
    
    issues_found = []
    success = True
    
    # Test 1: Verifica che supervised_training non carichi piÃ¹ clustering params
    print("ğŸ” TEST 1: Analisi supervised_training endpoint")
    
    try:
        server_path = "/home/ubuntu/classificatore/server.py"
        with open(server_path, 'r', encoding='utf-8') as f:
            server_content = f.read()
        
        # Cerca la funzione supervised_training
        lines = server_content.split('\n')
        in_supervised_function = False
        clustering_params_assignments = []
        
        for i, line in enumerate(lines):
            if 'def supervised_training(' in line:
                in_supervised_function = True
                start_line = i
                continue
            
            if in_supervised_function:
                # Fine della funzione (prossima def o fine file)
                if line.strip().startswith('def ') and 'supervised_training' not in line:
                    break
                
                # Cerca assegnazioni a clustering_params
                if 'clustering_params = {' in line:
                    clustering_params_assignments.append(i + 1)  # Line numbers start from 1
        
        if clustering_params_assignments:
            issues_found.append(f"TROVATE {len(clustering_params_assignments)} assegnazioni clustering_params in supervised_training alle righe: {clustering_params_assignments}")
            success = False
            print(f"   âŒ ERRORE: Trovate assegnazioni clustering_params alle righe: {clustering_params_assignments}")
        else:
            print(f"   âœ… supervised_training NON carica piÃ¹ clustering_params")
            
    except Exception as e:
        issues_found.append(f"Errore lettura server.py: {e}")
        success = False
        print(f"   âŒ Errore lettura server.py: {e}")
    
    # Test 2: Verifica che get_all_clustering_parameters_for_tenant esista
    print("\nğŸ” TEST 2: Verifica funzione centralizzata")
    
    try:
        tenant_config_path = "/home/ubuntu/classificatore/Utils/tenant_config_helper.py"
        with open(tenant_config_path, 'r', encoding='utf-8') as f:
            tenant_content = f.read()
        
        if 'def get_all_clustering_parameters_for_tenant(' in tenant_content:
            print(f"   âœ… get_all_clustering_parameters_for_tenant() trovata")
        else:
            issues_found.append("get_all_clustering_parameters_for_tenant() NON trovata")
            success = False
            print(f"   âŒ get_all_clustering_parameters_for_tenant() NON trovata")
            
    except Exception as e:
        issues_found.append(f"Errore lettura tenant_config_helper.py: {e}")
        success = False
        print(f"   âŒ Errore lettura tenant_config_helper.py: {e}")
    
    # Test 3: Verifica che pipeline usi get_all_clustering_parameters_for_tenant
    print("\nğŸ” TEST 3: Verifica uso nella pipeline")
    
    try:
        pipeline_path = "/home/ubuntu/classificatore/Pipeline/end_to_end_pipeline.py"
        with open(pipeline_path, 'r', encoding='utf-8') as f:
            pipeline_content = f.read()
        
        if 'get_all_clustering_parameters_for_tenant(' in pipeline_content:
            print(f"   âœ… Pipeline usa get_all_clustering_parameters_for_tenant()")
        else:
            issues_found.append("Pipeline NON usa get_all_clustering_parameters_for_tenant()")
            success = False
            print(f"   âŒ Pipeline NON usa get_all_clustering_parameters_for_tenant()")
            
    except Exception as e:
        issues_found.append(f"Errore lettura end_to_end_pipeline.py: {e}")
        success = False
        print(f"   âŒ Errore lettura pipeline: {e}")
    
    # Test 4: Cerca query SQL duplicate
    print("\nğŸ” TEST 4: Ricerca query SQL duplicate")
    
    try:
        sql_patterns = [
            "SELECT * FROM soglie WHERE tenant_id",
            "SELECT.*FROM soglie.*WHERE tenant_id"
        ]
        
        files_to_check = [
            "/home/ubuntu/classificatore/server.py",
            "/home/ubuntu/classificatore/Utils/tenant_config_helper.py"
        ]
        
        sql_occurrences = {}
        
        for file_path in files_to_check:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                for pattern in sql_patterns:
                    count = content.count("SELECT") + content.count("FROM soglie")
                    if count > 0:
                        sql_occurrences[os.path.basename(file_path)] = count
                        
            except Exception as e:
                print(f"   âš ï¸ Errore lettura {file_path}: {e}")
        
        print(f"   ğŸ“Š Query SQL trovate per file:")
        for file, count in sql_occurrences.items():
            print(f"      {file}: query patterns trovati")
            
        # Questo Ã¨ normale - tenant_config_helper dovrebbe avere le query
        print(f"   âœ… Query SQL centralizzate in tenant_config_helper.py")
            
    except Exception as e:
        print(f"   âš ï¸ Errore analisi query SQL: {e}")
    
    # Test 5: Verifica rimozione variabili clustering_params
    print("\nğŸ” TEST 5: Verifica rimozione variabili clustering_params in supervised_training")
    
    try:
        with open(server_path, 'r', encoding='utf-8') as f:
            server_content = f.read()
        
        # Cerca riferimenti a clustering_params nella funzione supervised_training
        lines = server_content.split('\n')
        in_supervised_function = False
        clustering_params_references = []
        
        for i, line in enumerate(lines):
            if 'def supervised_training(' in line:
                in_supervised_function = True
                continue
            
            if in_supervised_function:
                if line.strip().startswith('def ') and 'supervised_training' not in line:
                    break
                
                if 'clustering_params' in line and 'RIMOSSO' not in line and 'NOTE' not in line:
                    clustering_params_references.append(i + 1)
        
        if clustering_params_references:
            issues_found.append(f"Trovati riferimenti clustering_params in supervised_training alle righe: {clustering_params_references}")
            success = False
            print(f"   âŒ Trovati riferimenti clustering_params alle righe: {clustering_params_references}")
        else:
            print(f"   âœ… Tutti i riferimenti clustering_params rimossi da supervised_training")
            
    except Exception as e:
        print(f"   âŒ Errore analisi clustering_params: {e}")
    
    # Report finale
    print("\nğŸ“‹ REPORT FINALE CORREZIONE")
    print("-" * 50)
    
    if success:
        print("ğŸ‰ CORREZIONE DOPPIO RECUPERO COMPLETATA CON SUCCESSO!")
        print("   âœ… supervised_training NON carica piÃ¹ parametri clustering")
        print("   âœ… Pipeline usa fonte centralizzata get_all_clustering_parameters_for_tenant()")
        print("   âœ… Eliminato codice duplicato")
        print("   âœ… Un'unica connessione DB per parametri clustering")
        print("\nğŸ’¡ BENEFICI:")
        print("   â€¢ Performance migliorate (una sola query DB)")
        print("   â€¢ Coerenza garantita (fonte unica)")
        print("   â€¢ ManutenibilitÃ  migliorata (logica centralizzata)")
        print("   â€¢ Riduzione rischio inconsistenze")
    else:
        print("âš ï¸ CORREZIONE DOPPIO RECUPERO INCOMPLETA")
        print("ğŸ“‹ Problemi trovati:")
        for issue in issues_found:
            print(f"   â€¢ {issue}")
        print("\nğŸ’¡ AZIONI RICHIESTE:")
        print("   â€¢ Risolvere i problemi sopra elencati")
        print("   â€¢ Verificare che tutti i riferimenti siano stati rimossi")
    
    return success

def test_clustering_params_flow():
    """
    Test per tracciare il flusso corretto dei parametri clustering
    
    Scopo: Documentare il flusso corretto post-correzione
    
    Ultima modifica: 05/09/2025 - Valerio Bignardi
    """
    print("\nğŸ”„ FLUSSO CORRETTO PARAMETRI CLUSTERING")
    print("=" * 60)
    
    print("ğŸ“‹ FLUSSO POST-CORREZIONE:")
    print("   1. ğŸŒ Frontend: Modifica parametri clustering")
    print("   2. ğŸ’¾ API: Salva in database MySQL soglie table")  
    print("   3. ğŸš€ supervised_training: Carica SOLO soglie review queue")
    print("   4. ğŸ­ Pipeline: Chiama get_all_clustering_parameters_for_tenant()")
    print("   5. ğŸ“Š tenant_config_helper: Legge TUTTI i parametri da DB")
    print("   6. ğŸ§© Clustering: Usa parametri unificati")
    
    print("\nâœ… VANTAGGI DEL NUOVO FLUSSO:")
    print("   â€¢ Una sola fonte di veritÃ  per parametri clustering")
    print("   â€¢ Eliminata duplicazione query database")
    print("   â€¢ Coerenza garantita tra componenti")
    print("   â€¢ Performance migliorate")
    print("   â€¢ ManutenibilitÃ  semplificata")
    
    print("\nğŸ¯ RESPONSABILITÃ€:")
    print("   â€¢ supervised_training: Solo soglie review queue")
    print("   â€¢ get_all_clustering_parameters_for_tenant(): Tutti i parametri clustering")
    print("   â€¢ Pipeline: Uso parametri centralizzati")
    
    return True

if __name__ == "__main__":
    print("ğŸ§ª SUITE TEST CORREZIONE DOPPIO RECUPERO")
    print("=" * 60)
    print(f"â° Avvio test: {datetime.now().isoformat()}")
    print()
    
    # Esegui test
    test1_result = test_no_double_data_retrieval()
    test2_result = test_clustering_params_flow()
    
    # Report finale
    print("\n" + "=" * 60)
    print("ğŸ“Š RISULTATI FINALI")
    print("=" * 60)
    print(f"   ğŸ”§ Test Correzione Doppio Recupero: {'âœ… PASS' if test1_result else 'âŒ FAIL'}")
    print(f"   ğŸ“‹ Test Flusso Parametri: {'âœ… PASS' if test2_result else 'âŒ FAIL'}")
    
    overall_success = test1_result and test2_result
    print(f"\nğŸ¯ RISULTATO COMPLESSIVO: {'âœ… SUCCESSO' if overall_success else 'âŒ FALLIMENTO'}")
    
    if overall_success:
        print("\nğŸ‰ La correzione del doppio recupero Ã¨ COMPLETA e FUNZIONANTE!")
        print("   â€¢ Codice duplicato eliminato")
        print("   â€¢ Fonte unica centralizzata attiva")
        print("   â€¢ Performance e coerenza migliorate")
    else:
        print("\nâš ï¸ La correzione richiede ancora alcuni aggiustamenti.")
    
    print(f"\nâ° Test completati: {datetime.now().isoformat()}")
