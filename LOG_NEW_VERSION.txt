ğŸš€ UMAP disponibile per riduzione dimensionale!
ğŸš€ cuML GPU clustering disponibile!
ğŸ’¥ EmbeddingDestroyer inizializzato - Ready to destroy and rebuild!
ğŸ¯ SimpleEmbeddingManager inizializzato
ğŸ›ï¸ Configurazioni AI saranno salvate su DATABASE MySQL
ğŸ›ï¸ AIConfigurationService inizializzato
   ï¿½ Backend: DATABASE MySQL
   ğŸ”‘ OpenAI API Key: âœ… Configurata
ğŸ­ EmbeddingEngineFactory inizializzata
ğŸ¯ EmbeddingManager inizializzato
âœ… Blueprint esempi inizializzato correttamente
ğŸš€ Avvio server Flask - Debug: True
 * Serving Flask app 'server'
 * Debug mode: on
ğŸ” [DEBUG] GET /api/tenants - Avvio richiesta tenant
ğŸ” [DEBUG] Inizializzo MongoClassificationReader...
ğŸ” [DEBUG] Chiamo get_available_tenants()...
Recuperati 22 tenant dalla tabella TAG.tenants
ğŸ” [DEBUG] Recuperati 22 tenant dal database
ğŸ” [DEBUG] Primi 3 tenant: [{'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'nome': 'Alleanza'}, {'tenant_id': '6bc4f06f-742e-11f0-acb8-96000228e7fe', 'nome': 'BluPantheon'}, {'tenant_id': '0f9d6e90-d319-11ef-86a5-96000228e7fe', 'nome': 'Boots'}]
ğŸ” [DEBUG] Invio risposta con 22 tenant
ğŸ”§ Creazione MongoClassificationReader per cliente: humanitas
âœ… MongoClassificationReader humanitas creato con collection: humanitas_015007d9-d413-11ef-86a5-96000228e7fe
âœ… Connesso a MongoDB database: classificazioni
ğŸ” Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
ğŸ” [DEBUG] GET /api/tenants - Avvio richiesta tenant
ğŸ” [DEBUG] Inizializzo MongoClassificationReader...
ğŸ” [DEBUG] Chiamo get_available_tenants()...
Recuperati 22 tenant dalla tabella TAG.tenants
ğŸ” [DEBUG] Recuperati 22 tenant dal database
ğŸ” [DEBUG] Primi 3 tenant: [{'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'nome': 'Alleanza'}, {'tenant_id': '6bc4f06f-742e-11f0-acb8-96000228e7fe', 'nome': 'BluPantheon'}, {'tenant_id': '0f9d6e90-d319-11ef-86a5-96000228e7fe', 'nome': 'Boots'}]
ğŸ” [DEBUG] Invio risposta con 22 tenant
ğŸ” [DEBUG] GET /api/prompts/a0fd7600-f4f7-11ef-9315-96000228e7fe/status - Avvio richiesta
ğŸ” [DEBUG] API: Recupero status prompt per tenant: a0fd7600-f4f7-11ef-9315-96000228e7fe
âœ… [DEBUG] Riconosciuto come tenant_id UUID: a0fd7600-f4f7-11ef-9315-96000228e7fe
ğŸ” [DEBUG] Inizializzo PromptManager...
ğŸ” [DEBUG] Chiamo get_all_prompts_for_tenant(a0fd7600-f4f7-11ef-9315-96000228e7fe)...
ğŸ” [DEBUG] Recuperati 5 prompt dal PromptManager
ğŸ” [DEBUG] Statistiche: 5/5 attivi, 0 inattivi
âœ… [DEBUG] Status calcolato: {'success': True, 'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'tenant_name': 'Alleanza', 'total_prompts': 5, 'active_prompts': 5, 'inactive_prompts': 0, 'last_updated': '2025-08-25T08:54:43', 'status': 'ready', 'canOperate': True, 'requiredPrompts': [{'name': 'System Prompt', 'type': 'system', 'description': 'Prompt di sistema per la classificazione', 'exists': True}, {'name': 'User Template', 'type': 'user', 'description': 'Template per prompt utente', 'exists': True}, {'name': 'Classification Prompt', 'type': 'classification', 'description': 'Prompt per classificazione intelligente', 'exists': False}], 'missingCount': 1}
âœ… [DEBUG] Status prompt per tenant_id a0fd7600-f4f7-11ef-9315-96000228e7fe: 5/5 attivi
ğŸ” [DEBUG] Invio risposta JSON per status prompt
ğŸ” [DEBUG] GET /api/prompts/a0fd7600-f4f7-11ef-9315-96000228e7fe/status - Avvio richiesta
ğŸ” [DEBUG] API: Recupero status prompt per tenant: a0fd7600-f4f7-11ef-9315-96000228e7fe
âœ… [DEBUG] Riconosciuto come tenant_id UUID: a0fd7600-f4f7-11ef-9315-96000228e7fe
ğŸ” [DEBUG] Inizializzo PromptManager...
ğŸ” [DEBUG] Chiamo get_all_prompts_for_tenant(a0fd7600-f4f7-11ef-9315-96000228e7fe)...
ğŸ” [DEBUG] Recuperati 5 prompt dal PromptManager
ğŸ” [DEBUG] Statistiche: 5/5 attivi, 0 inattivi
âœ… [DEBUG] Status calcolato: {'success': True, 'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'tenant_name': 'Alleanza', 'total_prompts': 5, 'active_prompts': 5, 'inactive_prompts': 0, 'last_updated': '2025-08-25T08:54:43', 'status': 'ready', 'canOperate': True, 'requiredPrompts': [{'name': 'System Prompt', 'type': 'system', 'description': 'Prompt di sistema per la classificazione', 'exists': True}, {'name': 'User Template', 'type': 'user', 'description': 'Template per prompt utente', 'exists': True}, {'name': 'Classification Prompt', 'type': 'classification', 'description': 'Prompt per classificazione intelligente', 'exists': False}], 'missingCount': 1}
âœ… [DEBUG] Status prompt per tenant_id a0fd7600-f4f7-11ef-9315-96000228e7fe: 5/5 attivi
ğŸ” [DEBUG] Invio risposta JSON per status prompt
ğŸ”§ Creazione MongoClassificationReader per cliente: humanitas
ğŸ” [DEBUG] GET /api/prompts/015007d9-d413-11ef-86a5-96000228e7fe/status - Avvio richiesta
ğŸ” [DEBUG] API: Recupero status prompt per tenant: 015007d9-d413-11ef-86a5-96000228e7fe
âœ… [DEBUG] Riconosciuto come tenant_id UUID: 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ” [DEBUG] Inizializzo PromptManager...
ğŸ” [DEBUG] Chiamo get_all_prompts_for_tenant(015007d9-d413-11ef-86a5-96000228e7fe)...
ğŸ” [DEBUG] Recuperati 5 prompt dal PromptManager
ğŸ” [DEBUG] Statistiche: 5/5 attivi, 0 inattivi
âœ… [DEBUG] Status calcolato: {'success': True, 'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'total_prompts': 5, 'active_prompts': 5, 'inactive_prompts': 0, 'last_updated': '2025-08-26T15:04:08', 'status': 'ready', 'canOperate': True, 'requiredPrompts': [{'name': 'System Prompt', 'type': 'system', 'description': 'Prompt di sistema per la classificazione', 'exists': True}, {'name': 'User Template', 'type': 'user', 'description': 'Template per prompt utente', 'exists': True}, {'name': 'Classification Prompt', 'type': 'classification', 'description': 'Prompt per classificazione intelligente', 'exists': False}], 'missingCount': 1}
âœ… [DEBUG] Status prompt per tenant_id 015007d9-d413-11ef-86a5-96000228e7fe: 5/5 attivi
ğŸ” [DEBUG] Invio risposta JSON per status prompt
âœ… MongoClassificationReader humanitas creato con collection: humanitas_015007d9-d413-11ef-86a5-96000228e7fe
âœ… Connesso a MongoDB database: classificazioni
ğŸ” Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
ğŸ¯ TRAINING SUPERVISIONATO - Cliente: humanitas
ğŸ“‹ Parametri utente semplificati:
  ï¿½ Max sessioni review: 500
  ğŸ¯ Soglia confidenza: 0.9
  ğŸ”„ Forza review: False
  âš–ï¸  Soglia disagreement: 0.3
ğŸ”§ Inizializzazione pipeline per cliente: humanitas (con lock)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
âœ… Tenant risolto da slug (DB TAG locale): Humanitas (humanitas) UUID=015007d9-d413-11ef-86a5-96000228e7fe
âœ… [CONFIG] Configurazione base caricata da /home/ubuntu/classificatore/Utils/../config.yaml
ğŸ¯ [PIPELINE CLUSTERING CONFIG] Caricati parametri personalizzati per tenant 015007d9-d413-11ef-86a5-96000228e7fe:
   allow_single_cluster: non_definito -> False
   alpha: non_definito -> 0.7
   cluster_selection_epsilon: non_definito -> 0.13
   cluster_selection_method: non_definito -> leaf
   max_cluster_size: non_definito -> 0
   metric: non_definito -> euclidean
   min_cluster_size: 5 -> 21
   min_samples: 3 -> 14
   only_user: non_definito -> False
   umap_metric: non_definito -> cosine
   umap_min_dist: non_definito -> 0.05
   umap_n_components: non_definito -> 100
   umap_n_neighbors: non_definito -> 15
   umap_random_state: non_definito -> 42
   use_umap: non_definito -> True

ğŸš€ [FASE 1: INIZIALIZZAZIONE] Avvio pipeline...
ğŸ¥ [FASE 1: INIZIALIZZAZIONE] Tenant: humanitas
ğŸ¯ [FASE 1: INIZIALIZZAZIONE] Configurazione:
   ğŸ“Š Confidence threshold: 0.7
   ğŸ¤– Auto mode: True
   ğŸ”„ Auto retrain: False
ï¿½ [FASE 1: INIZIALIZZAZIONE] Inizializzazione lettore conversazioni...
ğŸ“– [LETTORE] Schema common: only_user = False (legacy - no tenant_id)
ï¿½ [FASE 1: INIZIALIZZAZIONE] Inizializzazione aggregator...
   ğŸ” Schema: 'humanitas'
   ğŸ†” Tenant ID: '015007d9-d413-11ef-86a5-96000228e7fe'
âœ… [CONFIG] Configurazione base caricata da /home/ubuntu/classificatore/Utils/../config.yaml
âœ… [CONFIG] Config personalizzata tenant 015007d9-d413-11ef-86a5-96000228e7fe: 15 parametri
ğŸ¯ [ONLY_USER] Tenant 015007d9-d413-11ef-86a5-96000228e7fe: False (da config personalizzata)
ğŸ¯ [LETTORE] Tenant 015007d9-d413-11ef-86a5-96000228e7fe: only_user = False (da config tenant)
ğŸ¯ [ONLY_USER] Tenant 015007d9-d413-11ef-86a5-96000228e7fe: False (da config personalizzata)
ğŸ¯ [ONLY_USER] Tenant 015007d9-d413-11ef-86a5-96000228e7fe: False (da config tenant)
ğŸ§  [FASE 1: INIZIALIZZAZIONE] Sistema embedder dinamico (lazy loading)
ğŸ”§ [FASE 1: INIZIALIZZAZIONE] Parametri clustering:
   ğŸ“Š Min cluster size: 21
   ğŸ“Š Min samples: 14
âœ… [CONFIG] Config personalizzata tenant 015007d9-d413-11ef-86a5-96000228e7fe: 15 parametri
ğŸ—‚ï¸  [UMAP] Parametri per tenant 015007d9-d413-11ef-86a5-96000228e7fe:
   use_umap: True
   n_neighbors: 15
   min_dist: 0.05
   n_components: 100
   metric: cosine
ğŸ”§ [FIX DEBUG] Parametri tenant passati a HDBSCANClusterer:
   min_cluster_size: 21
   min_samples: 14
   alpha: 0.7
   cluster_selection_method: leaf
   cluster_selection_epsilon: 0.13
   metric: euclidean
   allow_single_cluster: False
   max_cluster_size: 0
   ğŸ—‚ï¸  use_umap: True
   ğŸ—‚ï¸  umap_n_neighbors: 15
   ğŸ—‚ï¸  umap_min_dist: 0.05
   ğŸ—‚ï¸  umap_n_components: 100
ğŸ¯ [BERTOPIC] Parametri consistenti configurati:
   ğŸ“Š HDBSCAN: 10 parametri
   ğŸ“Š UMAP: 5 parametri
ğŸ”§ HDBSCANClusterer inizializzato:
   min_cluster_size: 21
   min_samples: 14
   metric: euclidean
   cluster_selection_epsilon: 0.13
   ğŸ—‚ï¸  UMAP enabled: True
     ğŸ“ n_neighbors: 15
     ğŸ“ min_dist: 0.05
     ğŸ“Š n_components: 100
     ğŸ¯ metric: cosine
   ğŸš€ GPU enabled: True
   ğŸ’¾ GPU memory limit: 80%
   ğŸ”„ CPU fallback: True
   âš ï¸  [GPU MODE] Limitazioni cuML HDBSCAN:
     ğŸš« leaf_size=40 sarÃ  IGNORATO su GPU
     âœ… Parametri supportati: cluster_selection_method, alpha, allow_single_cluster
ğŸ¯ [DEBUG REACT] Parametri configurati:
   cluster_selection_method: leaf
   alpha: 0.7
   allow_single_cluster: False
ğŸ§  Inizializzazione memoria semantica...
ğŸ”§ TokenizationManager inizializzato:
   ğŸ“Š Modello tokenizer: cl100k_base
   ğŸ”¢ Limite massimo token: 8000
   âœ‚ï¸  Strategia troncamento: start
âœ… TokenizationManager integrato in LaBSE per gestione conversazioni lunghe
ğŸš€ Inizializzazione LaBSE embedder su device: cuda
ğŸ“¥ Caricamento modello sentence-transformers/LaBSE...
ğŸš€ Caricamento diretto su GPU...
âœ… Modello caricato con successo!
ğŸ“Š Dimensione embedding: 768
ğŸ”§ Device: cuda
ğŸ® GPU: NVIDIA A10G
ğŸ’¾ GPU Memory: 23.7 GB
ğŸ“ˆ GPU Memory utilizzata: 1.89 GB
ï¿½ Primo parametro su device: cuda:0
ğŸ§ª Test del modello LaBSE...
ğŸ” Encoding 3 testi con LaBSE su device cuda...

ğŸ” TOKENIZZAZIONE PREVENTIVA LABSE CLUSTERING
============================================================
ğŸ” ELABORAZIONE CONVERSAZIONI PER CLUSTERING
   ğŸ“Š Numero conversazioni: 3
   ğŸ†” Session IDs forniti: No

ğŸ“Š STATISTICHE ELABORAZIONE:
   ğŸ”¢ Conversazioni totali: 3
   âœ‚ï¸  Conversazioni troncate: 0
   ğŸ“ Token originali totali: 20
   ğŸ“ Token finali totali: 20
   ğŸ“Š Range token: 6 - 7
âœ… Tokenizzazione LaBSE completata:
   ğŸ“Š Conversazioni processate: 3
   ğŸ“Š Conversazioni troncate: 0
   ğŸ“Š Token limite configurato: 8000
   âœ… Tutte le conversazioni entro i limiti, nessun troncamento
============================================================
âœ… Embedding generati: shape (3, 768)
âœ… Test modello completato con successo!
   Shape: (3, 768)
   Norme: [0.99999994 1.         1.        ]
   Device: cuda
ğŸ¯ Modello pronto per l'uso!
ğŸ§  SemanticMemoryManager inizializzato
  ğŸ¯ Soglia riutilizzo etichette: 0.8
  ğŸ” Soglia similaritÃ  semantica: 0.8
  ğŸ’¾ Cache path: semantic_cache/humanitas_015007d9_memory
ğŸ”— Inizializzazione ensemble classifier avanzato...
ğŸ” ML Ensemble Debugger inizializzato e ATTIVO
   ğŸ“ Debug file: ./debug_logs/ml_debug.log
ğŸ” ML Ensemble Debugger attivato
ğŸ”§ Tentativo di inizializzazione IntelligentClassifier tramite LLMFactory...
ğŸ§  GPU Memory prima di LLM: 1.8GB/22.1GB (free: 20.3GB)
âœ… Memoria GPU sufficiente, inizializzazione LLM tramite Factory...
ğŸ›ï¸ Configurazioni AI saranno salvate su DATABASE MySQL
ğŸ›ï¸ AIConfigurationService inizializzato
   ï¿½ Backend: DATABASE MySQL
   ğŸ”‘ OpenAI API Key: âœ… Configurata
ğŸ­ LLM Factory inizializzato con cache invalidation intelligente
ğŸ” LLM FACTORY DEBUG: Chiamata ai_config_service.get_tenant_configuration(humanitas) normale...
ğŸ”„ DatabaseAI: ModalitÃ  legacy - risolvo tenant_id humanitas
ğŸ” [DEBUG] Query eseguita per tenant_id: 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ” [DEBUG] Risultato database: {'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'tenant_slug': 'humanitas', 'embedding_engine': 'labse', 'llm_engine': 'mistral:7b', 'embedding_config': None, 'llm_config': None, 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 28, 16, 51, 54)}
ğŸ” [DEBUG AIConfig] db_config ricevuto: {'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'tenant_slug': 'humanitas', 'embedding_engine': 'labse', 'llm_engine': 'mistral:7b', 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 28, 16, 51, 54), 'embedding_config': {}, 'llm_config': {}}
ğŸ” [DEBUG AIConfig] llm_engine nel db_config: mistral:7b
ğŸ¯ LLM FACTORY DEBUG: Modello normale = 'mistral:7b'
ğŸ”§ Creazione LLM classifier mistral:7b per tenant humanitas
ğŸš€ LLM FACTORY DEBUG: Avvio creazione nuovo classifier modello 'mistral:7b'
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
âœ… Tenant risolto da slug (DB TAG locale): Humanitas (humanitas) UUID=015007d9-d413-11ef-86a5-96000228e7fe
ğŸ” LLM Debugger inizializzato e ATTIVO
   ğŸ“ Debug file: ./debug_logs/llm_debug.log
   ğŸ¨ Visual formatting: True
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa
ğŸ”§ TokenizationManager inizializzato:
   ğŸ“Š Modello tokenizer: cl100k_base
   ğŸ”¢ Limite massimo token: 8000
   âœ‚ï¸  Strategia troncamento: start
âœ… LLM FACTORY DEBUG: Nuovo classifier creato: mistral:7b
âœ… LLM Classifier mistral:7b (mistral:7b) creato e cached per tenant humanitas
ğŸ­ LLM classifier ottenuto tramite Factory per tenant humanitas
ğŸ¤– LLM classifier creato automaticamente nell'ensemble: mistral:7b
ğŸ’¡ Possibile fine-tuning per humanitas
ğŸ”— Advanced Ensemble Classifier inizializzato
   ğŸ§  LLM weight: 0.60
   ğŸ¤– ML weight: 0.40
   ğŸ¯ Confidence threshold: 0.7
   ğŸ”„ Adaptive weights: True
   ğŸ‘¤ Disaccordi gestiti da QualityGateEngine
âš ï¸ Nessun modello trovato per tenant 'humanitas' nella directory models/
â¸ï¸ Riaddestramento automatico disabilitato (modalitÃ  supervisione/API)
   ğŸ’¡ Per abilitare, usare auto_retrain=True nell'inizializzazione
âœ… Classificatore LLM disponibile nell'ensemble
ğŸ‘¤ Inizializzazione trainer interattivo...
ğŸ¯ SIMPLE MANAGER: Richiesta embedder per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ“¥ Primo embedder - creazione per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸš€ CREATING FRESH EMBEDDER per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ›ï¸ Configurazioni AI saranno salvate su DATABASE MySQL
ğŸ›ï¸ AIConfigurationService inizializzato
   ï¿½ Backend: DATABASE MySQL
   ğŸ”‘ OpenAI API Key: âœ… Configurata
ğŸ”„ DatabaseAI: ModalitÃ  legacy - risolvo tenant_id 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ”§ FORCE NO CACHE: Bypass cache per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ”¥ FORCE NO CACHE: Bypasso cache e leggo DIRETTAMENTE dal database per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ” [DEBUG] Query eseguita per tenant_id: 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ” [DEBUG] Risultato database: {'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'tenant_slug': 'humanitas', 'embedding_engine': 'labse', 'llm_engine': 'mistral:7b', 'embedding_config': None, 'llm_config': None, 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 28, 16, 51, 54)}
ğŸ” [DEBUG AIConfig] db_config ricevuto: {'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'tenant_slug': 'humanitas', 'embedding_engine': 'labse', 'llm_engine': 'mistral:7b', 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 28, 16, 51, 54), 'embedding_config': {}, 'llm_config': {}}
ğŸ” [DEBUG AIConfig] llm_engine nel db_config: mistral:7b
ğŸ” SIMPLE MANAGER: Engine da DB per 015007d9-d413-11ef-86a5-96000228e7fe = 'labse'
ğŸ¯ Engine configurato: labse
ğŸ”§ DIRECT CREATE: labse
ğŸ”§ TokenizationManager inizializzato:
   ğŸ“Š Modello tokenizer: cl100k_base
   ğŸ”¢ Limite massimo token: 8000
   âœ‚ï¸  Strategia troncamento: start
âœ… TokenizationManager integrato in LaBSE per gestione conversazioni lunghe
ğŸš€ Inizializzazione LaBSE embedder su device: cuda
ğŸ“¥ Caricamento modello sentence-transformers/LaBSE...
ğŸš€ Caricamento diretto su GPU...
âœ… Modello caricato con successo!
ğŸ“Š Dimensione embedding: 768
ğŸ”§ Device: cuda
ğŸ® GPU: NVIDIA A10G
ğŸ’¾ GPU Memory: 23.7 GB
ğŸ“ˆ GPU Memory utilizzata: 3.78 GB
ï¿½ Primo parametro su device: cuda:0
ğŸ§ª Test del modello LaBSE...
ğŸ” Encoding 3 testi con LaBSE su device cuda...

ğŸ” TOKENIZZAZIONE PREVENTIVA LABSE CLUSTERING
============================================================
ğŸ” ELABORAZIONE CONVERSAZIONI PER CLUSTERING
   ğŸ“Š Numero conversazioni: 3
   ğŸ†” Session IDs forniti: No

ğŸ“Š STATISTICHE ELABORAZIONE:
   ğŸ”¢ Conversazioni totali: 3
   âœ‚ï¸  Conversazioni troncate: 0
   ğŸ“ Token originali totali: 20
   ğŸ“ Token finali totali: 20
   ğŸ“Š Range token: 6 - 7
âœ… Tokenizzazione LaBSE completata:
   ğŸ“Š Conversazioni processate: 3
   ğŸ“Š Conversazioni troncate: 0
   ğŸ“Š Token limite configurato: 8000
   âœ… Tutte le conversazioni entro i limiti, nessun troncamento
============================================================
âœ… Embedding generati: shape (3, 768)
âœ… Test modello completato con successo!
   Shape: (3, 768)
   Norme: [0.99999994 1.         1.        ]
   Device: cuda
ğŸ¯ Modello pronto per l'uso!
âœ… FRESH EMBEDDER creato: LaBSEEmbedder per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ§  Inizializzazione dedupplicatore intelligente...
ğŸ’¾ [FASE 1: INIZIALIZZAZIONE] Caricamento memoria semantica...
ğŸ“¦ Memoria semantica caricata da cache (4089 sessioni)
   ğŸ“Š Campioni: 1797
   ğŸ·ï¸ Tag: 250
âœ… [FASE 1: INIZIALIZZAZIONE] Completata in 7.70s
ğŸ¯ [FASE 1: INIZIALIZZAZIONE] Pipeline pronta per l'uso!
âœ… Pipeline humanitas inizializzata
ğŸš€ TRAINING SUPERVISIONATO CON DATASET COMPLETO
  ğŸ“Š Estrazione: TUTTE le discussioni dal database
  ğŸ§© Clustering: Su tutto il dataset disponibile
  ğŸ‘¤ Review umana: Max 500 sessioni rappresentative
ğŸ¯ Confidence threshold aggiornato a: 0.9
ğŸ“ TRAINING SUPERVISIONATO AVANZATO
ï¿½ NUOVA LOGICA:
  ğŸ”„ Estrazione: TUTTE le discussioni dal database
  ğŸ§© Clustering: Su tutto il dataset completo
  ğŸ‘¤ Review umana: Massimo 500 sessioni rappresentative
--------------------------------------------------
ğŸ“Š FASE 1: ESTRAZIONE COMPLETA DATASET

ï¿½ [FASE 2: ESTRAZIONE] Avvio estrazione sessioni...
ğŸ¥ [FASE 2: ESTRAZIONE] Tenant: humanitas
ğŸ“… [FASE 2: ESTRAZIONE] Giorni indietro: 7
ğŸ”„ [FASE 2: ESTRAZIONE] ModalitÃ  COMPLETA attivata
ğŸ¯ [FASE 2: ESTRAZIONE] Ignorando limite - estrazione totale dataset
ï¿½ [FASE 2: ESTRAZIONE] ModalitÃ : COMPLETA
ï¿½ [FASE 2: ESTRAZIONE] Connessione database...
ğŸ“Š [DEBUG ONLY_USER] Estrazione sessioni aggregate dal schema 'humanitas'...
ğŸ¯ [DEBUG ONLY_USER] Parametro only_user = False (tenant_id: 015007d9-d413-11ef-86a5-96000228e7fe)
ğŸ“„ [DEBUG ONLY_USER] Estrazione completa (senza limite)
ğŸ“„ [DEBUG ONLY_USER] Filtraggio standard: messaggi USER e AGENT
ğŸ” [DEBUG ONLY_USER] Esecuzione query per leggere conversazioni dal schema 'humanitas'...
ğŸ¯ [DEBUG ONLY_USER] Parametro only_user = False
ğŸ“‹ [DEBUG ONLY_USER] Filtro applicato: WHERE csm.said_by IN ('USER', 'AGENT')
Connessione al database MySQL stabilita con successo
âœ… [DEBUG ONLY_USER] Query eseguita con successo!
ğŸ“Š [DEBUG ONLY_USER] Totale righe: 21129
ğŸ‘¤ [DEBUG ONLY_USER] Messaggi USER: 10546
ğŸ¤– [DEBUG ONLY_USER] Messaggi AGENT: 10583
âœ… [DEBUG ONLY_USER] Filtro funziona correttamente!
âœ… Trovate 21129 righe da aggregare
ğŸ”„ [DEBUG ONLY_USER] Inizio generazione testo completo per 4215 sessioni
ğŸ” [DEBUG ONLY_USER] Sessione 0008ef4f-c2f4-4f5e-933e-646574f3638c: 3 USER, 3 AGENT
ğŸ“ [DEBUG ONLY_USER] Sessione 0008ef4f-c2f4-4f5e-933e-646574f3638c testo finale:
   [UTENTE] tags: 2
   [ASSISTENTE] tags: 2
   Lunghezza testo: 554 caratteri
ğŸ” [DEBUG ONLY_USER] Sessione 000b61d7-4431-40d2-b83c-9abbb70c98be: 4 USER, 4 AGENT
ğŸ“ [DEBUG ONLY_USER] Sessione 000b61d7-4431-40d2-b83c-9abbb70c98be testo finale:
   [UTENTE] tags: 3
   [ASSISTENTE] tags: 3
   Lunghezza testo: 1133 caratteri
ğŸ” [DEBUG ONLY_USER] Sessione 00160700-ac7f-463d-8fa0-fe57f74a73e6: 4 USER, 4 AGENT
âœ… Aggregate 4215 sessioni uniche
ğŸ”„ Saltati 8430 messaggi di benvenuto (primi 2 per sessione)
ğŸ”„ Sessioni vuote (solo benvenuto): 887
ğŸ“¥ [FASE 2: ESTRAZIONE] Sessioni grezze: 4215
ğŸ” [FASE 2: ESTRAZIONE] Filtraggio sessioni...
ğŸ” Filtraggio sessioni vuote/irrilevanti...
âœ… Filtro completato:
  ğŸ“Š Sessioni originali: 4215
  âŒ Sessioni scartate: 887
  âœ… Sessioni valide: 3328
âœ… [FASE 2: ESTRAZIONE] Completata in 0.59s
ğŸ“Š [FASE 2: ESTRAZIONE] Dataset completo: 3328 sessioni
ğŸ—‘ï¸ [FASE 2: ESTRAZIONE] Filtrate: 887 sessioni vuote/irrilevanti
ğŸ¯ [FASE 2: ESTRAZIONE] Pronte per clustering completo
âœ… Dataset completo: 3328 sessioni totali

ğŸ“Š FASE 2: CLUSTERING COMPLETO

ğŸš€ [FASE 4: CLUSTERING] Avvio clustering intelligente...
ğŸ“Š [FASE 4: CLUSTERING] Dataset: 3328 sessioni
ğŸ¯ [FASE 4: CLUSTERING] ModalitÃ : INTELLIGENTE
ğŸ§  [FASE 4: CLUSTERING] Clustering incrementale (se possibile)...

ğŸš€ [FASE 3: EMBEDDINGS] Avvio generazione embeddings...
ï¿½ [FASE 3: EMBEDDINGS] Dataset: 3328 sessioni
ğŸ“Š [FASE 3: EMBEDDINGS] Caratteristiche testo:
   ğŸ“ Lunghezza media: 1011 caratteri
   ğŸ“ Lunghezza massima: 29104 caratteri
   ğŸ“ Lunghezza minima: 75 caratteri
ğŸ§  [FASE 3: EMBEDDINGS] Generazione embeddings...
ğŸ”„ LAZY LOADING: Caricamento embedder dinamico per tenant 'humanitas'
ğŸ¯ SimpleEmbeddingManager inizializzato
ğŸ”„ SIMPLE MANAGER: Normalizzato 'humanitas' -> '015007d9-d413-11ef-86a5-96000228e7fe'
ğŸ¯ SIMPLE MANAGER: Richiesta embedder per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ“¥ Primo embedder - creazione per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸš€ CREATING FRESH EMBEDDER per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ›ï¸ Configurazioni AI saranno salvate su DATABASE MySQL
ğŸ›ï¸ AIConfigurationService inizializzato
   ï¿½ Backend: DATABASE MySQL
   ğŸ”‘ OpenAI API Key: âœ… Configurata
ğŸ”„ DatabaseAI: ModalitÃ  legacy - risolvo tenant_id 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ”§ FORCE NO CACHE: Bypass cache per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ”¥ FORCE NO CACHE: Bypasso cache e leggo DIRETTAMENTE dal database per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ” [DEBUG] Query eseguita per tenant_id: 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ” [DEBUG] Risultato database: {'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'tenant_slug': 'humanitas', 'embedding_engine': 'labse', 'llm_engine': 'mistral:7b', 'embedding_config': None, 'llm_config': None, 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 28, 16, 51, 54)}
ğŸ” [DEBUG AIConfig] db_config ricevuto: {'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'tenant_slug': 'humanitas', 'embedding_engine': 'labse', 'llm_engine': 'mistral:7b', 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 28, 16, 51, 54), 'embedding_config': {}, 'llm_config': {}}
ğŸ” [DEBUG AIConfig] llm_engine nel db_config: mistral:7b
ğŸ” SIMPLE MANAGER: Engine da DB per 015007d9-d413-11ef-86a5-96000228e7fe = 'labse'
ğŸ¯ Engine configurato: labse
ğŸ”§ DIRECT CREATE: labse
ğŸ”§ TokenizationManager inizializzato:
   ğŸ“Š Modello tokenizer: cl100k_base
   ğŸ”¢ Limite massimo token: 8000
   âœ‚ï¸  Strategia troncamento: start
âœ… TokenizationManager integrato in LaBSE per gestione conversazioni lunghe
ğŸš€ Inizializzazione LaBSE embedder su device: cuda
ğŸ“¥ Caricamento modello sentence-transformers/LaBSE...
ğŸš€ Caricamento diretto su GPU...
âœ… Modello caricato con successo!
ğŸ“Š Dimensione embedding: 768
ğŸ”§ Device: cuda
ğŸ® GPU: NVIDIA A10G
ğŸ’¾ GPU Memory: 23.7 GB
ğŸ“ˆ GPU Memory utilizzata: 5.67 GB
ï¿½ Primo parametro su device: cuda:0
ğŸ§ª Test del modello LaBSE...
ğŸ” Encoding 3 testi con LaBSE su device cuda...

ğŸ” TOKENIZZAZIONE PREVENTIVA LABSE CLUSTERING
============================================================
ğŸ” ELABORAZIONE CONVERSAZIONI PER CLUSTERING
   ğŸ“Š Numero conversazioni: 3
   ğŸ†” Session IDs forniti: No

ğŸ“Š STATISTICHE ELABORAZIONE:
   ğŸ”¢ Conversazioni totali: 3
   âœ‚ï¸  Conversazioni troncate: 0
   ğŸ“ Token originali totali: 20
   ğŸ“ Token finali totali: 20
   ğŸ“Š Range token: 6 - 7
âœ… Tokenizzazione LaBSE completata:
   ğŸ“Š Conversazioni processate: 3
   ğŸ“Š Conversazioni troncate: 0
   ğŸ“Š Token limite configurato: 8000
   âœ… Tutte le conversazioni entro i limiti, nessun troncamento
============================================================
âœ… Embedding generati: shape (3, 768)
âœ… Test modello completato con successo!
   Shape: (3, 768)
   Norme: [0.99999994 1.         1.        ]
   Device: cuda
ğŸ¯ Modello pronto per l'uso!
âœ… FRESH EMBEDDER creato: LaBSEEmbedder per tenant 015007d9-d413-11ef-86a5-96000228e7fe
âœ… Embedder caricato per tenant UUID 'humanitas': LaBSEEmbedder
ğŸ” Encoding 3328 testi con LaBSE su device cuda...

ğŸ” TOKENIZZAZIONE PREVENTIVA LABSE CLUSTERING
============================================================
ğŸ” ELABORAZIONE CONVERSAZIONI PER CLUSTERING
   ğŸ“Š Numero conversazioni: 3328
   ğŸ†” Session IDs forniti: SÃ¬
âœ‚ï¸  TRONCAMENTO NECESSARIO:
   ğŸ“Š Token originali: 8588
   ğŸ¯ Target token: 8000
   âš¡ Strategia: start
   âœ… Token finali: 8000
   ğŸ“ Caratteri rimossi: 1927
   âœ‚ï¸  Conversazione 3fe6b43b-3d09-4ed4-9002-d8a1f2b64291: 8588 â†’ 8000 token
âœ‚ï¸  TRONCAMENTO NECESSARIO:
   ğŸ“Š Token originali: 8227
   ğŸ¯ Target token: 8000
   âš¡ Strategia: start
   âœ… Token finali: 8000
   ğŸ“ Caratteri rimossi: 710
   âœ‚ï¸  Conversazione dbd64c8d-dcd6-4b19-a8ab-7f3760898dfe: 8227 â†’ 8000 token

ğŸ“Š STATISTICHE ELABORAZIONE:
   ğŸ”¢ Conversazioni totali: 3328
   âœ‚ï¸  Conversazioni troncate: 2
   ğŸ“ Token originali totali: 1,011,590
   ğŸ“ Token finali totali: 1,010,775
   ğŸ“Š Range token: 26 - 8588
   ğŸ’¾ Riduzione totale: 0.1%
âœ… Tokenizzazione LaBSE completata:
   ğŸ“Š Conversazioni processate: 3328
   ğŸ“Š Conversazioni troncate: 2
   ğŸ“Š Token limite configurato: 8000
   âœ‚ï¸  2 conversazioni TRONCATE per rispettare limite token
============================================================
âœ… Embedding generati: shape (3328, 768)
âœ… [FASE 3: EMBEDDINGS] Completata in 8.44s
ğŸ“ˆ [FASE 3: EMBEDDINGS] Shape: (3328, 768)
âš¡ [FASE 3: EMBEDDINGS] Throughput: 394.5 testi/secondo

ğŸ“Š FASE 2A: TRAINING BERTOPIC ANTICIPATO

ğŸš€ TRAINING BERTOPIC ANTICIPATO (NUOVO FLUSSO OTTIMIZZATO):
   ğŸ“Š Dataset completo: 3328 sessioni
   ğŸ“Š Embeddings shape: (3328, 768)
   ğŸ¯ Addestramento su TUTTO il dataset per features ottimali
   ğŸ”¥ Esecuzione bertopic_provider.fit() su dataset completo...
ğŸ“Š BERTopic training su 3328 campioni
   ğŸ¯ Embedder configurato: LaBSEEmbedder
   ğŸ”§ STRATEGIA: BERTopic userÃ  embedder personalizzato via wrapper
   âœ… Wrapper embedder creato per BERTopic
   ğŸ”§ BERTopic userÃ  embedder personalizzato interno
ğŸ”§ Creazione MongoClassificationReader per cliente: humanitas
âœ… MongoClassificationReader humanitas creato con collection: humanitas_015007d9-d413-11ef-86a5-96000228e7fe
âœ… Connesso a MongoDB database: classificazioni
ğŸ” Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
âœ… BERTopic FIT completato su 3328 campioni
   ğŸ”§ SVD Training: Usando embedder personalizzato interno
âœ… SVD addestrato su full probas (k=20)
   âœ… BERTopic FIT completato in 39.75 secondi
   ğŸ”„ Esecuzione bertopic_provider.transform() per features extraction...
ğŸ”§ Transform: BERTopic userÃ  embedder personalizzato interno
   âœ… BERTopic TRANSFORM completato in 4.26 secondi
   ğŸ“Š Topic probabilities shape: (3328, 20)
   ğŸ“Š One-hot shape: None
   âœ… BERTopic provider addestrato con successo su 3328 sessioni
   âœ… BERTopic provider disponibile per augmentation features
   ğŸ”— BERTopic model assegnato al trainer per validazione ALTRO

ğŸ“Š FASE 2B: CLUSTERING HDBSCAN
ğŸ§  Usando clustering INTELLIGENTE (LLM + ML senza pattern)
ğŸ—‚ï¸  [DEBUG] Caricamento config tenant-specific: /home/ubuntu/classificatore/tenant_configs/015007d9-d413-11ef-86a5-96000228e7fe_clustering.yaml
ğŸ—‚ï¸  [DEBUG] Config tenant caricato: ['allow_single_cluster', 'alpha', 'cluster_selection_epsilon', 'cluster_selection_method', 'max_cluster_size', 'metric', 'min_cluster_size', 'min_samples', 'only_user', 'umap_metric', 'umap_min_dist', 'umap_n_components', 'umap_n_neighbors', 'umap_random_state', 'use_umap']
ğŸ—‚ï¸  [DEBUG] UMAP config finale: use_umap=True, n_components=100, min_dist=0.05
ğŸ§  Clustering intelligente configurato:
   ğŸ¯ Categorie intent suggerite: 12
   ğŸ¤– LLM primario: True
   ğŸ“Š Min confidence: 0.8
   ğŸ“ˆ Min conversations per intent: 2
   ğŸ‘¥ Rappresentanti diversificati: True
   ğŸ”¢ Max rappresentanti per cluster: 5
   ğŸ¤ Strategia consenso: majority
ğŸ§  Avvio clustering intelligente OTTIMIZZATO di 3328 conversazioni...
ğŸ“Š Fase 1: Clustering semantico con HDBSCAN...
ğŸ”§ HDBSCANClusterer inizializzato:
   min_cluster_size: 21
   min_samples: 14
   metric: euclidean
   cluster_selection_epsilon: 0.13
   ğŸ—‚ï¸  UMAP enabled: True
     ğŸ“ n_neighbors: 15
     ğŸ“ min_dist: 0.05
     ğŸ“Š n_components: 100
     ğŸ¯ metric: cosine
   ğŸš€ GPU enabled: True
   ğŸ’¾ GPU memory limit: 80%
   ğŸ”„ CPU fallback: True
   âš ï¸  [GPU MODE] Limitazioni cuML HDBSCAN:
     ğŸš« leaf_size=40 sarÃ  IGNORATO su GPU
     âœ… Parametri supportati: cluster_selection_method, alpha, allow_single_cluster
ğŸ¯ [DEBUG REACT] Parametri configurati:
   cluster_selection_method: eom
   alpha: 1.0
   allow_single_cluster: False
ğŸ” Clustering HDBSCAN su 3328 embedding (9.8MB)...
âš™ï¸  Parametri: min_cluster_size=21, min_samples=14, metric=euclidean
ğŸ“Š [DEBUG FIT_PREDICT] Embedding input:
   ğŸ“ Shape: (3328, 768)
   ğŸ”¢ Dtype: float32
   ğŸ“ˆ Range: [-0.1261, 0.0955]
   ğŸ’¾ Memory: 9.8MB

ğŸ—‚ï¸  [DEBUG FIT_PREDICT] STEP 1: Controllo applicazione UMAP...
ğŸ” [DEBUG UMAP] Controllo condizioni applicazione UMAP...
   âœ… self.use_umap = True
   âœ… UMAP_AVAILABLE = True
ï¿½ [DEBUG UMAP] UMAP ABILITATO - Iniziando riduzione dimensionale...
   ğŸ“ Dimensioni input: (3328, 768)
   ğŸ”¢ Tipo dati input: float32
   ğŸ“Š Range valori input: [-0.1261, 0.0955]
   ğŸ¯ Parametri UMAP configurati:
     ğŸ“ n_neighbors: 15
     ğŸ“ min_dist: 0.05
     ğŸ”¢ n_components: 100
     ğŸ“ˆ metric: cosine
     ğŸ² random_state: 42
ğŸ”§ [DEBUG UMAP] Inizializzazione riduttore UMAP...
ğŸ†• [DEBUG UMAP] ModalitÃ  TRAINING - fit nuovo reducer
âœ… [DEBUG UMAP] Riduttore UMAP inizializzato con successo
â³ [DEBUG UMAP] Applicazione fit_transform agli embeddings...
UMAP(angular_rp_forest=True, metric='cosine', min_dist=0.05, n_components=100, n_jobs=1, random_state=42, verbose=True)
Fri Aug 29 11:15:30 2025 Construct fuzzy simplicial set
Fri Aug 29 11:15:43 2025 Finding Nearest Neighbors
Fri Aug 29 11:15:44 2025 Finished Nearest Neighbor Search
Fri Aug 29 11:15:44 2025 Construct embedding
	completed  0  /  500 epochs
	completed  50  /  500 epochs
	completed  100  /  500 epochs
	completed  150  /  500 epochs
	completed  200  /  500 epochs
	completed  250  /  500 epochs
	completed  300  /  500 epochs
	completed  350  /  500 epochs
	completed  400  /  500 epochs
	completed  450  /  500 epochs
Fri Aug 29 11:15:55 2025 Finished embedding
âœ… [DEBUG UMAP] UMAP COMPLETATO con SUCCESSO in 24.99s
   ğŸ“ Dimensioni output: (3328, 100)
   ï¿½ Tipo dati output: float32
   ï¿½ğŸ“Š Range valori output: [-1.1767, 14.7635]
   ğŸ“ˆ Riduzione dimensionale: 768 â†’ 100 dimensioni
   ğŸ“‰ Fattore riduzione: 7.7x
âœ… [DEBUG UMAP] RIDUZIONE DIMENSIONALE CONFERMATA
âœ… [DEBUG UMAP] Nessun NaN nel risultato UMAP
âœ… [DEBUG UMAP] Nessun valore infinito nel risultato UMAP
ğŸ“Š [DEBUG UMAP] DiversitÃ  embeddings ridotti: 3328/3328 righe uniche
âœ… [DEBUG UMAP] Buona diversitÃ  negli embeddings ridotti
ğŸ“‹ [DEBUG UMAP] Info riduzione salvate nel clusterer
ğŸ“‹ [DEBUG FIT_PREDICT] Risultato UMAP:
   âœ… UMAP applicato: True
   ğŸ“ Shape post-UMAP: (3328, 100)
   ğŸ“ˆ Range post-UMAP: [-1.1767, 14.7635]
   â±ï¸  Tempo riduzione: 24.99s

ğŸ”§ [DEBUG FIT_PREDICT] STEP 2: Normalizzazione per metrica euclidean...
   ğŸ¯ Nessuna normalizzazione necessaria per metrica euclidean
   ğŸ“ Shape finale per clustering: (3328, 100)
   ğŸ“ˆ Range finale: [-1.1767, 14.7635]
   ğŸ¯ Metrica effettiva clustering: euclidean
ğŸ’¾ Memoria GPU: 17.7GB disponibili, 0.0GB necessari
ğŸš€ Utilizzo GPU per clustering accelerato

ğŸš€ [DEBUG FIT_PREDICT] STEP 3: Avvio clustering...
   ğŸ–¥ï¸  ModalitÃ : GPU
ï¿½ [GPU CLUSTERING] Inizializzazione cuML HDBSCAN con parametri supportati...

âœ… [DEBUG FIT_PREDICT] CLUSTERING COMPLETATO in 0.11s con ğŸš€ GPU!
ğŸ“Š Risultati finali:
   ğŸ¯ Cluster trovati: 37
   ğŸ” Outlier: 808 (24.3%)
   ğŸ“ˆ Silhouette score: 0.642

ğŸ“‹ [DEBUG FIT_PREDICT] RIEPILOGO TRASFORMAZIONI:
   ğŸ”¤ Input originale: (3328, 768)
   ğŸ—‚ï¸  Dopo UMAP: (3328, 100)
   ğŸ”§ Dopo normalizzazione: (3328, 100)
   ğŸ¯ Utilizzato per clustering: (3328, 100) con metrica euclidean
   ğŸ“ˆ Cluster HDBSCAN trovati: 37
   ğŸ” Outliers: 808
ğŸ‘¥ Fase 2: Selezione rappresentanti per cluster...
   ï¿½ Cluster 0: 38 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 1: 261 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 2: 61 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 3: 192 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 4: 57 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 5: 156 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 6: 37 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 7: 135 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 8: 50 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 9: 50 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 10: 35 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 11: 24 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 12: 24 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 13: 41 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 14: 29 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 15: 51 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 16: 93 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 17: 133 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 18: 40 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 19: 59 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 20: 26 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 21: 50 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 22: 96 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 23: 26 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 24: 24 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 25: 23 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 26: 65 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 27: 55 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 28: 105 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 29: 34 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 30: 74 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 31: 148 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 32: 74 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 33: 60 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 34: 29 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 35: 41 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 36: 24 sessioni, 4 rappresentanti selezionati
ğŸ¤– Fase 3: Analisi LLM di 166 rappresentanti...
ğŸ¤– Analisi LLM di 166 conversazioni...
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 212
   ğŸ“Š Token totali: 640
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 640 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 212
   ğŸ“Š Token conversazione finale: 212
   ğŸ“Š Token totali: 640
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 774 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2721 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:15:58.742806
====================================================================================================
ğŸ“‹ Session ID: classify_1756466158
â±ï¸  Processing Time: 3.136s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (774 chars):
   [UTENTE] PerchÃ¨ non riesco a visualizzare le prenotazioni di mia figlia minorenne [ASSISTENTE] Per visualizzare le prenotazioni di un minore su [Humanitas con te](https://www.humanitasconte.it), Ã¨ ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [75 more lines] ...
     Line 79: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (147 chars):
    {"predicted_label": "info_prenotazione", "confidence": 0.9, "motivation": "Domanda su come visualizzare le prenotazioni di una persona minorenne"}

ğŸ“Š Parsed Response:
   predicted_label: info_prenotazione
   confidence: 0.9
   motivation: Domanda su come visualizzare le prenotazioni di una persona minorenne
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come visualizzare le prenotazioni di una persona minorenne
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

âœ… Connesso a MongoDB database: classificazioni
ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 54679b5dd0fd90d7bd845dfdb6fd8c8f classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 180
   ğŸ“Š Token totali: 608
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 608 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 180
   ğŸ“Š Token conversazione finale: 180
   ğŸ“Š Token totali: 608
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 625 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2730 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:15:59.694278
====================================================================================================
ğŸ“‹ Session ID: classify_1756466159
â±ï¸  Processing Time: 0.820s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (625 chars):
   [UTENTE] delega per gestione profilo humanitas da parte di altri come fare? [ASSISTENTE] Per delegare un utente terzo (curatore, caregiver, amministratore di sostegno) alla gestione del proprio pro...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (136 chars):
    {"predicted_label": "delega_profilo", "confidence": 0.9, "motivation": "Domanda su come delegare il proprio profilo a un altro utente"}

ğŸ“Š Parsed Response:
   predicted_label: delega_profilo
   confidence: 0.9
   motivation: Domanda su come delegare il proprio profilo a un altro utente
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come delegare il proprio profilo a un altro utente
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 356f7524398d9a84694232d68e070bc9 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 153
   ğŸ“Š Token totali: 581
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 581 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 153
   ğŸ“Š Token conversazione finale: 153
   ğŸ“Š Token totali: 581
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 518 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2657 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:00.526202
====================================================================================================
ğŸ“‹ Session ID: classify_1756466160
â±ï¸  Processing Time: 0.725s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (518 chars):
   [UTENTE] Come faccio a creare un altro profilo in una in un Humanitas per te [ASSISTENTE] Per creare un altro profilo su [Humanitas con te](https://www.humanitasconte.it), ad esempio per gestire un...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (125 chars):
    {"predicted_label": "profilo_nuovo", "confidence": 0.8, "motivation": "L'utente vuole creare un nuovo profilo su Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: L'utente vuole creare un nuovo profilo su Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   L'utente vuole creare un nuovo profilo su Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione ad2830a64127191792d9a5fbe01019f8 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 121
   ğŸ“Š Token totali: 569
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 569 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 121
   ğŸ“Š Token conversazione finale: 121
   ğŸ“Š Token totali: 569
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 410 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2824 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:01.575414
====================================================================================================
ğŸ“‹ Session ID: classify_1756466161
â±ï¸  Processing Time: 0.943s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (410 chars):
   [UTENTE] Giulia, avrei bisogno della copia della cartella clinica di mia figlia minorenne  [ASSISTENTE] Per richiedere la copia della cartella clinica di un minore, Ã¨ necessario seguire una procedu...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (158 chars):
    {"predicted_label": "info_copia_cartella_clinica", "confidence": 0.9, "motivation": "Domanda su come ottenere una copia della cartella clinica di un minore"}

ğŸ“Š Parsed Response:
   predicted_label: info_copia_cartella_clinica
   confidence: 0.9
   motivation: Domanda su come ottenere una copia della cartella clinica di un minore
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come ottenere una copia della cartella clinica di un minore
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 42fd7c859924ae0579aed8559acba313 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 373
   ğŸ“Š Token totali: 822
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 822 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 373
   ğŸ“Š Token conversazione finale: 373
   ğŸ“Š Token totali: 822
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1108 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2768 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:02.611469
====================================================================================================
ğŸ“‹ Session ID: classify_1756466162
â±ï¸  Processing Time: 0.930s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1108 chars):
   [UTENTE] Voglio prenotare visita oncologica  [ASSISTENTE] Per prenotare una visita oncologica presso Humanitas, puoi utilizzare i seguenti canali di prenotazione:

1. **Privatamente con fondi e ass...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (147 chars):
    {"predicted_label": "prenotazione_oncologica", "confidence": 0.9, "motivation": "L'utente vuole prenotare una visita oncologica presso Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: prenotazione_oncologica
   confidence: 0.9
   motivation: L'utente vuole prenotare una visita oncologica presso Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente vuole prenotare una visita oncologica presso Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 9e013dae3e1d9f72e3e02eb54dca24dd classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 447
   ğŸ’¬ Token conversazione: 996
   ğŸ“Š Token totali: 1443
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 1443 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 447
   ğŸ“Š Token conversazione originale: 996
   ğŸ“Š Token conversazione finale: 996
   ğŸ“Š Token totali: 1443
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 3385 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2753 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:03.834397
====================================================================================================
ğŸ“‹ Session ID: classify_1756466163
â±ï¸  Processing Time: 1.117s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (3385 chars):
   [UTENTE] Buongiorno mi rivolgo ad Humanitas perchÃ© sto cercando professionalitÃ  riguardo la mia patologia. Pultroppo anni fa mi Ã¨ stata diagnosticata artrosi deformante degenerativa e fibromiofalgi...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (126 chars):
    {"predicted_label": "parere_clinico", "confidence": 0.9, "motivation": "Domanda riguardo la professionalitÃ  della patologia"}

ğŸ“Š Parsed Response:
   predicted_label: parere_clinico
   confidence: 0.9
   motivation: Domanda riguardo la professionalitÃ  della patologia
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda riguardo la professionalitÃ  della patologia
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 0f4d2db633adaf47a65228144aa5b737 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 591
   ğŸ“Š Token totali: 1040
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 1040 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 591
   ğŸ“Š Token conversazione finale: 591
   ğŸ“Š Token totali: 1040
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1862 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2692 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:04.639926
====================================================================================================
ğŸ“‹ Session ID: classify_1756466164
â±ï¸  Processing Time: 0.700s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1862 chars):
   [UTENTE] Ginecomastia [UTENTE] uomo [ASSISTENTE] Ciao! Sono Giulia, lâ€™assistente digitale dellâ€™Istituto Clinico Humanitas. Come posso aiutarti oggi? [ASSISTENTE] La ginecomastia Ã¨ una condizione ca...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (106 chars):
    {"predicted_label": "info_esame", "confidence": 0.8, "motivation": "Domanda riguardante un esame medico"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: Domanda riguardante un esame medico
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   Domanda riguardante un esame medico
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ”§ Creazione MongoClassificationReader per cliente: humanitas
ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 87f5d0fa875e620abc9a723a1b05d11c classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 547
   ğŸ“Š Token totali: 995
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 995 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 547
   ğŸ“Š Token conversazione finale: 547
   ğŸ“Š Token totali: 995
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1653 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2842 chars (debug_prompt=False)
âœ… MongoClassificationReader humanitas creato con collection: humanitas_015007d9-d413-11ef-86a5-96000228e7fe
âœ… Connesso a MongoDB database: classificazioni
ğŸ” Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:05.668256
====================================================================================================
ğŸ“‹ Session ID: classify_1756466165
â±ï¸  Processing Time: 0.907s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1653 chars):
   [UTENTE] Con l'ecoendoscopia Ã¨  possibile esplorare per intero l'ideologia o l'intestino tenue [ASSISTENTE] L'ecoendoscopia Ã¨ una tecnica diagnostica avanzata che consente di esplorare alcune parti...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (126 chars):
    {"predicted_label": "info_ecoendoscopia", "confidence": 0.9, "motivation": "L'utente chiede informazioni sull'ecoendoscopia"}

ğŸ“Š Parsed Response:
   predicted_label: info_ecoendoscopia
   confidence: 0.9
   motivation: L'utente chiede informazioni sull'ecoendoscopia
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni sull'ecoendoscopia
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione cf5040ec7c44aa569f78ee053b4e34cf classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 579
   ğŸ“Š Token totali: 1027
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 1027 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 579
   ğŸ“Š Token conversazione finale: 579
   ğŸ“Š Token totali: 1027
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1735 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2871 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:06.662288
====================================================================================================
ğŸ“‹ Session ID: classify_1756466166
â±ï¸  Processing Time: 0.889s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1735 chars):
   [UTENTE] Vorrei sapere si voi fatte le onde d'urto ecoguidate? [ASSISTENTE] SÃ¬, presso Humanitas vengono effettuati trattamenti con onde d'urto ecoguidate, utilizzando tecnologie avanzate per tratt...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (148 chars):
    {"predicted_label": "info_trattamento", "confidence": 0.9, "motivation": "L'utente chiede informazioni sui trattamenti con onde d'urto ecoguidate"}

ğŸ“Š Parsed Response:
   predicted_label: info_trattamento
   confidence: 0.9
   motivation: L'utente chiede informazioni sui trattamenti con onde d'urto ecoguidate
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni sui trattamenti con onde d'urto ecoguidate
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione cfe4c0e70f680367333ef411c14fdc88 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 447
   ğŸ’¬ Token conversazione: 4489
   ğŸ“Š Token totali: 4936
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 4936 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 447
   ğŸ“Š Token conversazione originale: 4489
   ğŸ“Š Token conversazione finale: 4489
   ğŸ“Š Token totali: 4936
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 15466 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2847 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:07.583649
====================================================================================================
ğŸ“‹ Session ID: classify_1756466167
â±ï¸  Processing Time: 0.816s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (15466 chars):
   [UTENTE] Ciao! Sono Pimpa â¤ï¸ [ASSISTENTE] Ciao Pimpa! Come posso esserti utile oggi? [UTENTE] Soffro di Anoressia  [ASSISTENTE] Come assistente digitale di Humanitas, il mio scopo Ã¨ fornire informa...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (124 chars):
    {"predicted_label": "info_condizioni_patologiche", "confidence": 0.9, "motivation": "Domanda su una condizione patologica"}

ğŸ“Š Parsed Response:
   predicted_label: info_condizioni_patologiche
   confidence: 0.9
   motivation: Domanda su una condizione patologica
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su una condizione patologica
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 3b98a6346aac3d5c644d1a0470dacc40 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 255
   ğŸ“Š Token totali: 683
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 683 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 255
   ğŸ“Š Token conversazione finale: 255
   ğŸ“Š Token totali: 683
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 847 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2757 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:08.560099
====================================================================================================
ğŸ“‹ Session ID: classify_1756466168
â±ï¸  Processing Time: 0.865s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (847 chars):
   [UTENTE] GIULIA TU CONOSCI IL PACCHETTO COLON IRRITABILE [ASSISTENTE] Il pacchetto relativo alla sindrome del colon irritabile (o intestino irritabile) non Ã¨ specificamente menzionato nei documenti...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (139 chars):
    {"predicted_label": "info_malattia", "confidence": 0.9, "motivation": "Domanda su un pacchetto di trattamento specifico per una malattia"}

ğŸ“Š Parsed Response:
   predicted_label: info_malattia
   confidence: 0.9
   motivation: Domanda su un pacchetto di trattamento specifico per una malattia
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su un pacchetto di trattamento specifico per una malattia
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 05a99d0eb701e800f07c457c68bf4256 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 447
   ğŸ’¬ Token conversazione: 115
   ğŸ“Š Token totali: 562
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 562 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 447
   ğŸ“Š Token conversazione originale: 115
   ğŸ“Š Token conversazione finale: 115
   ğŸ“Š Token totali: 562
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 385 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2772 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:09.418186
====================================================================================================
ğŸ“‹ Session ID: classify_1756466169
â±ï¸  Processing Time: 0.750s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (385 chars):
   [UTENTE] Ciao Giulia, cosa vuol dire ICE? [ASSISTENTE] "ICE" Ã¨ l'acronimo di "In Case of Emergency" (in caso di emergenza). Viene spesso utilizzato per indicare un contatto da chiamare in caso di e...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (98 chars):
    {"predicted_label": "info_ice", "confidence": 0.9, "motivation": "Domanda su cosa significa ICE"}

ğŸ“Š Parsed Response:
   predicted_label: info_ice
   confidence: 0.9
   motivation: Domanda su cosa significa ICE
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su cosa significa ICE
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione e7dd50ce94013f05a68b4b633a35b9ea classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 130
   ğŸ“Š Token totali: 578
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 578 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 130
   ğŸ“Š Token conversazione finale: 130
   ğŸ“Š Token totali: 578
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 433 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2873 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:10.345765
====================================================================================================
ğŸ“‹ Session ID: classify_1756466170
â±ï¸  Processing Time: 0.822s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (433 chars):
   [UTENTE] Informazioni vaccini  [ASSISTENTE] Puoi trovare informazioni dettagliate sui vaccini, inclusi i tipi disponibili, le modalitÃ  di somministrazione e le indicazioni, visitando la pagina dedi...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (115 chars):
    {"predicted_label": "info_vaccini", "confidence": 0.9, "motivation": "L'utente richiede informazioni sui vaccini"}

ğŸ“Š Parsed Response:
   predicted_label: info_vaccini
   confidence: 0.9
   motivation: L'utente richiede informazioni sui vaccini
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente richiede informazioni sui vaccini
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 4ada1f2c0e7a44d0984089980736800c classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 143
   ğŸ“Š Token totali: 591
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 591 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 143
   ğŸ“Š Token conversazione finale: 143
   ğŸ“Š Token totali: 591
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 465 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2792 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:11.344871
====================================================================================================
ğŸ“‹ Session ID: classify_1756466171
â±ï¸  Processing Time: 0.893s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (465 chars):
   [UTENTE] Morso gatto randagio, anti rabbia, vado al pronto soccorso? [ASSISTENTE] In caso di morso da un animale randagio, come un gatto, Ã¨ importante agire rapidamente. Ti consiglio di recarti al ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (161 chars):
    {"predicted_label": "info_morso", "confidence": 0.9, "motivation": "L'utente ha chiesto informazioni su come procedere in caso di morso da un animale randagio"}

ğŸ“Š Parsed Response:
   predicted_label: info_morso
   confidence: 0.9
   motivation: L'utente ha chiesto informazioni su come procedere in caso di morso da un animale randagio
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente ha chiesto informazioni su come procedere in caso di morso da un animale randagio
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 787e9493efcd884aa2f08434cc66fd90 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 287
   ğŸ“Š Token totali: 736
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 736 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 287
   ğŸ“Š Token conversazione finale: 287
   ğŸ“Š Token totali: 736
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1020 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2865 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:12.259270
====================================================================================================
ğŸ“‹ Session ID: classify_1756466172
â±ï¸  Processing Time: 0.809s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1020 chars):
   [UTENTE] Non riesco a vedere gli esami online  [ASSISTENTE] Potresti dirmi che tipo di esame stai cercando di visualizzare online? Alcuni esami non sono consultabili online e devono essere ritirati...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (147 chars):
    {"predicted_label": "problema_visualizzazione_esami", "confidence": 0.8, "motivation": "Problema di visualizzazione degli esami online richiesto"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: Problema di visualizzazione degli esami online richiesto
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   Problema di visualizzazione degli esami online richiesto
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione f9d8f86ea510af30843b1b2ed6c21994 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 114
   ğŸ“Š Token totali: 542
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 542 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 114
   ğŸ“Š Token conversazione finale: 114
   ğŸ“Š Token totali: 542
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 363 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2651 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:13.144371
====================================================================================================
ğŸ“‹ Session ID: classify_1756466173
â±ï¸  Processing Time: 0.780s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (363 chars):
   [UTENTE] Posso avere telefono ufficio referti  [ASSISTENTE] L'ufficio ritiro referti di Humanitas si trova in Via Sardegna 5, Fizzonasco di Pieve Emanuele. Per ulteriori informazioni, puoi visitare...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (115 chars):
    {"predicted_label": "info_contatti", "confidence": 0.9, "motivation": "Domanda sui contatti dell'ufficio referti"}

ğŸ“Š Parsed Response:
   predicted_label: info_contatti
   confidence: 0.9
   motivation: Domanda sui contatti dell'ufficio referti
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda sui contatti dell'ufficio referti
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 9ebd75e21c44bf4a0feddfd09e4490fe classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 128
   ğŸ“Š Token totali: 556
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 556 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 128
   ğŸ“Š Token conversazione finale: 128
   ğŸ“Š Token totali: 556
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 437 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2741 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:14.167271
====================================================================================================
ğŸ“‹ Session ID: classify_1756466174
â±ï¸  Processing Time: 0.916s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (437 chars):
   [UTENTE] Ciao Giulia, se faccio gli esami del sangue per creatinina e GFR domani mattina, entro quando ho i risultati? [ASSISTENTE] Il tuo referto sarÃ  disponibile a partire dalla data e orario spe...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (153 chars):
    {"predicted_label": "info_esame", "confidence": 0.9, "motivation": "L'utente chiede quando avrÃ  i risultati degli esami di sangue per creatinina e GFR"}

ğŸ“Š Parsed Response:
   predicted_label: info_esame
   confidence: 0.9
   motivation: L'utente chiede quando avrÃ  i risultati degli esami di sangue per creatinina e GFR
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede quando avrÃ  i risultati degli esami di sangue per creatinina e GFR
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 7fd088f1d2e657b33ae81ac1d864c7c2 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 272
   ğŸ“Š Token totali: 721
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 721 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 272
   ğŸ“Š Token conversazione finale: 272
   ğŸ“Š Token totali: 721
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 930 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2876 chars (debug_prompt=False)
ğŸ”§ Creazione MongoClassificationReader per cliente: alleanza
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
âœ… MongoClassificationReader alleanza creato con collection: alleanza_a0fd7600-f4f7-11ef-9315-96000228e7fe
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
âœ… Connesso a MongoDB database: classificazioni
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:15.914587
====================================================================================================
ğŸ“‹ Session ID: classify_1756466175
â±ï¸  Processing Time: 1.641s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (930 chars):
   [UTENTE] Dopo quanto tempo scade una visita? [ASSISTENTE] Le ricette emesse prima del 30 dicembre 2024 hanno una validitÃ  di 180 giorni dalla data di prescrizione per effettuare la prenotazione. Le...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (355 chars):
    {"predicted_label": "info_prenotazione", "confidence": 0.9, "motivation": "La domanda riguarda il tempo di scadenza per una visita e la risposta fornita indica che le ricette emesse prima del 30 dicembre 2024 hanno una validitÃ  di 180 giorni dalla data di prescrizione per effettuare la prenotazi...

ğŸ“Š Parsed Response:
   predicted_label: info_prenotazione
   confidence: 0.9
   motivation: La domanda riguarda il tempo di scadenza per una visita e la risposta fornita indica che le ricette emesse prima del 30 dicembre 2024 hanno una validitÃ  di 180 giorni dalla data di prescrizione per effettuare la prenotazione, quindi si tratta di informazioni sulla prenotazione
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   La domanda riguarda il tempo di scadenza per una visita e la risposta fornita indica che le ricette emesse prima del 30 dicembre 2024 hanno una validitÃ  di 180 giorni dalla data di prescrizione per effettuare la prenotazione, quindi si tratta di informazioni sulla prenotazione
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ” Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione ceaf3fa0028b23278fde0666a682d87c classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 240
   ğŸ“Š Token totali: 688
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 688 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 240
   ğŸ“Š Token conversazione finale: 240
   ğŸ“Š Token totali: 688
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 856 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2850 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:16.845063
====================================================================================================
ğŸ“‹ Session ID: classify_1756466176
â±ï¸  Processing Time: 0.820s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (856 chars):
   [UTENTE] Ho prenotato Ho prenotato una risonanza magnetica alla spalla per il giorno 7 settembre presso la Clinica Pio decimo se prenoto la visita per il giorno successivo cioÃ¨ 8 settembre il medic...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (114 chars):
    {"predicted_label": "info_esame", "confidence": 0.9, "motivation": "Domanda sui risultati di un esame prenotato"}

ğŸ“Š Parsed Response:
   predicted_label: info_esame
   confidence: 0.9
   motivation: Domanda sui risultati di un esame prenotato
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda sui risultati di un esame prenotato
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione ffc7adf73747fda9ccd6b009c4ecf308 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 239
   ğŸ“Š Token totali: 688
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 688 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 239
   ğŸ“Š Token conversazione finale: 239
   ğŸ“Š Token totali: 688
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 746 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2814 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:17.828653
====================================================================================================
ğŸ“‹ Session ID: classify_1756466177
â±ï¸  Processing Time: 0.879s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (746 chars):
   [UTENTE] Ciao, vorrei prenotare dei prelievi venosi con SSN, mi indichi come faccio online? [ASSISTENTE] Per prenotare un prelievo venoso con il Servizio Sanitario Nazionale (SSN) presso Humanitas,...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (134 chars):
    {"predicted_label": "prenotazione_esame", "confidence": 0.9, "motivation": "L'utente vuole prenotare un esame di laboratorio online"}

ğŸ“Š Parsed Response:
   predicted_label: prenotazione_esame
   confidence: 0.9
   motivation: L'utente vuole prenotare un esame di laboratorio online
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente vuole prenotare un esame di laboratorio online
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione e3ff9852018699bdcf8f77dbf1b526d0 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 113
   ğŸ“Š Token totali: 562
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 562 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 113
   ğŸ“Š Token conversazione finale: 113
   ğŸ“Š Token totali: 562
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 370 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2859 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:18.790708
====================================================================================================
ğŸ“‹ Session ID: classify_1756466178
â±ï¸  Processing Time: 0.856s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (370 chars):
   [UTENTE] devo dare i campioni delle feci per coprocoltura e capotrectina [ASSISTENTE] Per consegnare campioni di materiale biologico, come le feci per coprocoltura e calprotectina, ti consiglio di ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (146 chars):
    {"predicted_label": "consegna_campioni", "confidence": 0.9, "motivation": "L'utente richiede informazioni su come consegnare campioni biologici"}

ğŸ“Š Parsed Response:
   predicted_label: consegna_campioni
   confidence: 0.9
   motivation: L'utente richiede informazioni su come consegnare campioni biologici
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente richiede informazioni su come consegnare campioni biologici
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 5d95d01e6ea12269ed200be3eae0024a classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 186
   ğŸ“Š Token totali: 635
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 635 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 186
   ğŸ“Š Token conversazione finale: 186
   ğŸ“Š Token totali: 635
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 567 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2846 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:19.997936
====================================================================================================
ğŸ“‹ Session ID: classify_1756466179
â±ï¸  Processing Time: 1.101s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (567 chars):
   [UTENTE] Il punto prelievi di viale sardegna Ã¨ aperto in estate?  [ASSISTENTE] Il punto prelievi di Via Sardegna 5, Fizzonasco di Pieve Emanuele, Ã¨ aperto durante l'estate con i seguenti orari: da ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (189 chars):
    {"predicted_label": "info_orario", "confidence": 0.9, "motivation": "L'utente chiede informazioni sui tempi di apertura del punto prelievi di Via Sardegna 5, Fizzonasco di Pieve Emanuele"}

ğŸ“Š Parsed Response:
   predicted_label: info_orario
   confidence: 0.9
   motivation: L'utente chiede informazioni sui tempi di apertura del punto prelievi di Via Sardegna 5, Fizzonasco di Pieve Emanuele
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni sui tempi di apertura del punto prelievi di Via Sardegna 5, Fizzonasco di Pieve Emanuele
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione ca50df1e6c42c5be1e6a170ea90d7c6f classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 94
   ğŸ“Š Token totali: 522
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 522 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 94
   ğŸ“Š Token conversazione finale: 94
   ğŸ“Š Token totali: 522
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 321 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2725 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:21.080096
====================================================================================================
ğŸ“‹ Session ID: classify_1756466181
â±ï¸  Processing Time: 0.976s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (321 chars):
   [UTENTE] Preparazione per coronografia  [ASSISTENTE] Per la preparazione alla coronarografia, Ã¨ necessario eseguire l'esame a digiuno e viene effettuato in regime di ricovero. Per ulteriori dettagl...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (188 chars):
    {"predicted_label": "info_preparazione_esame", "confidence": 0.9, "motivation": "L'utente chiede informazioni sulla preparazione per un esame specifico, in questo caso la coronarografia"}

ğŸ“Š Parsed Response:
   predicted_label: info_preparazione_esame
   confidence: 0.9
   motivation: L'utente chiede informazioni sulla preparazione per un esame specifico, in questo caso la coronarografia
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni sulla preparazione per un esame specifico, in questo caso la coronarografia
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 08172694b6e0077a2d8b2dd869a457ec classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 474
   ğŸ“Š Token totali: 922
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 922 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 474
   ğŸ“Š Token conversazione finale: 474
   ğŸ“Š Token totali: 922
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1553 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2878 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:22.276998
====================================================================================================
ğŸ“‹ Session ID: classify_1756466182
â±ï¸  Processing Time: 1.091s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1553 chars):
   [UTENTE] Vorrei sapere se sabato 30 settembre 2025 Ã¨ possibile fare gli esami del sangue Humanitas fiordaliso? [ASSISTENTE] Presso Humanitas Medical Care Rozzano-Fiordaliso, il sabato Ã¨ possibile e...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (214 chars):
    {"predicted_label": "info_prenotazione", "confidence": 0.8, "motivation": "Domanda su quando e' possibile prenotare un esame di sangue presso Humanitas Medical Care Rozzano-Fiordaliso il sabato 30 settembre 2025"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: Domanda su quando e' possibile prenotare un esame di sangue presso Humanitas Medical Care Rozzano-Fiordaliso il sabato 30 settembre 2025
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   Domanda su quando e' possibile prenotare un esame di sangue presso Humanitas Medical Care Rozzano-Fiordaliso il sabato 30 settembre 2025
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 0e136e7f2019409187c6b0278433e590 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 204
   ğŸ“Š Token totali: 632
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 632 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 204
   ğŸ“Š Token conversazione finale: 204
   ğŸ“Š Token totali: 632
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 646 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2683 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:23.199171
====================================================================================================
ğŸ“‹ Session ID: classify_1756466183
â±ï¸  Processing Time: 0.816s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (646 chars):
   [UTENTE] vorrei disdire un appuntamento [ASSISTENTE] Per disdire un appuntamento presso Humanitas, puoi seguire queste indicazioni:

1. **Prenotazioni private**: Puoi annullare tramite il portale [...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [77 more lines] ...
     Line 81: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (120 chars):
    {"predicted_label": "disdetta_appuntamento", "confidence": 0.9, "motivation": "L'utente vuole disdire un appuntamento"}

ğŸ“Š Parsed Response:
   predicted_label: disdetta_appuntamento
   confidence: 0.9
   motivation: L'utente vuole disdire un appuntamento
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente vuole disdire un appuntamento
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 561cd119e94fd7da2a11e19b794f0b59 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 124
   ğŸ“Š Token totali: 552
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 552 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 124
   ğŸ“Š Token conversazione finale: 124
   ğŸ“Š Token totali: 552
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 428 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2621 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:24.123811
====================================================================================================
ğŸ“‹ Session ID: classify_1756466184
â±ï¸  Processing Time: 0.819s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (428 chars):
   [UTENTE] Buongiorno ho disdetto una visita privata usando la segreteria telefonica come da istruzioni. La conferma di disdetta viene mandata via e.mail? [ASSISTENTE] Non ho informazioni specifiche ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (131 chars):
    {"predicted_label": "info_disdetta_visita", "confidence": 0.9, "motivation": "Domanda riguardante una disdetta di visita privata"}

ğŸ“Š Parsed Response:
   predicted_label: info_disdetta_visita
   confidence: 0.9
   motivation: Domanda riguardante una disdetta di visita privata
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda riguardante una disdetta di visita privata
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione ed4b837eb3ba2dc5310b8a6d16a39e73 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 287
   ğŸ“Š Token totali: 735
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 735 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 287
   ğŸ“Š Token conversazione finale: 287
   ğŸ“Š Token totali: 735
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 978 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2856 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:25.095939
====================================================================================================
ğŸ“‹ Session ID: classify_1756466185
â±ï¸  Processing Time: 0.866s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (978 chars):
   [UTENTE] Buongiorno volevo sapere quale Ã¨ la tempistica per l'annullamento di una visita in regime privato Grazie [ASSISTENTE] Per annullare una visita in regime privato, Ã¨ necessario farlo almeno ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (139 chars):
    {"predicted_label": "info_annullamento_visita", "confidence": 0.9, "motivation": "Domanda su come annullare una visita in regime privato"}

ğŸ“Š Parsed Response:
   predicted_label: info_annullamento_visita
   confidence: 0.9
   motivation: Domanda su come annullare una visita in regime privato
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come annullare una visita in regime privato
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 47950ed6055043e0200bd4736615170d classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 425
   ğŸ“Š Token totali: 853
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 853 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 425
   ğŸ“Š Token conversazione finale: 425
   ğŸ“Š Token totali: 853
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1383 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2685 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:26.131897
====================================================================================================
ğŸ“‹ Session ID: classify_1756466186
â±ï¸  Processing Time: 0.931s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1383 chars):
   [UTENTE] Ho prenotato un prelievo venoso tramite assicurazione per una data ma dovrei spostare l'appuntamento. E' possibile farlo visto che l'autorizzazione dell'assicurazione ha un determinato per...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (161 chars):
    {"predicted_label": "cambio_appuntamento", "confidence": 0.9, "motivation": "Domanda su come spostare un appuntamento di prelievo venoso tramite assicurazione"}

ğŸ“Š Parsed Response:
   predicted_label: cambio_appuntamento
   confidence: 0.9
   motivation: Domanda su come spostare un appuntamento di prelievo venoso tramite assicurazione
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come spostare un appuntamento di prelievo venoso tramite assicurazione
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 93e307139bd3a7bd30aff9b98e043652 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 183
   ğŸ“Š Token totali: 611
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 611 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 183
   ğŸ“Š Token conversazione finale: 183
   ğŸ“Š Token totali: 611
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 628 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2695 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:27.007517
====================================================================================================
ğŸ“‹ Session ID: classify_1756466187
â±ï¸  Processing Time: 0.769s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (628 chars):
   [UTENTE] Come vedo se una prenotazione Ã¨ stata annullata?  [ASSISTENTE] Per verificare se una prenotazione Ã¨ stata annullata, puoi accedere allâ€™area â€œMiei appuntamentiâ€ sul sito [Humanitas con te](...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (133 chars):
    {"predicted_label": "info_prenotazione", "confidence": 0.9, "motivation": "Domanda su come verificare lo stato di una prenotazione"}

ğŸ“Š Parsed Response:
   predicted_label: info_prenotazione
   confidence: 0.9
   motivation: Domanda su come verificare lo stato di una prenotazione
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come verificare lo stato di una prenotazione
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 25fe727a43271a08704e9da0ea3af470 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 568
   ğŸ“Š Token totali: 1016
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 1016 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 568
   ğŸ“Š Token conversazione finale: 568
   ğŸ“Š Token totali: 1016
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1706 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2624 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:27.936171
====================================================================================================
ğŸ“‹ Session ID: classify_1756466187
â±ï¸  Processing Time: 0.823s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1706 chars):
   [UTENTE] Ciao Giulia, domani ho una visita. Come posso arrivare in Humanitas? [ASSISTENTE] Da dove parti e in quale sede Humanitas devi arrivare? Inoltre, preferisci utilizzare l'auto, i mezzi pubb...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (124 chars):
    {"predicted_label": "info_visita", "confidence": 0.9, "motivation": "Domanda riguardante una visita al centro ospedaliero"}

ğŸ“Š Parsed Response:
   predicted_label: info_visita
   confidence: 0.9
   motivation: Domanda riguardante una visita al centro ospedaliero
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda riguardante una visita al centro ospedaliero
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 094dd46d9b78f8dad0d021f7b3741c05 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 85
   ğŸ“Š Token totali: 513
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 513 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 85
   ğŸ“Š Token conversazione finale: 85
   ğŸ“Š Token totali: 513
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 267 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2737 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:28.917675
====================================================================================================
ğŸ“‹ Session ID: classify_1756466188
â±ï¸  Processing Time: 0.876s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (267 chars):
   [UTENTE] La linea 220 Ã¨ extraurbana? [ASSISTENTE] SÃ¬, la linea 220 Ã¨ una linea extraurbana che collega Humanitas con Pieve Emanuele, Opera e Locate, partendo da Rozzano, via della SolidarietÃ ã€6:0â€ s...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (132 chars):
    {"predicted_label": "info_linea", "confidence": 0.9, "motivation": "Domanda su dove si trova la linea 220 e sulle cittÃ  che serve"}

ğŸ“Š Parsed Response:
   predicted_label: info_linea
   confidence: 0.9
   motivation: Domanda su dove si trova la linea 220 e sulle cittÃ  che serve
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su dove si trova la linea 220 e sulle cittÃ  che serve
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 8b42ef48bf61435ee6b34184131a5418 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 161
   ğŸ“Š Token totali: 589
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 589 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 161
   ğŸ“Š Token conversazione finale: 161
   ğŸ“Š Token totali: 589
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 529 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2502 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:29.599828
====================================================================================================
ğŸ“‹ Session ID: classify_1756466189
â±ï¸  Processing Time: 0.576s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (529 chars):
   [UTENTE] Buongiorno. Esiste ancora il servizio navetta che ti porta dalla metropolitana di Abbiategrasso all'ospedale Humanitas ? [ASSISTENTE] SÃ¬, esiste ancora un servizio di trasporto pubblico ch...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (95 chars):
    {"predicted_label": "info_benvenuto", "confidence": 0.9, "motivation": "Domanda di benvenuto"}

ğŸ“Š Parsed Response:
   predicted_label: info_benvenuto
   confidence: 0.9
   motivation: Domanda di benvenuto
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda di benvenuto
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 2f23911465f38b6123f687633306d10c classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 182
   ğŸ“Š Token totali: 630
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 630 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 182
   ğŸ“Š Token conversazione finale: 182
   ğŸ“Š Token totali: 630
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 587 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2843 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:30.502619
====================================================================================================
ğŸ“‹ Session ID: classify_1756466190
â±ï¸  Processing Time: 0.797s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (587 chars):
   [UTENTE] Volevo chiedere se ce il servizio transfer ? [ASSISTENTE] Potresti specificare meglio cosa intendi per "servizio transfer"? Ti riferisci a un servizio di trasporto da e per l'ospedale, opp...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (130 chars):
    {"predicted_label": "info_trasporto", "confidence": 0.8, "motivation": "Domanda su un servizio di trasporto da e per l'ospedale"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: Domanda su un servizio di trasporto da e per l'ospedale
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   Domanda su un servizio di trasporto da e per l'ospedale
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione d0684fe510373586ea1882e862fa606e classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 136
   ğŸ“Š Token totali: 585
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 585 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 136
   ğŸ“Š Token conversazione finale: 136
   ğŸ“Š Token totali: 585
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 493 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2763 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:31.423953
====================================================================================================
ğŸ“‹ Session ID: classify_1756466191
â±ï¸  Processing Time: 0.815s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (493 chars):
   [UTENTE] Voglio visionare i miei referti online [ASSISTENTE] Per visionare i tuoi referti online, Ã¨ necessario registrarsi a [Humanitas con te](https://www.humanitasconte.it). Una volta registrato,...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (123 chars):
    {"predicted_label": "info_referti", "confidence": 0.9, "motivation": "L'utente chiede di visionare i suoi referti online"}

ğŸ“Š Parsed Response:
   predicted_label: info_referti
   confidence: 0.9
   motivation: L'utente chiede di visionare i suoi referti online
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede di visionare i suoi referti online
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione f64fbee98f98a2c83c37373a473f1f69 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 128
   ğŸ“Š Token totali: 556
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 556 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 128
   ğŸ“Š Token conversazione finale: 128
   ğŸ“Š Token totali: 556
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 429 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2743 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:32.515488
====================================================================================================
ğŸ“‹ Session ID: classify_1756466192
â±ï¸  Processing Time: 0.986s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (429 chars):
   [UTENTE] non so come verificare la mia postazione  [ASSISTENTE] Per verificare la tua postazione o il luogo di accettazione per una visita o esame, puoi consultare la sezione "Miei appuntamenti" de...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (173 chars):
    {"predicted_label": "info_miei_appuntamenti", "confidence": 0.9, "motivation": "Domanda su come verificare la postazione o il luogo di accettazione per una visita o esame"}

ğŸ“Š Parsed Response:
   predicted_label: info_miei_appuntamenti
   confidence: 0.9
   motivation: Domanda su come verificare la postazione o il luogo di accettazione per una visita o esame
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come verificare la postazione o il luogo di accettazione per una visita o esame
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 636b13b7899b5f48f73cab8a20b442e7 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 98
   ğŸ“Š Token totali: 526
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 526 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 98
   ğŸ“Š Token conversazione finale: 98
   ğŸ“Š Token totali: 526
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 308 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2656 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:33.511098
====================================================================================================
ğŸ“‹ Session ID: classify_1756466193
â±ï¸  Processing Time: 0.889s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (308 chars):
   [UTENTE] Fatturazione [ASSISTENTE] Puoi consultare e scaricare le tue fatture direttamente dal portale [Humanitas con te](https://www.humanitasconte.it). Accedi con le tue credenziali, vai alla sez...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (162 chars):
    {"predicted_label": "info_fatturazione", "confidence": 0.9, "motivation": "L'utente Ã¨ informato su come consultare e scaricare le fatture dal portale Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: info_fatturazione
   confidence: 0.9
   motivation: L'utente Ã¨ informato su come consultare e scaricare le fatture dal portale Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente Ã¨ informato su come consultare e scaricare le fatture dal portale Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 92b438ff69e40821dc52e3b2012f7b60 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 481
   ğŸ“Š Token totali: 929
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 929 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 481
   ğŸ“Š Token conversazione finale: 481
   ğŸ“Š Token totali: 929
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1502 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2810 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:34.499956
====================================================================================================
ğŸ“‹ Session ID: classify_1756466194
â±ï¸  Processing Time: 0.866s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1502 chars):
   [UTENTE] come scaricare la prenotazione di un esame [ASSISTENTE] Per scaricare la prenotazione di un esame, Ã¨ necessario accedere al portale [Humanitas con te](https://www.humanitasconte.it). Dopo ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (132 chars):
    {"predicted_label": "info_prenotazione", "confidence": 0.9, "motivation": "Domanda su come scaricare una prenotazione di un esame"}

ğŸ“Š Parsed Response:
   predicted_label: info_prenotazione
   confidence: 0.9
   motivation: Domanda su come scaricare una prenotazione di un esame
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come scaricare una prenotazione di un esame
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 244e3645f6ed55b7bdfd90c5cac927f7 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 97
   ğŸ“Š Token totali: 525
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 525 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 97
   ğŸ“Š Token conversazione finale: 97
   ğŸ“Š Token totali: 525
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 336 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2616 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:35.458113
====================================================================================================
ğŸ“‹ Session ID: classify_1756466195
â±ï¸  Processing Time: 0.852s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (336 chars):
   [UTENTE] Non ho ancora ricevuto il messaggio per il ritiro del RX del 01.08 [ASSISTENTE] Per verificare lo stato del referto, ti consiglio di contattare il servizio dedicato compilando il modulo di...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (135 chars):
    {"predicted_label": "problema_ritiro_RX", "confidence": 0.9, "motivation": "Domanda su un problema con il ritiro di una prescrizione"}

ğŸ“Š Parsed Response:
   predicted_label: problema_ritiro_rx
   confidence: 0.9
   motivation: Domanda su un problema con il ritiro di una prescrizione
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su un problema con il ritiro di una prescrizione
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 2b17e5dd553ce95d37370e4b03146537 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 295
   ğŸ“Š Token totali: 743
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 743 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 295
   ğŸ“Š Token conversazione finale: 295
   ğŸ“Š Token totali: 743
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 952 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2687 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:36.432788
====================================================================================================
ğŸ“‹ Session ID: classify_1756466196
â±ï¸  Processing Time: 0.869s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (952 chars):
   [UTENTE] P7 castellanza [ASSISTENTE] Non ho informazioni specifiche sul parcheggio P7 a Castellanza. Tuttavia, se hai bisogno di informazioni sui parcheggi o su come raggiungere una delle sedi di H...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (142 chars):
    {"predicted_label": "info_parcheggio", "confidence": 0.9, "motivation": "Domanda su informazioni specifiche sul parcheggio P7 a Castellanza"}

ğŸ“Š Parsed Response:
   predicted_label: info_parcheggio
   confidence: 0.9
   motivation: Domanda su informazioni specifiche sul parcheggio P7 a Castellanza
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su informazioni specifiche sul parcheggio P7 a Castellanza
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 9e2176698f02b81f1a6ecbf79bf9d863 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 116
   ğŸ“Š Token totali: 544
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 544 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 116
   ğŸ“Š Token conversazione finale: 116
   ğŸ“Š Token totali: 544
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 327 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2702 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:37.426755
====================================================================================================
ğŸ“‹ Session ID: classify_1756466197
â±ï¸  Processing Time: 0.887s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (327 chars):
   [UTENTE] Costo parcheggio P4 [ASSISTENTE] Il costo del parcheggio P4 Ã¨ il seguente:

- Prima ora (o frazione di ora): â‚¬ 2,00;
- Ora o frazione successiva: â‚¬ 2,00;
- Giornata intera: â‚¬ 8,00.

Per ma...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [77 more lines] ...
     Line 81: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (132 chars):
    {"predicted_label": "info_parcheggio", "confidence": 0.9, "motivation": "L'utente chiede informazioni sul costo del parcheggio P4"}

ğŸ“Š Parsed Response:
   predicted_label: info_parcheggio
   confidence: 0.9
   motivation: L'utente chiede informazioni sul costo del parcheggio P4
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni sul costo del parcheggio P4
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione dda3b104960241c9488ad8199585f8a0 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 167
   ğŸ“Š Token totali: 595
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 595 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 167
   ğŸ“Š Token conversazione finale: 167
   ğŸ“Š Token totali: 595
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 554 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2739 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:38.299465
====================================================================================================
ğŸ“‹ Session ID: classify_1756466198
â±ï¸  Processing Time: 0.767s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (554 chars):
   [UTENTE] cosa include il pacchettp p [ASSISTENTE] Non ho trovato informazioni specifiche sul "pacchetto p" nei documenti caricati. Potresti fornirmi maggiori dettagli o chiarire a cosa ti riferisci...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (146 chars):
    {"predicted_label": "info_pacchetto", "confidence": 0.6, "motivation": "L'utente chiede informazioni su un pacchetto specifico non identificato"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.39999999999999997
   motivation: L'utente chiede informazioni su un pacchetto specifico non identificato
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.400
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 40.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni su un pacchetto specifico non identificato
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 52ede270308eb3d573a70134426f6525 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 146
   ğŸ“Š Token totali: 594
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 594 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 146
   ğŸ“Š Token conversazione finale: 146
   ğŸ“Š Token totali: 594
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 489 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2799 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:39.168614
====================================================================================================
ğŸ“‹ Session ID: classify_1756466199
â±ï¸  Processing Time: 0.764s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (489 chars):
   [UTENTE] Posso pagare il parcheggio con l'app easy park? [ASSISTENTE] Non ho informazioni specifiche sull'utilizzo dell'app EasyPark per il pagamento del parcheggio presso Humanitas. Tuttavia, poss...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (129 chars):
    {"predicted_label": "info_parcheggio", "confidence": 0.8, "motivation": "Domanda su come pagare il parcheggio presso Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: Domanda su come pagare il parcheggio presso Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come pagare il parcheggio presso Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 22b97fda51adf4a0d4e203293986d3e6 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 82
   ğŸ“Š Token totali: 510
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 510 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 82
   ğŸ“Š Token conversazione finale: 82
   ğŸ“Š Token totali: 510
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 279 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2779 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:40.152014
====================================================================================================
ğŸ“‹ Session ID: classify_1756466200
â±ï¸  Processing Time: 0.878s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (279 chars):
   [UTENTE] Ho bisogno di un oncologo [ASSISTENTE] Per avere informazioni specifiche sui medici oncologi di Humanitas, ti consiglio di visitare la pagina dedicata alla [Ricerca Medici](https://www.hum...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (137 chars):
    {"predicted_label": "info_medico", "confidence": 0.9, "motivation": "L'utente ha chiesto informazioni sui medici oncologi di Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: info_medico
   confidence: 0.9
   motivation: L'utente ha chiesto informazioni sui medici oncologi di Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente ha chiesto informazioni sui medici oncologi di Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione e6810c2a4142fea56170c5119b4324f0 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 236
   ğŸ“Š Token totali: 664
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 664 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 236
   ğŸ“Š Token conversazione finale: 236
   ğŸ“Š Token totali: 664
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 773 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2779 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:41.266244
====================================================================================================
ğŸ“‹ Session ID: classify_1756466201
â±ï¸  Processing Time: 1.009s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (773 chars):
   [UTENTE] Cerco oncologo che tratti tumore pancreas con metastasi fegato  [ASSISTENTE] Per il trattamento del tumore al pancreas con metastasi epatiche, Humanitas offre un approccio multidisciplinar...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (183 chars):
    {"predicted_label": "info_oncologo", "confidence": 0.9, "motivation": "L'utente sta cercando informazioni su un oncologo specializzato in tumori del pancreas con metastasi epatiche"}

ğŸ“Š Parsed Response:
   predicted_label: info_oncologo
   confidence: 0.9
   motivation: L'utente sta cercando informazioni su un oncologo specializzato in tumori del pancreas con metastasi epatiche
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente sta cercando informazioni su un oncologo specializzato in tumori del pancreas con metastasi epatiche
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione cf269492799fa61e3379452b2c7e7557 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 290
   ğŸ“Š Token totali: 718
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 718 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 290
   ğŸ“Š Token conversazione finale: 290
   ğŸ“Š Token totali: 718
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 979 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2693 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:42.241509
====================================================================================================
ğŸ“‹ Session ID: classify_1756466202
â±ï¸  Processing Time: 0.869s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (979 chars):
   [UTENTE] Volevo elenco medici humanityâ€™s per gastroenterologos [ASSISTENTE] Per informazioni sui medici specializzati in gastroenterologia presso Humanitas, puoi consultare le seguenti unitÃ  operat...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [75 more lines] ...
     Line 79: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (163 chars):
    {"predicted_label": "info_medico", "confidence": 0.9, "motivation": "L'utente chiede informazioni sui medici specializzati in gastroenterologia presso Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: info_medico
   confidence: 0.9
   motivation: L'utente chiede informazioni sui medici specializzati in gastroenterologia presso Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni sui medici specializzati in gastroenterologia presso Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 880f12cd8a9ca920769f71bf440a4f5d classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 105
   ğŸ“Š Token totali: 533
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 533 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 105
   ğŸ“Š Token conversazione finale: 105
   ğŸ“Š Token totali: 533
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 371 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2774 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:43.235635
====================================================================================================
ğŸ“‹ Session ID: classify_1756466203
â±ï¸  Processing Time: 0.888s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (371 chars):
   [UTENTE] come posso contattare la struttura del Dottor Carlo Castoro per la conferma di un appuntamento ? [ASSISTENTE] Per ottenere informazioni specifiche sul Dottor Carlo Castoro e sulla struttur...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (164 chars):
    {"predicted_label": "info_prenotazione", "confidence": 0.9, "motivation": "Domanda su come contattare per conferma di un appuntamento con il Dottor Carlo Castoro"}

ğŸ“Š Parsed Response:
   predicted_label: info_prenotazione
   confidence: 0.9
   motivation: Domanda su come contattare per conferma di un appuntamento con il Dottor Carlo Castoro
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come contattare per conferma di un appuntamento con il Dottor Carlo Castoro
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 8bf990eba6830f9587452d2ef5b349cf classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 207
   ğŸ“Š Token totali: 655
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 655 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 207
   ğŸ“Š Token conversazione finale: 207
   ğŸ“Š Token totali: 655
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 741 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2773 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:44.270320
====================================================================================================
ğŸ“‹ Session ID: classify_1756466204
â±ï¸  Processing Time: 0.929s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (741 chars):
   [UTENTE] Vorrei richiedere la cartella online [ASSISTENTE] Puoi richiedere la cartella clinica online tramite l'area referti di [Humanitas con te](https://www.humanitasconte.it). Se hai bisogno di ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (168 chars):
    {"predicted_label": "info_ritiro_referto_cartella_clinica", "confidence": 0.9, "motivation": "Richiesta di informazioni sulla richiesta della cartella clinica online"}

ğŸ“Š Parsed Response:
   predicted_label: info_ritiro_referto_cartella_clinica
   confidence: 0.9
   motivation: Richiesta di informazioni sulla richiesta della cartella clinica online
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Richiesta di informazioni sulla richiesta della cartella clinica online
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 681d4afc1e0e843fa5b35ff5ce0b9999 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 170
   ğŸ“Š Token totali: 598
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 598 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 170
   ğŸ“Š Token conversazione finale: 170
   ğŸ“Š Token totali: 598
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 599 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2731 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:45.350866
====================================================================================================
ğŸ“‹ Session ID: classify_1756466205
â±ï¸  Processing Time: 0.975s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (599 chars):
   [UTENTE] Buon giorno sono Oriana corradino in data 30 luglio ho fatto la spirometria a torino nel vostro centro mi doveva arrivare il referto via mail ma non mi Ã¨ arrivato  [ASSISTENTE] Se non hai ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (203 chars):
    {"predicted_label": "problema_amministrativo", "confidence": 0.8, "motivation": "L'utente ha ricevuto un referto ma non lo ha ancora ricevuto via email, quindi si tratta di un problema amministrativo."}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: L'utente ha ricevuto un referto ma non lo ha ancora ricevuto via email, quindi si tratta di un problema amministrativo.
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   L'utente ha ricevuto un referto ma non lo ha ancora ricevuto via email, quindi si tratta di un problema amministrativo.
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione bdb04270dbcec6ec7d43a8c78a1edc22 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 257
   ğŸ“Š Token totali: 706
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 706 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 257
   ğŸ“Š Token conversazione finale: 257
   ğŸ“Š Token totali: 706
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 848 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2763 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:46.195011
====================================================================================================
ğŸ“‹ Session ID: classify_1756466206
â±ï¸  Processing Time: 0.738s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (848 chars):
   [UTENTE] io circa Anna mia cosa fare [ASSISTENTE] Potresti spiegarmi meglio la tua richiesta? CosÃ¬ posso aiutarti nel modo piÃ¹ adeguato. [UTENTE] Buongiorno Giulia  [ASSISTENTE] Buongiorno! Come po...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (131 chars):
    {"predicted_label": "info_aiuto", "confidence": 0.8, "motivation": "L'utente ha chiesto informazioni su come ricevere assistenza"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: L'utente ha chiesto informazioni su come ricevere assistenza
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   L'utente ha chiesto informazioni su come ricevere assistenza
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 437f07ded15971033a82bf41d20041ff classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 231
   ğŸ“Š Token totali: 679
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 679 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 231
   ğŸ“Š Token conversazione finale: 231
   ğŸ“Š Token totali: 679
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 787 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2751 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:47.340652
====================================================================================================
ğŸ“‹ Session ID: classify_1756466207
â±ï¸  Processing Time: 1.041s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (787 chars):
   [UTENTE] Sto aspettando che qualcuno mi contatti con URGENZA per poter scaricare gli esami di laboratorio fatti a Torino in Humaniyas Cellini pet Luciana Sanna e Leandro Difino. Sono urgentissimo e...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (189 chars):
    {"predicted_label": "info_ritiro_esami", "confidence": 0.9, "motivation": "Domanda su come scaricare gli esami di laboratorio fatti a Torino in un'unitÃ  specifica dell'ospedale Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: info_ritiro_esami
   confidence: 0.9
   motivation: Domanda su come scaricare gli esami di laboratorio fatti a Torino in un'unitÃ  specifica dell'ospedale Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come scaricare gli esami di laboratorio fatti a Torino in un'unitÃ  specifica dell'ospedale Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 2542996825cf2262442ba8028f52d2af classificata tramite LLM diretto (classificazione=unknown)
   ğŸ“ˆ Progresso LLM: 50/166
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 242
   ğŸ“Š Token totali: 690
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 690 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 242
   ğŸ“Š Token conversazione finale: 242
   ğŸ“Š Token totali: 690
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 845 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2852 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:48.534138
====================================================================================================
ğŸ“‹ Session ID: classify_1756466208
â±ï¸  Processing Time: 1.089s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (845 chars):
   [UTENTE] Vorrei sapere la tariffa agevolata con mÃ¨taSalute di rmn aperta rachide cervicale senza contrasto humanitas Rozzano  [ASSISTENTE] Non ho trovato informazioni specifiche sulla tariffa agevo...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (241 chars):
    {"predicted_label": "info_tariffa", "confidence": 0.7, "motivation": "L'utente ha chiesto informazioni sulla tariffa agevolata con mÃ¨taSalute per la risonanza magnetica aperta del rachide cervicale senza contrasto presso Humanitas Rozzano"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.49999999999999994
   motivation: L'utente ha chiesto informazioni sulla tariffa agevolata con mÃ¨taSalute per la risonanza magnetica aperta del rachide cervicale senza contrasto presso Humanitas Rozzano
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.500
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 50.0%

ğŸ§  Reasoning/Motivation:
   L'utente ha chiesto informazioni sulla tariffa agevolata con mÃ¨taSalute per la risonanza magnetica aperta del rachide cervicale senza contrasto presso Humanitas Rozzano
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione afd4014c5ca4c54e07c2de2688922d18 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 158
   ğŸ“Š Token totali: 586
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 586 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 158
   ğŸ“Š Token conversazione finale: 158
   ğŸ“Š Token totali: 586
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 521 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2816 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:49.485064
====================================================================================================
ğŸ“‹ Session ID: classify_1756466209
â±ï¸  Processing Time: 0.845s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (521 chars):
   [UTENTE] Buon giorno, sto cercando di capire se il vs istituto fornisce anche la medicina nucleare ed in particolare Cintigrafia cerebrale [ASSISTENTE] SÃ¬, l'Istituto Clinico Humanitas offre serviz...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (132 chars):
    {"predicted_label": "info_medicina_nucleare", "confidence": 0.9, "motivation": "Richiesta di informazioni sulla medicina nucleare"}

ğŸ“Š Parsed Response:
   predicted_label: info_medicina_nucleare
   confidence: 0.9
   motivation: Richiesta di informazioni sulla medicina nucleare
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Richiesta di informazioni sulla medicina nucleare
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 6512d16919369ef5bd4dac2c199f7010 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 173
   ğŸ“Š Token totali: 601
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 601 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 173
   ğŸ“Š Token conversazione finale: 173
   ğŸ“Š Token totali: 601
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 618 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2770 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:50.330985
====================================================================================================
ğŸ“‹ Session ID: classify_1756466210
â±ï¸  Processing Time: 0.740s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (618 chars):
   [UTENTE] Salve volevo chiedere se eseguite la radiografia colonna completa sotto carico con metodo eos [ASSISTENTE] SÃ¬, Humanitas esegue la radiografia della colonna vertebrale completa, utile per ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (112 chars):
    {"predicted_label": "info_esame", "confidence": 0.9, "motivation": "Domanda su un esame diagnostico specifico"}

ğŸ“Š Parsed Response:
   predicted_label: info_esame
   confidence: 0.9
   motivation: Domanda su un esame diagnostico specifico
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su un esame diagnostico specifico
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione ce1f4d3ffa6b071d1ab717c7872d253a classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 172
   ğŸ“Š Token totali: 620
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 620 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 172
   ğŸ“Š Token conversazione finale: 172
   ğŸ“Š Token totali: 620
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 583 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2854 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:51.209408
====================================================================================================
ğŸ“‹ Session ID: classify_1756466211
â±ï¸  Processing Time: 0.773s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (583 chars):
   [UTENTE] Buongiorno,  vorrei sapere se fate la mammografia in 3d [ASSISTENTE] SÃ¬, presso Humanitas Ã¨ possibile effettuare la mammografia in Tomosintesi, una tecnica avanzata che consente una valuta...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (107 chars):
    {"predicted_label": "info_esame", "confidence": 0.9, "motivation": "Domanda su un esame medico specifico"}

ğŸ“Š Parsed Response:
   predicted_label: info_esame
   confidence: 0.9
   motivation: Domanda su un esame medico specifico
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su un esame medico specifico
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione fe179b6339df101273ac93bc3435d1a6 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 68
   ğŸ“Š Token totali: 517
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 517 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 68
   ğŸ“Š Token conversazione finale: 68
   ğŸ“Š Token totali: 517
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 227 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2780 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:52.243072
====================================================================================================
ğŸ“‹ Session ID: classify_1756466212
â±ï¸  Processing Time: 0.929s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (227 chars):
   [UTENTE] Voglio parlare con un operatore  [ASSISTENTE] Puoi contattare il servizio centralino di Humanitas al numero 02 822 41 per parlare con un operatore umano. Se hai bisogno di ulteriori inform...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (159 chars):
    {"predicted_label": "info_contatti", "confidence": 0.9, "motivation": "L'utente chiede di contattare un operatore umano del servizio centralino di Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: info_contatti
   confidence: 0.9
   motivation: L'utente chiede di contattare un operatore umano del servizio centralino di Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede di contattare un operatore umano del servizio centralino di Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 58dcea97d71b6960da7e90df6b17bb0c classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 56
   ğŸ“Š Token totali: 504
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 504 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 56
   ğŸ“Š Token conversazione finale: 56
   ğŸ“Š Token totali: 504
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 179 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2751 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:53.167225
====================================================================================================
ğŸ“‹ Session ID: classify_1756466213
â±ï¸  Processing Time: 0.818s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (179 chars):
   [UTENTE] Mi serce io numero del centralino grazie  [ASSISTENTE] Il numero del centralino di Humanitas Ã¨ 02 8224 1. Se hai bisogno di ulteriori informazioni, sono qui per aiutarti!

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (127 chars):
    {"predicted_label": "info_contatto", "confidence": 0.9, "motivation": "L'utente chiede il numero del centralino di Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: info_contatto
   confidence: 0.9
   motivation: L'utente chiede il numero del centralino di Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede il numero del centralino di Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 3635a11a107d03df46aba779fb4d3f3c classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 87
   ğŸ“Š Token totali: 515
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 515 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 87
   ğŸ“Š Token conversazione finale: 87
   ğŸ“Š Token totali: 515
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 299 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2779 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:54.067934
====================================================================================================
ğŸ“‹ Session ID: classify_1756466214
â±ï¸  Processing Time: 0.796s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (299 chars):
   [UTENTE] Numero di telefono ritiro referti [ASSISTENTE] Il numero di telefono specifico per il ritiro referti non Ã¨ indicato. Ti consiglio di contattare il centralino di Humanitas al numero 02 8224...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (114 chars):
    {"predicted_label": "info_ritiro_referto", "confidence": 0.9, "motivation": "Domanda su come ritirare i referti"}

ğŸ“Š Parsed Response:
   predicted_label: info_ritiro_referto
   confidence: 0.9
   motivation: Domanda su come ritirare i referti
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come ritirare i referti
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 1e9a8529a34b030126ab8ab1e771b5fc classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 88
   ğŸ“Š Token totali: 516
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 516 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 88
   ğŸ“Š Token conversazione finale: 88
   ğŸ“Š Token totali: 516
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 292 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2772 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:54.941523
====================================================================================================
ğŸ“‹ Session ID: classify_1756466214
â±ï¸  Processing Time: 0.766s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (292 chars):
   [UTENTE] Ho una televisita ma il medico non c'Ã¨  [ASSISTENTE] Mi dispiace per l'inconveniente. Ti consiglio di contattare il centralino di Humanitas al numero 02 822 41 per segnalare il problema e ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (139 chars):
    {"predicted_label": "problema_accesso_visita", "confidence": 0.9, "motivation": "L'utente ha segnalato un problema con una visita medica"}

ğŸ“Š Parsed Response:
   predicted_label: problema_accesso_visita
   confidence: 0.9
   motivation: L'utente ha segnalato un problema con una visita medica
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente ha segnalato un problema con una visita medica
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione a1ba7c5135dd160b2685280c3e38634c classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 157
   ğŸ“Š Token totali: 606
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 606 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 157
   ğŸ“Š Token conversazione finale: 157
   ğŸ“Š Token totali: 606
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 517 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2878 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:55.923099
====================================================================================================
ğŸ“‹ Session ID: classify_1756466215
â±ï¸  Processing Time: 0.876s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (517 chars):
   [UTENTE] devo richiedere una cartella clinica [ASSISTENTE] Puoi richiedere il rilascio delle cartelle cliniche dei ricoveri svolti presso l'Istituto Clinico Humanitas online dallâ€™area referti di [H...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (130 chars):
    {"predicted_label": "ricerca_cartella_clinica", "confidence": 0.9, "motivation": "Richiesta di rilascio delle cartelle cliniche"}

ğŸ“Š Parsed Response:
   predicted_label: ricerca_cartella_clinica
   confidence: 0.9
   motivation: Richiesta di rilascio delle cartelle cliniche
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Richiesta di rilascio delle cartelle cliniche
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione ee20cf335f29e8d397ac6070f4f1569e classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 106
   ğŸ“Š Token totali: 554
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 554 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 106
   ğŸ“Š Token conversazione finale: 106
   ğŸ“Š Token totali: 554
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 368 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2819 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:56.987287
====================================================================================================
ğŸ“‹ Session ID: classify_1756466216
â±ï¸  Processing Time: 0.956s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (368 chars):
   [UTENTE] Ho bisogno la cartella clinica di un deceduto  [ASSISTENTE] Per richiedere la cartella clinica di una persona deceduta, Ã¨ necessario seguire una procedura specifica. Ti consiglio di consul...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (158 chars):
    {"predicted_label": "info_ritiro_referto_cartella_clinica", "confidence": 0.9, "motivation": "L'utente richiede la cartella clinica di una persona deceduta"}

ğŸ“Š Parsed Response:
   predicted_label: info_ritiro_referto_cartella_clinica
   confidence: 0.9
   motivation: L'utente richiede la cartella clinica di una persona deceduta
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente richiede la cartella clinica di una persona deceduta
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 5458db5557b93ade31b4ce36f80732cb classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 124
   ğŸ“Š Token totali: 572
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 572 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 124
   ğŸ“Š Token conversazione finale: 124
   ğŸ“Š Token totali: 572
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 447 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2782 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:57.902501
====================================================================================================
ğŸ“‹ Session ID: classify_1756466217
â±ï¸  Processing Time: 0.810s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (447 chars):
   [UTENTE] Richiesta preparati istologici  [ASSISTENTE] Per quanto riguarda i preparati istologici, Ã¨ importante sapere che i referti istologici con esito positivo non possono essere delegati per il ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (128 chars):
    {"predicted_label": "info_preparati_istologici", "confidence": 0.9, "motivation": "Domanda sui preparati istologici richiesti"}

ğŸ“Š Parsed Response:
   predicted_label: info_preparati_istologici
   confidence: 0.9
   motivation: Domanda sui preparati istologici richiesti
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda sui preparati istologici richiesti
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 4dcacdbbe4bc66b785aa20f98c67981a classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 175
   ğŸ“Š Token totali: 603
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 603 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 175
   ğŸ“Š Token conversazione finale: 175
   ğŸ“Š Token totali: 603
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 580 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2613 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:16:58.997514
====================================================================================================
ğŸ“‹ Session ID: classify_1756466218
â±ï¸  Processing Time: 0.989s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (580 chars):
   [UTENTE] cartella clinica persona deceduta [ASSISTENTE] Per richiedere la cartella clinica di una persona deceduta, Ã¨ necessario esercitare i diritti previsti dall'art. 2-terdecies del Codice in ma...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (192 chars):
    {"predicted_label": "info_ritiro_referto_cartella_clinica", "confidence": 0.9, "motivation": "Richiesta informazioni sulla procedura per ritirare la cartella clinica di una persona deceduta"}

ğŸ“Š Parsed Response:
   predicted_label: info_ritiro_referto_cartella_clinica
   confidence: 0.9
   motivation: Richiesta informazioni sulla procedura per ritirare la cartella clinica di una persona deceduta
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Richiesta informazioni sulla procedura per ritirare la cartella clinica di una persona deceduta
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 3f3c2e85a21279ca6e6dcd8204b43cb4 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 590
   ğŸ“Š Token totali: 1038
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 1038 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 590
   ğŸ“Š Token conversazione finale: 590
   ğŸ“Š Token totali: 1038
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 2022 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2766 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:00.006656
====================================================================================================
ğŸ“‹ Session ID: classify_1756466220
â±ï¸  Processing Time: 0.903s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (2022 chars):
   [UTENTE] Buongiorno sto cercando una cartella  clinica [ASSISTENTE] Per richiedere una cartella clinica, puoi farlo online tramite lâ€™area referti di [Humanitas con te](https://www.humanitasconte.it...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (151 chars):
    {"predicted_label": "info_ritiro_referto_cartella_clinica", "confidence": 0.9, "motivation": "Domanda su come richiedere una cartella clinica online"}

ğŸ“Š Parsed Response:
   predicted_label: info_ritiro_referto_cartella_clinica
   confidence: 0.9
   motivation: Domanda su come richiedere una cartella clinica online
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come richiedere una cartella clinica online
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 8e6a188964cee438a18e98e4a36b19d4 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 353
   ğŸ“Š Token totali: 801
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 801 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 353
   ğŸ“Š Token conversazione finale: 353
   ğŸ“Š Token totali: 801
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1143 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2836 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:00.986880
====================================================================================================
ğŸ“‹ Session ID: classify_1756466220
â±ï¸  Processing Time: 0.874s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1143 chars):
   [UTENTE] Buongiorno, scrivo perchÃ© non ho ritirato un referto che avrei dovuto ritirare entro circa 15 gennaio 2025 [ASSISTENTE] Se non hai ritirato il referto entro i 30 giorni dalla data indicata...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (160 chars):
    {"predicted_label": "info_ritiro_referto", "confidence": 0.9, "motivation": "Domanda su come ritirare un referto non ancora ritirato entro il tempo stabilito"}

ğŸ“Š Parsed Response:
   predicted_label: info_ritiro_referto
   confidence: 0.9
   motivation: Domanda su come ritirare un referto non ancora ritirato entro il tempo stabilito
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come ritirare un referto non ancora ritirato entro il tempo stabilito
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 4829a9000e4e07e73aa596ac2fe222bd classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 262
   ğŸ“Š Token totali: 710
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 710 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 262
   ğŸ“Š Token conversazione finale: 262
   ğŸ“Š Token totali: 710
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 926 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2682 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:01.948092
====================================================================================================
ğŸ“‹ Session ID: classify_1756466221
â±ï¸  Processing Time: 0.853s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (926 chars):
   [UTENTE] Sono stata ricoverata dal 29 06 al 02 07 2025 ma la cartella clinica non Ã¨ ancora disponibile . Come.posso sapere quando potrÃ² scaricarla? [ASSISTENTE] La copia digitale della cartella cli...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (159 chars):
    {"predicted_label": "info_ritiro_referto_cartella_clinica", "confidence": 0.9, "motivation": "Domanda su come ottenere la cartella clinica dopo una ricovero"}

ğŸ“Š Parsed Response:
   predicted_label: info_ritiro_referto_cartella_clinica
   confidence: 0.9
   motivation: Domanda su come ottenere la cartella clinica dopo una ricovero
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come ottenere la cartella clinica dopo una ricovero
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 3f613cc0add0ba362c47ea52094c1408 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 191
   ğŸ“Š Token totali: 619
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 619 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 191
   ğŸ“Š Token conversazione finale: 191
   ğŸ“Š Token totali: 619
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 641 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2728 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:02.998688
====================================================================================================
ğŸ“‹ Session ID: classify_1756466222
â±ï¸  Processing Time: 0.943s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (641 chars):
   [UTENTE] Avrei bisogno di avere referto RMN encefalo fatta tra ottobre e dicembre 2020 [ASSISTENTE] I referti relativi a esami effettuati prima del 2018 non sono consultabili online. Per ottenere i...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [75 more lines] ...
     Line 79: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (151 chars):
    {"predicted_label": "info_esame", "confidence": 0.9, "motivation": "Richiesta di informazioni su un esame RMN effettuato tra ottobre e dicembre 2020"}

ğŸ“Š Parsed Response:
   predicted_label: info_esame
   confidence: 0.9
   motivation: Richiesta di informazioni su un esame RMN effettuato tra ottobre e dicembre 2020
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Richiesta di informazioni su un esame RMN effettuato tra ottobre e dicembre 2020
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 95d26de177974faef8ed04f27ac70c6d classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 218
   ğŸ“Š Token totali: 646
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 646 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 218
   ğŸ“Š Token conversazione finale: 218
   ğŸ“Š Token totali: 646
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 739 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2741 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:03.965596
====================================================================================================
ğŸ“‹ Session ID: classify_1756466223
â±ï¸  Processing Time: 0.861s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (739 chars):
   [UTENTE] buonasera, ho un'intervento prenotato ma vorrei maggiori informazioni [ASSISTENTE] Buonasera! Potresti specificare se il tuo intervento Ã¨ stato prenotato tramite il Servizio Sanitario Nazi...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (148 chars):
    {"predicted_label": "info_prenotazione", "confidence": 0.9, "motivation": "L'utente ha prenotato un intervento e richiede informazioni su di esso"}

ğŸ“Š Parsed Response:
   predicted_label: info_prenotazione
   confidence: 0.9
   motivation: L'utente ha prenotato un intervento e richiede informazioni su di esso
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente ha prenotato un intervento e richiede informazioni su di esso
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 09ca9fcba0c4c70d9499687d76c00da3 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 279
   ğŸ“Š Token totali: 707
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 707 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 279
   ğŸ“Š Token conversazione finale: 279
   ğŸ“Š Token totali: 707
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 904 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2750 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:04.940804
====================================================================================================
ğŸ“‹ Session ID: classify_1756466224
â±ï¸  Processing Time: 0.871s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (904 chars):
   [UTENTE] come si puÃ² fare la chirurgia refrattiva? [ASSISTENTE] La chirurgia refrattiva puÃ² essere effettuata con diverse tecniche, tra cui il laser a eccimeri e il laser a femtosecondi. Questi tra...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (136 chars):
    {"predicted_label": "info_chirurgia_refrattiva", "confidence": 0.9, "motivation": "Domanda su come effettuare la chirurgia refrattiva"}

ğŸ“Š Parsed Response:
   predicted_label: info_chirurgia_refrattiva
   confidence: 0.9
   motivation: Domanda su come effettuare la chirurgia refrattiva
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come effettuare la chirurgia refrattiva
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 2e492a83704f46c45a8cb4640f96f349 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 275
   ğŸ“Š Token totali: 723
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 723 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 275
   ğŸ“Š Token conversazione finale: 275
   ğŸ“Š Token totali: 723
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 881 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2836 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:05.904024
====================================================================================================
ğŸ“‹ Session ID: classify_1756466225
â±ï¸  Processing Time: 0.857s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (881 chars):
   [UTENTE] VORREI SAPERE SE IN hUMANITAS EFFETTUATE LE INFILTRAZIONI ECO/RADIOGUIDATE DELLA SACROILIACA DESTRA CON ANESTETICO E COTRTISONE [ASSISTENTE] In Humanitas, Ã¨ possibile effettuare infiltrazi...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (129 chars):
    {"predicted_label": "info_terapia", "confidence": 0.9, "motivation": "Domanda su una terapia specifica effettuata in Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: info_terapia
   confidence: 0.9
   motivation: Domanda su una terapia specifica effettuata in Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su una terapia specifica effettuata in Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione df983cacc0c4ea5eb6ef3f42d18b7d1f classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 195
   ğŸ“Š Token totali: 623
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 623 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 195
   ğŸ“Š Token conversazione finale: 195
   ğŸ“Š Token totali: 623
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 678 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2724 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:06.881474
====================================================================================================
ğŸ“‹ Session ID: classify_1756466226
â±ï¸  Processing Time: 0.871s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (678 chars):
   [UTENTE] Sono assicurato con QUAS avere in previsione una convenzione diretta? [ASSISTENTE] L'Istituto Clinico Humanitas Ã¨ convenzionato con molteplici enti che gestiscono polizze salute e casse mu...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (144 chars):
    {"predicted_label": "info_convenzione", "confidence": 0.9, "motivation": "Domanda su una convenzione diretta con l'Istituto Clinico Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: info_convenzione
   confidence: 0.9
   motivation: Domanda su una convenzione diretta con l'Istituto Clinico Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su una convenzione diretta con l'Istituto Clinico Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 9e54685bad0596182b03d1ae095084d8 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 74
   ğŸ“Š Token totali: 523
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 523 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 74
   ğŸ“Š Token conversazione finale: 74
   ğŸ“Š Token totali: 523
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 243 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2825 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:07.930349
====================================================================================================
ğŸ“‹ Session ID: classify_1756466227
â±ï¸  Processing Time: 0.944s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (243 chars):
   [UTENTE] Salve vorrei desideri due appuntamenti.  [ASSISTENTE] Certamente! Potresti specificare per quali visite o esami desideri prenotare gli appuntamenti? Inoltre, vuoi prenotare tramite il Serv...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (154 chars):
    {"predicted_label": "prenotazione_appuntamento", "confidence": 0.9, "motivation": "L'utente ha chiesto di prenotare due appuntamenti per visite o esami"}

ğŸ“Š Parsed Response:
   predicted_label: prenotazione_appuntamento
   confidence: 0.9
   motivation: L'utente ha chiesto di prenotare due appuntamenti per visite o esami
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente ha chiesto di prenotare due appuntamenti per visite o esami
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione eb2ca36ca2f1c8b5fe13faf74d5e3692 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 262
   ğŸ“Š Token totali: 690
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 690 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 262
   ğŸ“Š Token conversazione finale: 262
   ğŸ“Š Token totali: 690
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 886 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2743 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:09.091472
====================================================================================================
ğŸ“‹ Session ID: classify_1756466229
â±ï¸  Processing Time: 1.052s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (886 chars):
   [UTENTE] Avrei bisogno di una cartella clinica  [ASSISTENTE] Puoi richiedere la cartella clinica dei ricoveri svolti presso l'Istituto Clinico Humanitas in diversi modi:

1. **Copia digitale**: Puo...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [75 more lines] ...
     Line 79: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (184 chars):
    {"predicted_label": "info_ritiro_referto_cartella_clinica", "confidence": 0.9, "motivation": "L'utente richiede una cartella clinica dei ricoveri presso l'Istituto Clinico Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: info_ritiro_referto_cartella_clinica
   confidence: 0.9
   motivation: L'utente richiede una cartella clinica dei ricoveri presso l'Istituto Clinico Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente richiede una cartella clinica dei ricoveri presso l'Istituto Clinico Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 3aa520569eed0b5cfa800280fc129da4 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 841
   ğŸ“Š Token totali: 1289
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 1289 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 841
   ğŸ“Š Token conversazione finale: 841
   ğŸ“Š Token totali: 1289
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 2744 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2857 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:10.318482
====================================================================================================
ğŸ“‹ Session ID: classify_1756466230
â±ï¸  Processing Time: 1.121s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (2744 chars):
   [UTENTE] Buon pomeriggio [ASSISTENTE] Buon pomeriggio! Come posso esserti utile? [UTENTE] Vorrei sapere come poter richiedere la cartella clinica di mio padre inerente al suo ricovero al centro di ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (209 chars):
    {"predicted_label": "info_ritiro_referto_cartella_clinica", "confidence": 0.9, "motivation": "Domanda su come richiedere la cartella clinica di un paziente inerente a un ricovero al centro di riabilitazione"}

ğŸ“Š Parsed Response:
   predicted_label: info_ritiro_referto_cartella_clinica
   confidence: 0.9
   motivation: Domanda su come richiedere la cartella clinica di un paziente inerente a un ricovero al centro di riabilitazione
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come richiedere la cartella clinica di un paziente inerente a un ricovero al centro di riabilitazione
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ”§ Creazione MongoClassificationReader per cliente: humanitas
ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione e4c0a8f3dc98cc31ec36ce8060dff391 classificata tramite LLM diretto (classificazione=unknown)
âœ… MongoClassificationReader humanitas creato con collection: humanitas_015007d9-d413-11ef-86a5-96000228e7fe
âœ… Connesso a MongoDB database: classificazioni
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 453
   ğŸ“Š Token totali: 901
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 901 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 453
   ğŸ“Š Token conversazione finale: 453
   ğŸ“Š Token totali: 901
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1507 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2579 chars (debug_prompt=False)
ğŸ” Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:11.172965
====================================================================================================
ğŸ“‹ Session ID: classify_1756466231
â±ï¸  Processing Time: 0.743s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1507 chars):
   [UTENTE] Buon giorno Giulia. [ASSISTENTE] Buongiorno! Come posso esserti utile oggi? ğŸ˜Š [UTENTE] Buon giorno vorrei ricevere a casa x via posta la cartella clinica del mio. Intervento eseguito il 19...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (120 chars):
    {"predicted_label": "saluto", "confidence": 0.9, "motivation": "Domanda di saluto non riferita a un intento specifico"}

ğŸ“Š Parsed Response:
   predicted_label: saluto
   confidence: 0.9
   motivation: Domanda di saluto non riferita a un intento specifico
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda di saluto non riferita a un intento specifico
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 971037ef14ecfaff479c543d83b3a592 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 152
   ğŸ“Š Token totali: 580
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 580 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 152
   ğŸ“Š Token conversazione finale: 152
   ğŸ“Š Token totali: 580
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 526 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2748 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:12.428781
====================================================================================================
ğŸ“‹ Session ID: classify_1756466232
â±ï¸  Processing Time: 1.151s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (526 chars):
   [UTENTE] Buongiorno, ho erroneamente annullato una richiesta di cartella clinica, quanto tempo passa per effettuare nuova richiesta? [ASSISTENTE] Puoi effettuare una nuova richiesta di cartella cli...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (232 chars):
    {"predicted_label": "info_ritiro_referto_cartella_clinica", "confidence": 0.9, "motivation": "L'utente ha richiesto informazioni su come effettuare una nuova richiesta di cartella clinica dopo averne annullato una precedentemente"}

ğŸ“Š Parsed Response:
   predicted_label: info_ritiro_referto_cartella_clinica
   confidence: 0.9
   motivation: L'utente ha richiesto informazioni su come effettuare una nuova richiesta di cartella clinica dopo averne annullato una precedentemente
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente ha richiesto informazioni su come effettuare una nuova richiesta di cartella clinica dopo averne annullato una precedentemente
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 0395ae4ff369e2db62fdf96eeb8af1b2 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 375
   ğŸ“Š Token totali: 824
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 824 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 375
   ğŸ“Š Token conversazione finale: 375
   ğŸ“Š Token totali: 824
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1296 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2810 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:13.406471
====================================================================================================
ğŸ“‹ Session ID: classify_1756466233
â±ï¸  Processing Time: 0.873s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1296 chars):
   [UTENTE] Come ritirare il referto di mia figlia minorenne? [ASSISTENTE] Per ritirare il referto di tua figlia minorenne, Ã¨ necessario seguire queste indicazioni:

1. **Ritiro da parte del genitore ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [78 more lines] ...
     Line 82: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (139 chars):
    {"predicted_label": "info_ritiro_referto", "confidence": 0.9, "motivation": "Domanda su come ritirare il referto di una figlia minorenne"}

ğŸ“Š Parsed Response:
   predicted_label: info_ritiro_referto
   confidence: 0.9
   motivation: Domanda su come ritirare il referto di una figlia minorenne
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come ritirare il referto di una figlia minorenne
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 77d183bd3ba6e3f3380e2384c48e28a4 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 202
   ğŸ“Š Token totali: 630
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 630 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 202
   ğŸ“Š Token conversazione finale: 202
   ğŸ“Š Token totali: 630
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 721 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2732 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:14.267734
====================================================================================================
ğŸ“‹ Session ID: classify_1756466234
â±ï¸  Processing Time: 0.755s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (721 chars):
   [UTENTE] Non riesco a registrarmi con il codice fiscale  [ASSISTENTE] Se non riesci a registrarti utilizzando il codice fiscale, ti consiglio di verificare che i dati inseriti siano corretti. Assic...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [75 more lines] ...
     Line 79: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (130 chars):
    {"predicted_label": "problema_accesso_portale", "confidence": 0.8, "motivation": "Problema tecnico di accesso al portale online"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: Problema tecnico di accesso al portale online
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   Problema tecnico di accesso al portale online
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 2fd0e4ae095b98ab42d617aa78f6b8fc classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 452
   ğŸ’¬ Token conversazione: 190
   ğŸ“Š Token totali: 642
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 642 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 452
   ğŸ“Š Token conversazione originale: 190
   ğŸ“Š Token conversazione finale: 190
   ğŸ“Š Token totali: 642
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 692 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2897 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:15.337995
====================================================================================================
ğŸ“‹ Session ID: classify_1756466235
â±ï¸  Processing Time: 0.963s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (692 chars):
   [UTENTE] Buongiorno, sto cercando di prenotare un RX gastrointestinale superiore per mio figlio, ma dopo aver selezionato la data al momento di confermare la prenotazione il sistema va in errore [A...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (159 chars):
    {"predicted_label": "prenotazione_RX", "confidence": 0.9, "motivation": "Richiesta di prenotare un RX gastrointestinale superiore per il figlio del paziente"}

ğŸ“Š Parsed Response:
   predicted_label: prenotazione_rx
   confidence: 0.9
   motivation: Richiesta di prenotare un RX gastrointestinale superiore per il figlio del paziente
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Richiesta di prenotare un RX gastrointestinale superiore per il figlio del paziente
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 4a2c96f66be7d5db6d5babf072483150 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 226
   ğŸ“Š Token totali: 654
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 654 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 226
   ğŸ“Š Token conversazione finale: 226
   ğŸ“Š Token totali: 654
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 784 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2563 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:16.165049
====================================================================================================
ğŸ“‹ Session ID: classify_1756466236
â±ï¸  Processing Time: 0.721s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (784 chars):
   [UTENTE] Buongiorno. In fase di registrazione, Ã¨ stato abbinato automaticamente il mio codice fiscale PRTMTN97H60F205S alla mail sbagliata e quindi non riesco a procedere con l'iscrizione. La mail ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [75 more lines] ...
     Line 79: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (96 chars):
    {"predicted_label": "aiuto", "confidence": 0.9, "motivation": "L'utente ha chiesto assistenza"}

ğŸ“Š Parsed Response:
   predicted_label: aiuto
   confidence: 0.9
   motivation: L'utente ha chiesto assistenza
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente ha chiesto assistenza
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 2297a1e9265fb3e617fab3bc3dc4db05 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 194
   ğŸ“Š Token totali: 622
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 622 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 194
   ğŸ“Š Token conversazione finale: 194
   ğŸ“Š Token totali: 622
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 692 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2772 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:16.843214
====================================================================================================
ğŸ“‹ Session ID: classify_1756466236
â±ï¸  Processing Time: 0.574s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (692 chars):
   [UTENTE] Ciao Giulia, avrei bisogno di un contatto per poter chiedere delucidazioni su un codice di unâ€™impegnativa relativa a uno spermiogramma [ASSISTENTE] Per problematiche relative a codici o ID...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (111 chars):
    {"predicted_label": "info_esame", "confidence": 0.8, "motivation": "Domanda su un codice di un esame clinico"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: Domanda su un codice di un esame clinico
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   Domanda su un codice di un esame clinico
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 54ec7b4e58a6c3e0e7cb6bc7de1616eb classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 180
   ğŸ“Š Token totali: 608
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 608 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 180
   ğŸ“Š Token conversazione finale: 180
   ğŸ“Š Token totali: 608
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 654 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2764 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:17.867166
====================================================================================================
ğŸ“‹ Session ID: classify_1756466237
â±ï¸  Processing Time: 0.918s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (654 chars):
   [UTENTE] Ho piÃ¹ di 100 anni: come posso registrarmi per il ritiro dei referti? il sistema mi blocca perchÃ¨ dice che sono minorenne, guardando il mio codice fiscale  [ASSISTENTE] Per risolvere il pr...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (170 chars):
    {"predicted_label": "problema_accesso_portale", "confidence": 0.9, "motivation": "Domanda su come risolvere un problema di accesso al portale per il ritiro dei referti"}

ğŸ“Š Parsed Response:
   predicted_label: problema_accesso_portale
   confidence: 0.9
   motivation: Domanda su come risolvere un problema di accesso al portale per il ritiro dei referti
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come risolvere un problema di accesso al portale per il ritiro dei referti
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione ee4a3f963fa70a91b0d5e980f39477f1 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 255
   ğŸ“Š Token totali: 703
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 703 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 255
   ğŸ“Š Token conversazione finale: 255
   ğŸ“Š Token totali: 703
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 805 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2855 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:18.922536
====================================================================================================
ğŸ“‹ Session ID: classify_1756466238
â±ï¸  Processing Time: 0.949s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (805 chars):
   [UTENTE] salve vorrei sapere come fare per un ricovero in solvenza [ASSISTENTE] Per prenotare un ricovero in regime privato (solvenza) presso Humanitas, puoi contattare l'Ufficio Ricoveri Privati c...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (157 chars):
    {"predicted_label": "info_ricovero", "confidence": 0.9, "motivation": "Domanda su come prenotare un ricovero in regime privato (solvenza) presso Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: info_ricovero
   confidence: 0.9
   motivation: Domanda su come prenotare un ricovero in regime privato (solvenza) presso Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come prenotare un ricovero in regime privato (solvenza) presso Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 07d8e38a9405dcd6e27aa01e114ebac3 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 155
   ğŸ“Š Token totali: 604
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 604 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 155
   ğŸ“Š Token conversazione finale: 155
   ğŸ“Š Token totali: 604
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 493 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2733 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:19.934462
====================================================================================================
ğŸ“‹ Session ID: classify_1756466239
â±ï¸  Processing Time: 0.906s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (493 chars):
   [UTENTE] mi potresti dare il numero di telefono della chirurgia della mano per una visita [ASSISTENTE] Puoi prenotare una visita per la chirurgia della mano chiamando il numero 02.82242358, attivo ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (147 chars):
    {"predicted_label": "prenotazione_chirurgia", "confidence": 0.9, "motivation": "Domanda su come prenotare una visita per la chirurgia della mano"}

ğŸ“Š Parsed Response:
   predicted_label: prenotazione_chirurgia
   confidence: 0.9
   motivation: Domanda su come prenotare una visita per la chirurgia della mano
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come prenotare una visita per la chirurgia della mano
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 3c460cff69da2e9baf16437b346752cf classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 130
   ğŸ“Š Token totali: 558
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 558 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 130
   ğŸ“Š Token conversazione finale: 130
   ğŸ“Š Token totali: 558
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 393 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2732 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:20.885201
====================================================================================================
ğŸ“‹ Session ID: classify_1756466240
â±ï¸  Processing Time: 0.846s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (393 chars):
   [UTENTE] Buongiorno vorrei modificare un appuntamento telefonicamente [ASSISTENTE] Per modificare un appuntamento telefonicamente presso l'Istituto Clinico Humanitas, puoi contattare il numero 02 8...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [75 more lines] ...
     Line 79: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (131 chars):
    {"predicted_label": "modifica_appuntamento", "confidence": 0.9, "motivation": "L'utente ha chiesto di modificare un appuntamento"}

ğŸ“Š Parsed Response:
   predicted_label: modifica_appuntamento
   confidence: 0.9
   motivation: L'utente ha chiesto di modificare un appuntamento
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente ha chiesto di modificare un appuntamento
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 625b172465feb159c22f8c25b2cf40c1 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 179
   ğŸ“Š Token totali: 607
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 607 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 179
   ğŸ“Š Token conversazione finale: 179
   ğŸ“Š Token totali: 607
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 549 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2618 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:21.801358
====================================================================================================
ğŸ“‹ Session ID: classify_1756466241
â±ï¸  Processing Time: 0.812s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (549 chars):
   [UTENTE] Buongiorno sono Samuele Mulargia e son in vostro paziente. Ho fatto un intervento in regime privato e mi servirebbe la fattura della spesa affrontata  [ASSISTENTE] Per ottenere la fattura ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [75 more lines] ...
     Line 79: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (139 chars):
    {"predicted_label": "info_paziente", "confidence": 0.9, "motivation": "Utente si identifica come paziente e offre di aiutare l'operatore"}

ğŸ“Š Parsed Response:
   predicted_label: info_paziente
   confidence: 0.9
   motivation: Utente si identifica come paziente e offre di aiutare l'operatore
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Utente si identifica come paziente e offre di aiutare l'operatore
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 15fdbb98b2b553b465f945431b21a05d classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 159
   ğŸ“Š Token totali: 587
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 587 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 159
   ğŸ“Š Token conversazione finale: 159
   ğŸ“Š Token totali: 587
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 574 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2698 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:22.635645
====================================================================================================
ğŸ“‹ Session ID: classify_1756466242
â±ï¸  Processing Time: 0.730s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (574 chars):
   [UTENTE] Non mi arriva la mail per reimpostare la password  [ASSISTENTE] Se non ricevi la mail per reimpostare la password su [Humanitas con te](https://www.humanitasconte.it), ti consiglio di cont...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [75 more lines] ...
     Line 79: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (145 chars):
    {"predicted_label": "problema_accesso_portale", "confidence": 0.8, "motivation": "Domanda su come ricevere la mail per reimpostare la password"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: Domanda su come ricevere la mail per reimpostare la password
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come ricevere la mail per reimpostare la password
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione b314a796098d5a4c4e07985c1a749f8d classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 205
   ğŸ“Š Token totali: 633
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 633 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 205
   ğŸ“Š Token conversazione finale: 205
   ğŸ“Š Token totali: 633
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 728 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2541 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:23.529101
====================================================================================================
ğŸ“‹ Session ID: classify_1756466243
â±ï¸  Processing Time: 0.789s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (728 chars):
   [UTENTE] Non riesco a scaricare il referto . Ho anche  cambiato browser. Ma non si carica mai. Ho segnalato all'assistenza il problema ma nessuno mi ha contattato.  Ãˆ dal 17 che sto provando sia su...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [75 more lines] ...
     Line 79: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (128 chars):
    {"predicted_label": "problema_scarico_referto", "confidence": 0.9, "motivation": "L'utente ha problemi a scaricare il referto"}

ğŸ“Š Parsed Response:
   predicted_label: problema_scarico_referto
   confidence: 0.9
   motivation: L'utente ha problemi a scaricare il referto
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente ha problemi a scaricare il referto
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione e0824d33448be844497f19096468a9e5 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 454
   ğŸ’¬ Token conversazione: 289
   ğŸ“Š Token totali: 743
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 743 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 454
   ğŸ“Š Token conversazione originale: 289
   ğŸ“Š Token conversazione finale: 289
   ğŸ“Š Token totali: 743
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 889 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2709 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:24.576512
====================================================================================================
ğŸ“‹ Session ID: classify_1756466244
â±ï¸  Processing Time: 0.943s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (889 chars):
   [UTENTE] NON RIESCO AD ACCEDERE PER VEDERE I MIEI REFERTI ONLINE. INSERENDO IL MIO CODICE FISCALE (FRGVTR59A22F205U) MI DICE CHE SONO GIA' REGISTRATO MA NON RIESCO A RECUPERARE LA PASSWORD. UN PAIO...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (161 chars):
    {"predicted_label": "problema_accesso_portale", "confidence": 0.9, "motivation": "Problema tecnico di accesso al portale online Ã¨ chiarissimo e inequivocabile"}

ğŸ“Š Parsed Response:
   predicted_label: problema_accesso_portale
   confidence: 0.9
   motivation: Problema tecnico di accesso al portale online Ã¨ chiarissimo e inequivocabile
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Problema tecnico di accesso al portale online Ã¨ chiarissimo e inequivocabile
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 9dad9db3ff581fcd8938a9d8412a4412 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 228
   ğŸ“Š Token totali: 677
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 677 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 228
   ğŸ“Š Token conversazione finale: 228
   ğŸ“Š Token totali: 677
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 831 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2876 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:25.576634
====================================================================================================
ğŸ“‹ Session ID: classify_1756466245
â±ï¸  Processing Time: 0.896s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (831 chars):
   [UTENTE] salve, io risulto giÃ  registrato presso il vostro portale, ma non ricordo la email con la quale mi ero registrato anni fa e che ora non ho piÃ¹, quindi per scaricare i nuovi esami che ho fa...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (135 chars):
    {"predicted_label": "cambio_anagrafica", "confidence": 0.9, "motivation": "Domanda su come cambiare l'email nella propria anagrafica"}

ğŸ“Š Parsed Response:
   predicted_label: cambio_anagrafica
   confidence: 0.9
   motivation: Domanda su come cambiare l'email nella propria anagrafica
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come cambiare l'email nella propria anagrafica
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione bdc17cfeb478e19f0a055ebbf14313ec classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 236
   ğŸ“Š Token totali: 664
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 664 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 236
   ğŸ“Š Token conversazione finale: 236
   ğŸ“Š Token totali: 664
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 786 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2655 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:26.618791
====================================================================================================
ğŸ“‹ Session ID: classify_1756466246
â±ï¸  Processing Time: 0.937s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (786 chars):
   [UTENTE] Buon giorno Giulia,
non riesco a registrarmi in quanto Ã¨ stato inserito il mio numero di telefono errato. Quello corretto Ã¨ : + 39 344 122 1902 
codice fiscale NNNSRA99C44M052U 
IANNONE SA...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (189 chars):
    {"predicted_label": "problema_accesso_portale", "confidence": 0.8, "motivation": "Domanda su un problema di accesso al portale online dovuto all'inserimento errato del numero di telefono"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: Domanda su un problema di accesso al portale online dovuto all'inserimento errato del numero di telefono
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   Domanda su un problema di accesso al portale online dovuto all'inserimento errato del numero di telefono
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione a2e7512836de94a985b02b662d1ddad0 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 149
   ğŸ“Š Token totali: 598
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 598 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 149
   ğŸ“Š Token conversazione finale: 149
   ğŸ“Š Token totali: 598
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 539 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2866 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:27.539605
====================================================================================================
ğŸ“‹ Session ID: classify_1756466247
â±ï¸  Processing Time: 0.816s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (539 chars):
   [UTENTE] Chi devo contattare perchÃ© non mi fa ad accedere ai referti  [ASSISTENTE] Se hai problemi ad accedere ai referti, ti consiglio di contattare il servizio di assistenza dedicata compilando i...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (150 chars):
    {"predicted_label": "info_contatti", "confidence": 0.8, "motivation": "Domanda sui contatti per risolvere un problema tecnico di accesso ai referti"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: Domanda sui contatti per risolvere un problema tecnico di accesso ai referti
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   Domanda sui contatti per risolvere un problema tecnico di accesso ai referti
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 5f6998ca8eb489d90cc1cb35e471fa57 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 348
   ğŸ“Š Token totali: 796
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 796 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 348
   ğŸ“Š Token conversazione finale: 348
   ğŸ“Š Token totali: 796
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1176 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2845 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:28.465155
====================================================================================================
ğŸ“‹ Session ID: classify_1756466248
â±ï¸  Processing Time: 0.820s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1176 chars):
   [UTENTE] indirizzo email  [ASSISTENTE] Potresti specificare per quale reparto, servizio o area desideri l'indirizzo email? CosÃ¬ posso aiutarti meglio! [UTENTE] servizio clienti [ASSISTENTE] Per con...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (125 chars):
    {"predicted_label": "info_contatti", "confidence": 0.9, "motivation": "Domanda sui contatti del servizio clienti richiesto"}

ğŸ“Š Parsed Response:
   predicted_label: info_contatti
   confidence: 0.9
   motivation: Domanda sui contatti del servizio clienti richiesto
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda sui contatti del servizio clienti richiesto
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione d9febae1c66d2ea2975ad27c9f3bfd2d classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 162
   ğŸ“Š Token totali: 590
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 590 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 162
   ğŸ“Š Token conversazione finale: 162
   ğŸ“Š Token totali: 590
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 581 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2787 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:29.397677
====================================================================================================
ğŸ“‹ Session ID: classify_1756466249
â±ï¸  Processing Time: 0.828s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (581 chars):
   [UTENTE] ho prenotato una televisita per mercoledi 30 luglio, ma non ho ancora ricevuto indicazioni di come effettuarla [ASSISTENTE] Per ricevere indicazioni su come effettuare la televisita, ti co...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (127 chars):
    {"predicted_label": "info_televisita", "confidence": 0.9, "motivation": "Domanda su come effettuare una televisita prenotata"}

ğŸ“Š Parsed Response:
   predicted_label: info_televisita
   confidence: 0.9
   motivation: Domanda su come effettuare una televisita prenotata
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come effettuare una televisita prenotata
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione d23dce8730320e6298c9f922d40b6a91 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 269
   ğŸ“Š Token totali: 697
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 697 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 269
   ğŸ“Š Token conversazione finale: 269
   ğŸ“Š Token totali: 697
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 964 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2724 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:30.406226
====================================================================================================
ğŸ“‹ Session ID: classify_1756466250
â±ï¸  Processing Time: 0.904s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (964 chars):
   [UTENTE] Mi serve il numero verde di Humanitas [ASSISTENTE] Il numero verde di Humanitas per prenotazioni tramite il Servizio Sanitario Nazionale (SSN) Ã¨ 800 638 638 (da rete fissa). Se chiami da r...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [75 more lines] ...
     Line 79: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (179 chars):
    {"predicted_label": "info_prenotazione", "confidence": 0.9, "motivation": "Richiesta di informazioni sulla prenotazione tramite il numero verde del Servizio Sanitario Nazionale"}

ğŸ“Š Parsed Response:
   predicted_label: info_prenotazione
   confidence: 0.9
   motivation: Richiesta di informazioni sulla prenotazione tramite il numero verde del Servizio Sanitario Nazionale
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Richiesta di informazioni sulla prenotazione tramite il numero verde del Servizio Sanitario Nazionale
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 860ec579669227a3ffbe3b92c98c16a2 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 207
   ğŸ“Š Token totali: 656
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 656 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 207
   ğŸ“Š Token conversazione finale: 207
   ğŸ“Š Token totali: 656
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 645 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2823 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:31.393832
====================================================================================================
ğŸ“‹ Session ID: classify_1756466251
â±ï¸  Processing Time: 0.883s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (645 chars):
   [UTENTE] come posso prenotare visita con assicurazione? [ASSISTENTE] Per prenotare una visita con assicurazione presso l'Istituto Clinico Humanitas, puoi utilizzare i seguenti canali di prenotazion...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (141 chars):
    {"predicted_label": "prenotazione_assicurazione", "confidence": 0.9, "motivation": "Domanda su come prenotare una visita con assicurazione"}

ğŸ“Š Parsed Response:
   predicted_label: prenotazione_assicurazione
   confidence: 0.9
   motivation: Domanda su come prenotare una visita con assicurazione
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come prenotare una visita con assicurazione
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 6c33251780abfc3eecf1461d406c6c01 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 303
   ğŸ“Š Token totali: 752
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 752 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 303
   ğŸ“Š Token conversazione finale: 303
   ğŸ“Š Token totali: 752
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 997 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2703 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:32.243586
====================================================================================================
ğŸ“‹ Session ID: classify_1756466252
â±ï¸  Processing Time: 0.746s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (997 chars):
   [UTENTE] PARCH TEST [ASSISTENTE] Il Patch Test Ã¨ un esame allergologico utilizzato per diagnosticare dermatiti da contatto. Si applicano cerotti contenenti allergeni sulla schiena del paziente per ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (115 chars):
    {"predicted_label": "info_esame", "confidence": 0.9, "motivation": "Richiesta di informazioni su un esame medico"}

ğŸ“Š Parsed Response:
   predicted_label: info_esame
   confidence: 0.9
   motivation: Richiesta di informazioni su un esame medico
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Richiesta di informazioni su un esame medico
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione c6800ef736789cf78ea6ab861d6dfa59 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 159
   ğŸ“Š Token totali: 607
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 607 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 159
   ğŸ“Š Token conversazione finale: 159
   ğŸ“Š Token totali: 607
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 548 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2843 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:33.312507
====================================================================================================
ğŸ“‹ Session ID: classify_1756466253
â±ï¸  Processing Time: 0.965s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (548 chars):
   [UTENTE] Buongiorno dovrei prenotare una ecografia alla spalla sx alla Cellini di Torino  [ASSISTENTE] Per prenotare un'ecografia alla spalla sinistra presso Humanitas Cellini di Torino, puoi conta...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (172 chars):
    {"predicted_label": "info_prenotazione", "confidence": 0.9, "motivation": "Domanda su come prenotare un'ecografia alla spalla sinistra presso Humanitas Cellini di Torino"}

ğŸ“Š Parsed Response:
   predicted_label: info_prenotazione
   confidence: 0.9
   motivation: Domanda su come prenotare un'ecografia alla spalla sinistra presso Humanitas Cellini di Torino
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come prenotare un'ecografia alla spalla sinistra presso Humanitas Cellini di Torino
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 64eded28c97e0d7d9fe27ecef113c9fb classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 202
   ğŸ“Š Token totali: 651
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 651 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 202
   ğŸ“Š Token conversazione finale: 202
   ğŸ“Š Token totali: 651
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 630 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2761 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:34.363101
====================================================================================================
ğŸ“‹ Session ID: classify_1756466254
â±ï¸  Processing Time: 0.946s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (630 chars):
   [UTENTE] Ciao Giulia, ho necessitÃ  di prenotare in regime privato una Colangio rm con mezzo di contrasto nei vostri centri di Bergamo o Milano o Monza. [ASSISTENTE] Per prenotare una Colangio RM co...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (162 chars):
    {"predicted_label": "prenotazione_esame", "confidence": 0.9, "motivation": "L'utente ha espresso la necessitÃ  di prenotare un esame specifico in regime privato"}

ğŸ“Š Parsed Response:
   predicted_label: prenotazione_esame
   confidence: 0.9
   motivation: L'utente ha espresso la necessitÃ  di prenotare un esame specifico in regime privato
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente ha espresso la necessitÃ  di prenotare un esame specifico in regime privato
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 4becc56acac69067e57a2f6fa88c21e2 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 487
   ğŸ“Š Token totali: 935
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 935 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 487
   ğŸ“Š Token conversazione finale: 487
   ğŸ“Š Token totali: 935
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1512 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2836 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:35.569815
====================================================================================================
ğŸ“‹ Session ID: classify_1756466255
â±ï¸  Processing Time: 1.102s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1512 chars):
   [UTENTE] Ho bisogno di prenotare una visita con il sistema sanitario regolare  [ASSISTENTE] Per prenotare una visita o un esame tramite il Servizio Sanitario Nazionale (SSN) presso Humanitas, puoi ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [78 more lines] ...
     Line 82: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (204 chars):
    {"predicted_label": "prenotazione", "confidence": 0.9, "motivation": "L'utente ha espresso il desiderio di prenotare una visita o un esame tramite il Servizio Sanitario Nazionale (SSN) presso Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: prenotazione
   confidence: 0.9
   motivation: L'utente ha espresso il desiderio di prenotare una visita o un esame tramite il Servizio Sanitario Nazionale (SSN) presso Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente ha espresso il desiderio di prenotare una visita o un esame tramite il Servizio Sanitario Nazionale (SSN) presso Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 65c084e8b4e262713ee4085a530f25d9 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 147
   ğŸ“Š Token totali: 596
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 596 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 147
   ğŸ“Š Token conversazione finale: 147
   ğŸ“Š Token totali: 596
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 499 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2831 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:36.840533
====================================================================================================
ğŸ“‹ Session ID: classify_1756466256
â±ï¸  Processing Time: 1.167s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (499 chars):
   [UTENTE] Possibile prenotare RX rachide dorsale morfodinamica via murat tramite ssn? [ASSISTENTE] Per prenotare un RX rachide dorsale morfodinamica presso la sede di Via Murat tramite il Servizio S...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (211 chars):
    {"predicted_label": "prenotazione_RX", "confidence": 0.9, "motivation": "Domanda su come prenotare un RX rachide dorsale morfodinamica presso la sede di Via Murat tramite il Servizio Sanitario Nazionale (SSN)"}

ğŸ“Š Parsed Response:
   predicted_label: prenotazione_rx
   confidence: 0.9
   motivation: Domanda su come prenotare un RX rachide dorsale morfodinamica presso la sede di Via Murat tramite il Servizio Sanitario Nazionale (SSN)
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come prenotare un RX rachide dorsale morfodinamica presso la sede di Via Murat tramite il Servizio Sanitario Nazionale (SSN)
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione dffdfb30b5b25aeaa1a97d767c5fa296 classificata tramite LLM diretto (classificazione=unknown)
   ğŸ“ˆ Progresso LLM: 100/166
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 177
   ğŸ“Š Token totali: 626
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 626 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 177
   ğŸ“Š Token conversazione finale: 177
   ğŸ“Š Token totali: 626
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 600 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2774 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:37.702027
====================================================================================================
ğŸ“‹ Session ID: classify_1756466257
â±ï¸  Processing Time: 0.757s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (600 chars):
   [UTENTE] Posso fare una visita endocrinologica con il sistema sanitario nazionale? [ASSISTENTE] SÃ¬, Ã¨ possibile effettuare una visita endocrinologica tramite il Servizio Sanitario Nazionale (SSN) p...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (116 chars):
    {"predicted_label": "info_visita", "confidence": 0.9, "motivation": "Domanda su come effettuare una visita medica"}

ğŸ“Š Parsed Response:
   predicted_label: info_visita
   confidence: 0.9
   motivation: Domanda su come effettuare una visita medica
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come effettuare una visita medica
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 14e443a5f48aa5f5597e959642958639 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 299
   ğŸ“Š Token totali: 747
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 747 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 299
   ğŸ“Š Token conversazione finale: 299
   ğŸ“Š Token totali: 747
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 915 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2849 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:38.947437
====================================================================================================
ğŸ“‹ Session ID: classify_1756466258
â±ï¸  Processing Time: 1.142s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (915 chars):
   [UTENTE] Buongiorno, [ASSISTENTE] Buongiorno! Come posso esserti utile oggi? [UTENTE] Dovendo eseguire 10 sedute di rieducazione motoria alluce piede dx in SSN a fronte di intervento eseguito c/o H...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (210 chars):
    {"predicted_label": "info_rieducazione_motoria", "confidence": 0.9, "motivation": "Domanda su possibilitÃ  di eseguire 10 sedute di rieducazione motoria alluce piede dx al centro ospedaliero Humanitas Rozzano"}

ğŸ“Š Parsed Response:
   predicted_label: info_rieducazione_motoria
   confidence: 0.9
   motivation: Domanda su possibilitÃ  di eseguire 10 sedute di rieducazione motoria alluce piede dx al centro ospedaliero Humanitas Rozzano
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su possibilitÃ  di eseguire 10 sedute di rieducazione motoria alluce piede dx al centro ospedaliero Humanitas Rozzano
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 40c6d5011caf092527fc288d8de50b78 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 388
   ğŸ“Š Token totali: 837
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 837 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 388
   ğŸ“Š Token conversazione finale: 388
   ğŸ“Š Token totali: 837
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1206 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2756 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:39.955509
====================================================================================================
ğŸ“‹ Session ID: classify_1756466259
â±ï¸  Processing Time: 0.904s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1206 chars):
   [UTENTE] Visita strabologica [ASSISTENTE] La visita strabologica Ã¨ parte delle procedure oculistiche e puÃ² includere una valutazione della funzionalitÃ  visiva e della motilitÃ  oculare. Per maggiori...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (152 chars):
    {"predicted_label": "info_prenotazione", "confidence": 0.9, "motivation": "L'utente chiede informazioni sulla prenotazione di una visita strabologica"}

ğŸ“Š Parsed Response:
   predicted_label: info_prenotazione
   confidence: 0.9
   motivation: L'utente chiede informazioni sulla prenotazione di una visita strabologica
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni sulla prenotazione di una visita strabologica
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione f6fbbaad5a312f4e5f5325467d6d0841 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 454
   ğŸ’¬ Token conversazione: 562
   ğŸ“Š Token totali: 1016
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 1016 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 454
   ğŸ“Š Token conversazione originale: 562
   ğŸ“Š Token conversazione finale: 562
   ğŸ“Š Token totali: 1016
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1965 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2866 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:40.911272
====================================================================================================
ğŸ“‹ Session ID: classify_1756466260
â±ï¸  Processing Time: 0.851s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1965 chars):
   [UTENTE] Non riesco a fare lÃ²a registrazione [ASSISTENTE] Per aiutarti con la registrazione, potresti specificare se stai cercando di registrarti a [Humanitas con te](https://www.humanitasconte.it)...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (132 chars):
    {"predicted_label": "registrazione_humanitas", "confidence": 0.9, "motivation": "Domanda riguardante la registrazione a Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: registrazione_humanitas
   confidence: 0.9
   motivation: Domanda riguardante la registrazione a Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda riguardante la registrazione a Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 41d2c1108c1dc4ec8b79a92c1e261246 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 118
   ğŸ“Š Token totali: 546
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 546 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 118
   ğŸ“Š Token conversazione finale: 118
   ğŸ“Š Token totali: 546
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 412 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2662 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:42.060975
====================================================================================================
ğŸ“‹ Session ID: classify_1756466262
â±ï¸  Processing Time: 1.044s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (412 chars):
   [UTENTE] Come calcellarsi dal sito [ASSISTENTE] Per cancellarsi dal sito Humanitas, Ã¨ necessario esercitare il diritto di revoca del consenso al trattamento dei dati personali. Puoi farlo compiland...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (196 chars):
    {"predicted_label": "info_revoca_consenso", "confidence": 0.9, "motivation": "L'utente chiede informazioni su come esercitare il diritto di revoca del consenso al trattamento dei dati personali"}

ğŸ“Š Parsed Response:
   predicted_label: info_revoca_consenso
   confidence: 0.9
   motivation: L'utente chiede informazioni su come esercitare il diritto di revoca del consenso al trattamento dei dati personali
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni su come esercitare il diritto di revoca del consenso al trattamento dei dati personali
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 9e84f316cbc611ae34a033a395658ba7 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 454
   ğŸ’¬ Token conversazione: 384
   ğŸ“Š Token totali: 838
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 838 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 454
   ğŸ“Š Token conversazione originale: 384
   ğŸ“Š Token conversazione finale: 384
   ğŸ“Š Token totali: 838
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1305 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2809 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:42.947447
====================================================================================================
ğŸ“‹ Session ID: classify_1756466262
â±ï¸  Processing Time: 0.782s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1305 chars):
   [UTENTE] Non riesco a impostare la ricezione di notifiche sullâ€™area referti  [ASSISTENTE] Per impostare la ricezione di notifiche sullâ€™area referti di [Humanitas con te](https://www.humanitasconte....

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (139 chars):
    {"predicted_label": "impostazione_notifiche", "confidence": 0.8, "motivation": "Domanda su come impostare le notifiche sull'area referti"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: Domanda su come impostare le notifiche sull'area referti
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come impostare le notifiche sull'area referti
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 92ca00fd7292bdc037db846b706c8b7f classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 174
   ğŸ“Š Token totali: 623
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 623 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 174
   ğŸ“Š Token conversazione finale: 174
   ğŸ“Š Token totali: 623
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 607 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2682 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:43.898094
====================================================================================================
ğŸ“‹ Session ID: classify_1756466263
â±ï¸  Processing Time: 0.845s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (607 chars):
   [UTENTE] Devo registrarmi oer la prima volta [ASSISTENTE] Per registrarti per la prima volta su [Humanitas con te](https://www.humanitasconte.it), puoi seguire questi passaggi:

1. Accedi al sito [...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (149 chars):
    {"predicted_label": "registrazione_portale", "confidence": 0.9, "motivation": "Domanda su come registrarsi al portale Humanitas per la prima volta"}

ğŸ“Š Parsed Response:
   predicted_label: registrazione_portale
   confidence: 0.9
   motivation: Domanda su come registrarsi al portale Humanitas per la prima volta
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come registrarsi al portale Humanitas per la prima volta
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 9a429544a663e9b7b242d510cce0d42b classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 447
   ğŸ’¬ Token conversazione: 2132
   ğŸ“Š Token totali: 2579
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 2579 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 447
   ğŸ“Š Token conversazione originale: 2132
   ğŸ“Š Token conversazione finale: 2132
   ğŸ“Š Token totali: 2579
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 7225 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2806 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:44.958836
====================================================================================================
ğŸ“‹ Session ID: classify_1756466264
â±ï¸  Processing Time: 0.955s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (7225 chars):
   [UTENTE] Ã¨ giusto prenotare come prima visita dermatologica la visita specialistica dermatologica [ASSISTENTE] SÃ¬, Ã¨ corretto prenotare una visita specialistica dermatologica come prima visita derm...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (171 chars):
    {"predicted_label": "prenotazione_specialistica", "confidence": 0.9, "motivation": "La richiesta Ã¨ di prenotare una visita specialistica dermatologica come prima visita"}

ğŸ“Š Parsed Response:
   predicted_label: prenotazione_specialistica
   confidence: 0.9
   motivation: La richiesta Ã¨ di prenotare una visita specialistica dermatologica come prima visita
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   La richiesta Ã¨ di prenotare una visita specialistica dermatologica come prima visita
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 84df953d8033cf4b00d8a60e20d2a5b2 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 147
   ğŸ“Š Token totali: 575
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 575 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 147
   ğŸ“Š Token conversazione finale: 147
   ğŸ“Š Token totali: 575
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 501 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2661 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:46.100998
====================================================================================================
ğŸ“‹ Session ID: classify_1756466266
â±ï¸  Processing Time: 1.037s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (501 chars):
   [UTENTE] Che tipo di preparazione per visita proctologica [ASSISTENTE] Per la visita proctologica non Ã¨ richiesta alcuna preparazione specifica. Ãˆ consigliabile portare con sÃ© eventuali esami effet...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (208 chars):
    {"predicted_label": "info_preparazione_visita", "confidence": 0.9, "motivation": "L'utente chiede informazioni sulla preparazione per una visita proctologica e non Ã¨ richiesta alcuna specifica preparazione"}

ğŸ“Š Parsed Response:
   predicted_label: info_preparazione_visita
   confidence: 0.9
   motivation: L'utente chiede informazioni sulla preparazione per una visita proctologica e non Ã¨ richiesta alcuna specifica preparazione
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni sulla preparazione per una visita proctologica e non Ã¨ richiesta alcuna specifica preparazione
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 99f47c0266917ed542846a39de17c1fc classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 164
   ğŸ“Š Token totali: 612
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 612 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 164
   ğŸ“Š Token conversazione finale: 164
   ğŸ“Š Token totali: 612
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 593 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2853 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:47.431437
====================================================================================================
ğŸ“‹ Session ID: classify_1756466267
â±ï¸  Processing Time: 1.226s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (593 chars):
   [UTENTE] Cosa si intende per impegnativa per il ricovero documentazione clinica riguardante patologie cardiache [ASSISTENTE] L'impegnativa per il ricovero Ã¨ un documento rilasciato dal medico curan...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (248 chars):
    {"predicted_label": "info_ricovero", "confidence": 0.9, "motivation": "L'utente chiede informazioni su un documento rilasciato dal medico curante o da uno specialista che attesta la necessitÃ  di un ricovero ospedaliero per il trattamento o la..."}

ğŸ“Š Parsed Response:
   predicted_label: info_ricovero
   confidence: 0.9
   motivation: L'utente chiede informazioni su un documento rilasciato dal medico curante o da uno specialista che attesta la necessitÃ  di un ricovero ospedaliero per il trattamento o la...
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni su un documento rilasciato dal medico curante o da uno specialista che attesta la necessitÃ  di un ricovero ospedaliero per il trattamento o la...
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione f7b8653ff5e30ae6b6f3d790f2d8a81c classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 103
   ğŸ“Š Token totali: 552
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 552 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 103
   ğŸ“Š Token conversazione finale: 103
   ğŸ“Š Token totali: 552
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 333 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2876 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:48.724812
====================================================================================================
ğŸ“‹ Session ID: classify_1756466268
â±ï¸  Processing Time: 1.189s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (333 chars):
   [UTENTE] Ã¨ obbligatorio portare la prescrizione del medico di base per effettuare i raggi x alla mano sinistra ? [ASSISTENTE] SÃ¬, Ã¨ obbligatorio avere la prescrizione del medico di base per effettu...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (213 chars):
    {"predicted_label": "prenotazione_raggi_x", "confidence": 0.9, "motivation": "L'utente chiede se Ã¨ obbligatorio portare la prescrizione del medico di base per effettuare i raggi X e l'assistente conferma che sÃ¬"}

ğŸ“Š Parsed Response:
   predicted_label: prenotazione_raggi_x
   confidence: 0.9
   motivation: L'utente chiede se Ã¨ obbligatorio portare la prescrizione del medico di base per effettuare i raggi X e l'assistente conferma che sÃ¬
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede se Ã¨ obbligatorio portare la prescrizione del medico di base per effettuare i raggi X e l'assistente conferma che sÃ¬
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 45440004ee590e3df9def7cac5dca162 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 302
   ğŸ“Š Token totali: 751
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 751 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 302
   ğŸ“Š Token conversazione finale: 302
   ğŸ“Š Token totali: 751
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1092 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2769 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:49.745562
====================================================================================================
ğŸ“‹ Session ID: classify_1756466269
â±ï¸  Processing Time: 0.917s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1092 chars):
   [UTENTE] vorrei avere un primo colloquio per inseminazione assistita [ASSISTENTE] SÃ¬, in Humanitas Ã¨ possibile seguire percorsi di fecondazione assistita presso il Fertility Center. Il centro offre...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (180 chars):
    {"predicted_label": "info_fertility_center", "confidence": 0.9, "motivation": "L'utente ha chiesto informazioni sul percorso di fecondazione assistita presso il Fertility Center"}

ğŸ“Š Parsed Response:
   predicted_label: info_fertility_center
   confidence: 0.9
   motivation: L'utente ha chiesto informazioni sul percorso di fecondazione assistita presso il Fertility Center
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente ha chiesto informazioni sul percorso di fecondazione assistita presso il Fertility Center
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione eea2d61d66a2c2af620e74b2d6ba91ed classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 119
   ğŸ“Š Token totali: 547
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 547 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 119
   ğŸ“Š Token conversazione finale: 119
   ğŸ“Š Token totali: 547
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 446 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2702 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:50.795732
====================================================================================================
ğŸ“‹ Session ID: classify_1756466270
â±ï¸  Processing Time: 0.946s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (446 chars):
   [UTENTE] Quando chiude la seminologia ad agosto? [ASSISTENTE] Non ho trovato informazioni specifiche sulla chiusura della seminologia ad agosto nei documenti forniti. Ti consiglio di contattare dir...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (202 chars):
    {"predicted_label": "info_esame", "confidence": 0.8, "motivation": "Domanda su quando si chiude una specifica attivitÃ  o esame (seminologia) non trovando informazioni specifiche nei documenti forniti"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: Domanda su quando si chiude una specifica attivitÃ  o esame (seminologia) non trovando informazioni specifiche nei documenti forniti
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   Domanda su quando si chiude una specifica attivitÃ  o esame (seminologia) non trovando informazioni specifiche nei documenti forniti
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione e920102521862718bc49cef83ad8b62f classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 396
   ğŸ“Š Token totali: 824
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 824 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 396
   ğŸ“Š Token conversazione finale: 396
   ğŸ“Š Token totali: 824
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1212 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2678 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:52.159249
====================================================================================================
ğŸ“‹ Session ID: classify_1756466272
â±ï¸  Processing Time: 1.258s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1212 chars):
   [UTENTE] PMA quali prestazioni? [ASSISTENTE] Le prestazioni di Procreazione Medicalmente Assistita (PMA) offerte presso Humanitas includono:

1. **Tecniche di primo livello**: Inseminazione intraut...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [75 more lines] ...
     Line 79: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (280 chars):
    {"predicted_label": "info_fertility_center", "confidence": 0.9, "motivation": "L'utente chiede informazioni sulle prestazioni di Procreazione Medicalmente Assistita (PMA) offerte presso Humanitas e l'assistente risponde con un elenco delle specialitÃ  che offrono tale servizio."}

ğŸ“Š Parsed Response:
   predicted_label: info_fertility_center
   confidence: 0.9
   motivation: L'utente chiede informazioni sulle prestazioni di Procreazione Medicalmente Assistita (PMA) offerte presso Humanitas e l'assistente risponde con un elenco delle specialitÃ  che offrono tale servizio.
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni sulle prestazioni di Procreazione Medicalmente Assistita (PMA) offerte presso Humanitas e l'assistente risponde con un elenco delle specialitÃ  che offrono tale servizio.
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 1e09f31daf3ca497cd60fc9c75ef8932 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 697
   ğŸ“Š Token totali: 1145
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 1145 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 697
   ğŸ“Š Token conversazione finale: 697
   ğŸ“Š Token totali: 1145
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 2276 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2792 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:53.141512
====================================================================================================
ğŸ“‹ Session ID: classify_1756466273
â±ï¸  Processing Time: 0.878s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (2276 chars):
   [UTENTE] ciao! ho bisogno di informazioni sulla crioconservazione degli ovociti [ASSISTENTE] La crioconservazione degli ovociti Ã¨ una tecnica che consente di preservare la fertilitÃ  congelando gli ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (151 chars):
    {"predicted_label": "info_crioconservazione_ovociti", "confidence": 0.9, "motivation": "Richiesta informazioni sulla crioconservazione degli ovociti"}

ğŸ“Š Parsed Response:
   predicted_label: info_crioconservazione_ovociti
   confidence: 0.9
   motivation: Richiesta informazioni sulla crioconservazione degli ovociti
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Richiesta informazioni sulla crioconservazione degli ovociti
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 9f976dc70d86cd1b739c433c7c852c55 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 447
   ğŸ’¬ Token conversazione: 221
   ğŸ“Š Token totali: 668
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 668 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 447
   ğŸ“Š Token conversazione originale: 221
   ğŸ“Š Token conversazione finale: 221
   ğŸ“Š Token totali: 668
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 771 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2737 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:54.007474
====================================================================================================
ğŸ“‹ Session ID: classify_1756466274
â±ï¸  Processing Time: 0.762s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (771 chars):
   [UTENTE] Ho bisogno di sapere il mio codice ID Humanitas con te [ASSISTENTE] Per recuperare lâ€™ID di [Humanitas con te](https://www.humanitasconte.it), ti consiglio di controllare tra i documenti fo...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (112 chars):
    {"predicted_label": "info_id", "confidence": 0.9, "motivation": "Richiesta di informazioni su un ID specifico"}

ğŸ“Š Parsed Response:
   predicted_label: info_id
   confidence: 0.9
   motivation: Richiesta di informazioni su un ID specifico
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Richiesta di informazioni su un ID specifico
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 5ec8430f050cb759cbb95311e5cd361a classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 197
   ğŸ“Š Token totali: 625
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 625 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 197
   ğŸ“Š Token conversazione finale: 197
   ğŸ“Š Token totali: 625
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 735 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2817 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:55.069046
====================================================================================================
ğŸ“‹ Session ID: classify_1756466275
â±ï¸  Processing Time: 0.958s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (735 chars):
   [UTENTE] Dove trovo il pin personale per la forma electronics dei consensus? [ASSISTENTE] Il PIN personale per accedere alla forma elettronica dei consensi o altre funzionalitÃ  si trova generalment...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (172 chars):
    {"predicted_label": "info_pin_personale", "confidence": 0.9, "motivation": "Richiesta informazioni su dove trovare il PIN personale per la forma elettronica dei consensi"}

ğŸ“Š Parsed Response:
   predicted_label: info_pin_personale
   confidence: 0.9
   motivation: Richiesta informazioni su dove trovare il PIN personale per la forma elettronica dei consensi
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Richiesta informazioni su dove trovare il PIN personale per la forma elettronica dei consensi
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione ec84b8a3b7f5880154514f8bf0b60088 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 274
   ğŸ“Š Token totali: 723
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 723 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 274
   ğŸ“Š Token conversazione finale: 274
   ğŸ“Š Token totali: 723
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 988 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2861 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:56.113864
====================================================================================================
ğŸ“‹ Session ID: classify_1756466276
â±ï¸  Processing Time: 0.940s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (988 chars):
   [UTENTE] ho bisogno di recuperare il mio ID Huawei [ASSISTENTE] Non posso aiutarti con il recupero dell'ID Huawei, in quanto mi occupo esclusivamente di informazioni relative all'Istituto Clinico H...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (175 chars):
    {"predicted_label": "info_ritiro_ID", "confidence": 0.7, "motivation": "Domanda su come recuperare l'ID Huawei, ma non Ã¨ un servizio offerto dall'Istituto Clinico Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.49999999999999994
   motivation: Domanda su come recuperare l'ID Huawei, ma non Ã¨ un servizio offerto dall'Istituto Clinico Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.500
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 50.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come recuperare l'ID Huawei, ma non Ã¨ un servizio offerto dall'Istituto Clinico Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione d25f2544882542290bc1b1de05965b4d classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 447
   ğŸ’¬ Token conversazione: 196
   ğŸ“Š Token totali: 643
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 643 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 447
   ğŸ“Š Token conversazione originale: 196
   ğŸ“Š Token conversazione finale: 196
   ğŸ“Š Token totali: 643
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 716 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2836 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:57.293200
====================================================================================================
ğŸ“‹ Session ID: classify_1756466277
â±ï¸  Processing Time: 1.075s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (716 chars):
   [UTENTE] Dove trovo il mio id humanitas per entrare nell app humanitas con te per consultare la mia cartella clinica?  [ASSISTENTE] Per recuperare lâ€™ID Humanitas con te, controlla tra i documenti f...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (207 chars):
    {"predicted_label": "info_ritiro_referto_cartella_clinica", "confidence": 0.9, "motivation": "Domanda su come recuperare l'ID Humanitas per accedere all'app con il tecnico e consultare la cartella clinica"}

ğŸ“Š Parsed Response:
   predicted_label: info_ritiro_referto_cartella_clinica
   confidence: 0.9
   motivation: Domanda su come recuperare l'ID Humanitas per accedere all'app con il tecnico e consultare la cartella clinica
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come recuperare l'ID Humanitas per accedere all'app con il tecnico e consultare la cartella clinica
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione c370013db9dcc6e9fc9e714a59dfe59d classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 441
   ğŸ“Š Token totali: 889
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 889 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 441
   ğŸ“Š Token conversazione finale: 441
   ğŸ“Š Token totali: 889
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1513 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2862 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:58.314775
====================================================================================================
ğŸ“‹ Session ID: classify_1756466278
â±ï¸  Processing Time: 0.918s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1513 chars):
   [UTENTE] Buongiorno, ho bisogno di recuperare il mio codice ID Humanitas con te per visualizzare il referto di un esame [ASSISTENTE] Per recuperare lâ€™ID Humanitas con te, ti consiglio di controllar...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (166 chars):
    {"predicted_label": "info_ritiro_referto", "confidence": 0.9, "motivation": "Domanda su come recuperare il codice ID Humanitas per visualizzare un referto di esame"}

ğŸ“Š Parsed Response:
   predicted_label: info_ritiro_referto
   confidence: 0.9
   motivation: Domanda su come recuperare il codice ID Humanitas per visualizzare un referto di esame
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come recuperare il codice ID Humanitas per visualizzare un referto di esame
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione fb89dcb4ed12f38b08870e24ae3a4d6c classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 219
   ğŸ“Š Token totali: 667
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 667 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 219
   ğŸ“Š Token conversazione finale: 219
   ğŸ“Š Token totali: 667
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 746 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2763 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:17:59.283780
====================================================================================================
ğŸ“‹ Session ID: classify_1756466279
â±ï¸  Processing Time: 0.865s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (746 chars):
   [UTENTE] Vorrei eseguire il pannello linfocitario mit [ASSISTENTE] Non ho trovato informazioni specifiche sul pannello linfocitario mit nei documenti forniti. Ti consiglio di contattare direttament...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (145 chars):
    {"predicted_label": "info_esame", "confidence": 0.9, "motivation": "Domanda specifica su un esame di laboratorio, il pannello linfocitario mit"}

ğŸ“Š Parsed Response:
   predicted_label: info_esame
   confidence: 0.9
   motivation: Domanda specifica su un esame di laboratorio, il pannello linfocitario mit
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda specifica su un esame di laboratorio, il pannello linfocitario mit
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione dfe4b795457e473d21833549a6e35634 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 202
   ğŸ“Š Token totali: 630
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 630 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 202
   ğŸ“Š Token conversazione finale: 202
   ğŸ“Š Token totali: 630
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 587 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2652 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:00.239714
====================================================================================================
ğŸ“‹ Session ID: classify_1756466280
â±ï¸  Processing Time: 0.852s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (587 chars):
   [UTENTE] E colordoppler [ASSISTENTE] L'ecocolordoppler Ã¨ una metodica non invasiva che permette di visualizzare i principali vasi sanguigni e studiarne il flusso ematico. Ãˆ utile per monitorare pat...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (130 chars):
    {"predicted_label": "info_ecocolordoppler", "confidence": 0.9, "motivation": "L'utente chiede informazioni sull'ecocolordoppler"}

ğŸ“Š Parsed Response:
   predicted_label: info_ecocolordoppler
   confidence: 0.9
   motivation: L'utente chiede informazioni sull'ecocolordoppler
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni sull'ecocolordoppler
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 5eafebf8756bfdb64f2c087c3332429b classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 165
   ğŸ“Š Token totali: 613
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 613 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 165
   ğŸ“Š Token conversazione finale: 165
   ğŸ“Š Token totali: 613
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 511 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2791 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:01.305440
====================================================================================================
ğŸ“‹ Session ID: classify_1756466281
â±ï¸  Processing Time: 0.962s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (511 chars):
   [UTENTE] Vorrei sapere se fate l'esame "ab anti covid", grazie [ASSISTENTE] SÃ¬, Humanitas esegue l'esame per la ricerca degli anticorpi anti SARS-CoV-2 (proteina trimerica) IgG. Puoi consultare le ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (156 chars):
    {"predicted_label": "info_esame", "confidence": 0.9, "motivation": "L'utente chiede informazioni sull'esame 'ab anti covid', che Ã¨ un esame di tipo esame"}

ğŸ“Š Parsed Response:
   predicted_label: info_esame
   confidence: 0.9
   motivation: L'utente chiede informazioni sull'esame 'ab anti covid', che Ã¨ un esame di tipo esame
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni sull'esame 'ab anti covid', che Ã¨ un esame di tipo esame
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione ebe092b7dc8273d4350bab0c1c11e754 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 195
   ğŸ“Š Token totali: 623
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 623 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 195
   ğŸ“Š Token conversazione finale: 195
   ğŸ“Š Token totali: 623
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 632 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2814 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:02.219405
====================================================================================================
ğŸ“‹ Session ID: classify_1756466282
â±ï¸  Processing Time: 0.809s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (632 chars):
   [UTENTE] Buongiorno, durante la visita proctologica viene eseguita anche l'anoscopia? [ASSISTENTE] Durante la visita proctologica, il medico puÃ² decidere di eseguire un'anoscopia se lo ritiene oppo...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (116 chars):
    {"predicted_label": "info_esame", "confidence": 0.9, "motivation": "La domanda riguarda un esame medico specifico"}

ğŸ“Š Parsed Response:
   predicted_label: info_esame
   confidence: 0.9
   motivation: La domanda riguarda un esame medico specifico
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   La domanda riguarda un esame medico specifico
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione aea468d466a643dc7463222fb7c45dae classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 211
   ğŸ“Š Token totali: 659
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 659 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 211
   ğŸ“Š Token conversazione finale: 211
   ğŸ“Š Token totali: 659
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 751 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2851 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:03.262508
====================================================================================================
ğŸ“‹ Session ID: classify_1756466283
â±ï¸  Processing Time: 0.938s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (751 chars):
   [UTENTE] ho bisogno di sapere praticamente quant'Ã¨ il costo check-up completo per una donna sopra i 50 anni che ho visto che viene fatto al Humanitas [ASSISTENTE] Il CheckLab Donna Over 50 Ã¨ un per...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (157 chars):
    {"predicted_label": "info_checkup", "confidence": 0.9, "motivation": "Richiesta di informazioni sui costi del check-up specifico per donne sopra i 50 anni"}

ğŸ“Š Parsed Response:
   predicted_label: info_checkup
   confidence: 0.9
   motivation: Richiesta di informazioni sui costi del check-up specifico per donne sopra i 50 anni
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Richiesta di informazioni sui costi del check-up specifico per donne sopra i 50 anni
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione b659f77b1097d69028e8b74a6a35e8c0 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 1568
   ğŸ“Š Token totali: 2016
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 2016 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 1568
   ğŸ“Š Token conversazione finale: 1568
   ğŸ“Š Token totali: 2016
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 4796 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2827 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:04.193952
====================================================================================================
ğŸ“‹ Session ID: classify_1756466284
â±ï¸  Processing Time: 0.826s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (4796 chars):
   [UTENTE] voreri avere le norme di preparazione per una risonanza al ginocchio [ASSISTENTE] Puoi consultare le norme di preparazione per la risonanza magnetica al ginocchio (con o senza contrasto) t...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (136 chars):
    {"predicted_label": "info_esame", "confidence": 0.9, "motivation": "Domanda su come prepararsi per un esame di risonanza al ginocchio"}

ğŸ“Š Parsed Response:
   predicted_label: info_esame
   confidence: 0.9
   motivation: Domanda su come prepararsi per un esame di risonanza al ginocchio
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come prepararsi per un esame di risonanza al ginocchio
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 24aba746ecff13e30673e932ba4becaf classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 198
   ğŸ“Š Token totali: 646
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 646 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 198
   ğŸ“Š Token conversazione finale: 198
   ğŸ“Š Token totali: 646
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 641 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2707 chars (debug_prompt=False)
ğŸ”§ Creazione MongoClassificationReader per cliente: humanitas
âœ… MongoClassificationReader humanitas creato con collection: humanitas_015007d9-d413-11ef-86a5-96000228e7fe
âœ… Connesso a MongoDB database: classificazioni
ğŸ” Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:05.085511
====================================================================================================
ğŸ“‹ Session ID: classify_1756466285
â±ï¸  Processing Time: 0.785s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (641 chars):
   [UTENTE] Buonasera,vorrei avere informazioni riguardo esame Pet al gallio.Grazie  [ASSISTENTE] L'esame PET con traccianti recettoriali al Gallio (68Ga-DOTATOC) Ã¨ utilizzato principalmente per la di...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (121 chars):
    {"predicted_label": "info_esame", "confidence": 0.9, "motivation": "L'utente chiede informazioni su un esame specifico"}

ğŸ“Š Parsed Response:
   predicted_label: info_esame
   confidence: 0.9
   motivation: L'utente chiede informazioni su un esame specifico
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni su un esame specifico
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 98662d69ca8acd4d1a815bb9dcb91a07 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 125
   ğŸ“Š Token totali: 553
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 553 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 125
   ğŸ“Š Token conversazione finale: 125
   ğŸ“Š Token totali: 553
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 378 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2748 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:06.154812
====================================================================================================
ğŸ“‹ Session ID: classify_1756466286
â±ï¸  Processing Time: 0.963s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (378 chars):
   [UTENTE] Ricerca proteine nelle urine nelle 24 orr [ASSISTENTE] Per la raccolta delle urine delle 24 ore, puoi consultare le norme di preparazione al seguente [link](https://www.humanitas.it/wp-con...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (164 chars):
    {"predicted_label": "info_esame", "confidence": 0.9, "motivation": "L'utente chiede informazioni su come effettuare un esame di proteine nelle urine delle 24 ore"}

ğŸ“Š Parsed Response:
   predicted_label: info_esame
   confidence: 0.9
   motivation: L'utente chiede informazioni su come effettuare un esame di proteine nelle urine delle 24 ore
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni su come effettuare un esame di proteine nelle urine delle 24 ore
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione b337410a23ebc759a922f7e1aca34af5 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 244
   ğŸ“Š Token totali: 672
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 672 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 244
   ğŸ“Š Token conversazione finale: 244
   ğŸ“Š Token totali: 672
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 850 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2751 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:07.146545
====================================================================================================
ğŸ“‹ Session ID: classify_1756466287
â±ï¸  Processing Time: 0.886s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (850 chars):
   [UTENTE] Come ci si prepara per l'eco color doppler [ASSISTENTE] Puoi trovare le norme di preparazione per l'eco color doppler al seguente [link](https://www.humanitas.it/wp-content/uploads/2025/01...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [75 more lines] ...
     Line 79: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (154 chars):
    {"predicted_label": "info_eco_color_doppler", "confidence": 0.9, "motivation": "L'utente chiede informazioni sulla preparazione per l'eco color doppler"}

ğŸ“Š Parsed Response:
   predicted_label: info_eco_color_doppler
   confidence: 0.9
   motivation: L'utente chiede informazioni sulla preparazione per l'eco color doppler
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni sulla preparazione per l'eco color doppler
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 775ddd853471ce144bff70ef718ce26a classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 121
   ğŸ“Š Token totali: 549
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 549 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 121
   ğŸ“Š Token conversazione finale: 121
   ğŸ“Š Token totali: 549
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 353 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2703 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:08.132632
====================================================================================================
ğŸ“‹ Session ID: classify_1756466288
â±ï¸  Processing Time: 0.881s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (353 chars):
   [UTENTE] NORME PREPARAZIONE TC COLON [ASSISTENTE] Puoi trovare le norme di preparazione per la Colonscopia virtuale â€“ TAC Addome inferiore con e senza contrasto al seguente [link](https://www.human...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (162 chars):
    {"predicted_label": "info_preparazione_TC_colon", "confidence": 0.9, "motivation": "L'utente chiede informazioni sulla preparazione per la colonscopia virtuale"}

ğŸ“Š Parsed Response:
   predicted_label: info_preparazione_tc_colon
   confidence: 0.9
   motivation: L'utente chiede informazioni sulla preparazione per la colonscopia virtuale
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni sulla preparazione per la colonscopia virtuale
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione dd96df884bfbb3b8d2e8a8cbe9187ff2 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 176
   ğŸ“Š Token totali: 625
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 625 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 176
   ğŸ“Š Token conversazione finale: 176
   ğŸ“Š Token totali: 625
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 644 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2875 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:09.128243
====================================================================================================
ğŸ“‹ Session ID: classify_1756466289
â±ï¸  Processing Time: 0.891s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (644 chars):
   [UTENTE] Devo modificare il numero di cellulare  [ASSISTENTE] Per modificare il numero di cellulare associato al tuo account o ai tuoi dati presso Humanitas, ti consiglio di accedere al portale [Hu...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (137 chars):
    {"predicted_label": "cambio_anagrafica", "confidence": 0.9, "motivation": "Domanda su come modificare il numero di cellulare richiesto"}

ğŸ“Š Parsed Response:
   predicted_label: cambio_anagrafica
   confidence: 0.9
   motivation: Domanda su come modificare il numero di cellulare richiesto
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come modificare il numero di cellulare richiesto
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione d7db4d98215dd878f73246f9963ea65b classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 452
   ğŸ’¬ Token conversazione: 93
   ğŸ“Š Token totali: 545
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 545 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 452
   ğŸ“Š Token conversazione originale: 93
   ğŸ“Š Token conversazione finale: 93
   ğŸ“Š Token totali: 545
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 322 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2811 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:10.593423
====================================================================================================
ğŸ“‹ Session ID: classify_1756466290
â±ï¸  Processing Time: 1.361s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (322 chars):
   [UTENTE] Hanno sbagliato il mio numero di telefono  [ASSISTENTE] Se il tuo numero di telefono Ã¨ stato registrato in modo errato, ti consiglio di contattare direttamente il servizio di assistenza o ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (277 chars):
    {"predicted_label": "correzione_anagrafica", "confidence": 0.9, "motivation": "L'utente ha richiesto di correggere un errore nella sua anagrafica (numero di telefono) e viene invitato a contattare il servizio di assistenza o il reparto con cui aveva avuto contatti per farlo"}

ğŸ“Š Parsed Response:
   predicted_label: correzione_anagrafica
   confidence: 0.9
   motivation: L'utente ha richiesto di correggere un errore nella sua anagrafica (numero di telefono) e viene invitato a contattare il servizio di assistenza o il reparto con cui aveva avuto contatti per farlo
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente ha richiesto di correggere un errore nella sua anagrafica (numero di telefono) e viene invitato a contattare il servizio di assistenza o il reparto con cui aveva avuto contatti per farlo
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 80a29c235341a523ff7128801a228f4e classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 149
   ğŸ“Š Token totali: 577
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 577 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 149
   ğŸ“Š Token conversazione finale: 149
   ğŸ“Š Token totali: 577
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 530 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2677 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:11.733516
====================================================================================================
ğŸ“‹ Session ID: classify_1756466291
â±ï¸  Processing Time: 1.036s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (530 chars):
   [UTENTE] Come faccio a modificare il mio numero di cellulare sul App area personale  [ASSISTENTE] Per modificare il numero di cellulare nell'App "Humanitas con te", accedi alla tua area personale. ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (195 chars):
    {"predicted_label": "info_modifica_numero_cellulare", "confidence": 0.9, "motivation": "L'utente chiede informazioni su come modificare il proprio numero di cellulare nell'App Humanitas con te"}

ğŸ“Š Parsed Response:
   predicted_label: info_modifica_numero_cellulare
   confidence: 0.9
   motivation: L'utente chiede informazioni su come modificare il proprio numero di cellulare nell'App Humanitas con te
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni su come modificare il proprio numero di cellulare nell'App Humanitas con te
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 7b26d1ea244055476bf8a1c69dbd417b classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 316
   ğŸ“Š Token totali: 765
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 765 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 316
   ğŸ“Š Token conversazione finale: 316
   ğŸ“Š Token totali: 765
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1118 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2876 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:12.737649
====================================================================================================
ğŸ“‹ Session ID: classify_1756466292
â±ï¸  Processing Time: 0.900s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1118 chars):
   [UTENTE] Buona sera Giulia  [ASSISTENTE] Buona sera! Come posso esserti utile? ğŸ˜Š [UTENTE] Allora, devo entrare nella sezione referti, perÃ² non posso piÃ¹ entrare, perchÃ© non ho piÃ¹ il vecchio numero...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (170 chars):
    {"predicted_label": "problema_accesso_portale", "confidence": 0.8, "motivation": "Domanda su difficoltÃ  di accesso al portale con richiesta di cambio numero telefonico"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: Domanda su difficoltÃ  di accesso al portale con richiesta di cambio numero telefonico
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   Domanda su difficoltÃ  di accesso al portale con richiesta di cambio numero telefonico
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 75cf2c1e361ed7ab550fc9e2f17bd5d4 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 371
   ğŸ“Š Token totali: 819
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 819 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 371
   ğŸ“Š Token conversazione finale: 371
   ğŸ“Š Token totali: 819
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1201 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2637 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:13.695478
====================================================================================================
ğŸ“‹ Session ID: classify_1756466293
â±ï¸  Processing Time: 0.853s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1201 chars):
   [UTENTE] Ciao Giulia, avrei bisogno di inviare via e-mail dei documenti alla dottoressa torracca..mi puoi aiutare? [ASSISTENTE] Per inviare documenti alla dottoressa Torracca, ti consiglio di verif...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (125 chars):
    {"predicted_label": "invio_documenti", "confidence": 0.9, "motivation": "L'utente richiede l'invio di documenti via e-mail"}

ğŸ“Š Parsed Response:
   predicted_label: invio_documenti
   confidence: 0.9
   motivation: L'utente richiede l'invio di documenti via e-mail
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente richiede l'invio di documenti via e-mail
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 0df5a763c83efa8e8be4cbe4101baef3 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 454
   ğŸ’¬ Token conversazione: 113
   ğŸ“Š Token totali: 567
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 567 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 454
   ğŸ“Š Token conversazione originale: 113
   ğŸ“Š Token conversazione finale: 113
   ğŸ“Š Token totali: 567
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 385 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2904 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:14.823887
====================================================================================================
ğŸ“‹ Session ID: classify_1756466294
â±ï¸  Processing Time: 1.025s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (385 chars):
   [UTENTE] Buongiorno, segnalo questo errore nel vostro sito WEB
"Centro di Ficerca" nelle indicazioni/info sulla struttura [ASSISTENTE] Grazie mille per aver segnalato l'errore "Centro di Ficerca" s...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [75 more lines] ...
     Line 79: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (167 chars):
    {"predicted_label": "problema_accesso_portale", "confidence": 0.9, "motivation": "L'utente segnala un errore nel sito web, che Ã¨ una richiesta di accesso al portale"}

ğŸ“Š Parsed Response:
   predicted_label: problema_accesso_portale
   confidence: 0.9
   motivation: L'utente segnala un errore nel sito web, che Ã¨ una richiesta di accesso al portale
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente segnala un errore nel sito web, che Ã¨ una richiesta di accesso al portale
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 1fc70b6b61ce38c08ef758ea103a8bad classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 83
   ğŸ“Š Token totali: 531
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 531 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 83
   ğŸ“Š Token conversazione finale: 83
   ğŸ“Š Token totali: 531
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 293 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2803 chars (debug_prompt=False)
ğŸ”§ Creazione MongoClassificationReader per cliente: alleanza
âœ… MongoClassificationReader alleanza creato con collection: alleanza_a0fd7600-f4f7-11ef-9315-96000228e7fe
âœ… Connesso a MongoDB database: classificazioni

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:15.881257
====================================================================================================
ğŸ“‹ Session ID: classify_1756466295
â±ï¸  Processing Time: 0.953s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (293 chars):
   [UTENTE] Vorrei eliminare e mail di Brevi Rita [ASSISTENTE] Non ho la possibilitÃ  di gestire o eliminare email o dati personali. Ti consiglio di contattare direttamente il servizio di supporto o l'...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (181 chars):
    {"predicted_label": "cambio_anagrafica", "confidence": 0.8, "motivation": "L'utente ha chiesto di eliminare un'email, che Ã¨ una richiesta di cambio delle informazioni anagrafiche"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: L'utente ha chiesto di eliminare un'email, che Ã¨ una richiesta di cambio delle informazioni anagrafiche
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   L'utente ha chiesto di eliminare un'email, che Ã¨ una richiesta di cambio delle informazioni anagrafiche
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ” Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 5cd1f7f6e25ff4fff08483a851c220d2 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 174
   ğŸ“Š Token totali: 622
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 622 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 174
   ğŸ“Š Token conversazione finale: 174
   ğŸ“Š Token totali: 622
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 608 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2765 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:16.703712
====================================================================================================
ğŸ“‹ Session ID: classify_1756466296
â±ï¸  Processing Time: 0.716s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (608 chars):
   [UTENTE] vorrei sapere se vendete stampelle canadesi [ASSISTENTE] Non ho informazioni specifiche sulla vendita di stampelle canadesi presso Humanitas. Ti consiglio di contattare direttamente il cen...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (130 chars):
    {"predicted_label": "info_prodotti", "confidence": 0.7, "motivation": "Domanda sui prodotti venduti presso l'ospedale Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.49999999999999994
   motivation: Domanda sui prodotti venduti presso l'ospedale Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.500
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 50.0%

ğŸ§  Reasoning/Motivation:
   Domanda sui prodotti venduti presso l'ospedale Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione f8e7d7f69ecdad5f8112ede558bca998 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 81
   ğŸ“Š Token totali: 509
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 509 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 81
   ğŸ“Š Token conversazione finale: 81
   ğŸ“Š Token totali: 509
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 309 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2765 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:17.637271
====================================================================================================
ğŸ“‹ Session ID: classify_1756466297
â±ï¸  Processing Time: 0.829s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (309 chars):
   [UTENTE] sto cercando il numero di telefono della dottoressa Federica Carlea [ASSISTENTE] Non ho trovato informazioni specifiche sul numero di telefono della dottoressa Federica Carlea. Ti consigli...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (127 chars):
    {"predicted_label": "info_contatti", "confidence": 0.9, "motivation": "Domanda sui contatti della dottoressa Federica Carlea"}

ğŸ“Š Parsed Response:
   predicted_label: info_contatti
   confidence: 0.9
   motivation: Domanda sui contatti della dottoressa Federica Carlea
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda sui contatti della dottoressa Federica Carlea
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione bcb6e3c5d7f0d11dca926aed5a534c34 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 289
   ğŸ“Š Token totali: 737
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 737 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 289
   ğŸ“Š Token conversazione finale: 289
   ğŸ“Š Token totali: 737
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 940 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2831 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:18.632924
====================================================================================================
ğŸ“‹ Session ID: classify_1756466298
â±ï¸  Processing Time: 0.889s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (940 chars):
   [UTENTE] Buongiorno Giulia sn in lista d'attesa x un intervento di otorinolaringoiatria ma nn ho ricevuto piÃ¹ notizie  [ASSISTENTE] Se sei in lista d'attesa per un intervento, Humanitas ti contatte...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (145 chars):
    {"predicted_label": "info_ricovero", "confidence": 0.9, "motivation": "Domanda su quando e come sarÃ  programmato il ricovero per un intervento"}

ğŸ“Š Parsed Response:
   predicted_label: info_ricovero
   confidence: 0.9
   motivation: Domanda su quando e come sarÃ  programmato il ricovero per un intervento
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su quando e come sarÃ  programmato il ricovero per un intervento
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione d482d6b8f7c0631ae9cb6af9674323c2 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 92
   ğŸ“Š Token totali: 520
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 520 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 92
   ğŸ“Š Token conversazione finale: 92
   ğŸ“Š Token totali: 520
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 286 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2760 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:19.576236
====================================================================================================
ğŸ“‹ Session ID: classify_1756466299
â±ï¸  Processing Time: 0.838s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (286 chars):
   [UTENTE] come posso chiamare caposala centro oetopedico [ASSISTENTE] Per contattare il caposala o il personale del Centro Ortopedico (Ortho Center) di Humanitas, puoi utilizzare il numero di telefo...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (129 chars):
    {"predicted_label": "info_contatti", "confidence": 0.9, "motivation": "Domanda sui contatti del Centro Ortopedico di Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: info_contatti
   confidence: 0.9
   motivation: Domanda sui contatti del Centro Ortopedico di Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda sui contatti del Centro Ortopedico di Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione f1c027c2d70e785afae3a0f24357ab90 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 62
   ğŸ“Š Token totali: 511
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 511 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 62
   ğŸ“Š Token conversazione finale: 62
   ğŸ“Š Token totali: 511
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 201 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2708 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:20.535068
====================================================================================================
ğŸ“‹ Session ID: classify_1756466300
â±ï¸  Processing Time: 0.852s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (201 chars):
   [UTENTE] devo parlare con la farmacia Voglio un po' diretto [ASSISTENTE] Ti consiglio di contattare il centralino al numero 02 82 24 1 per ottenere assistenza e informazioni dettagliate sulla farma...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (171 chars):
    {"predicted_label": "info_contatti", "confidence": 0.8, "motivation": "L'utente chiede di contattare il centralino per ottenere assistenza e informazioni sulla farmacia"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: L'utente chiede di contattare il centralino per ottenere assistenza e informazioni sulla farmacia
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede di contattare il centralino per ottenere assistenza e informazioni sulla farmacia
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 37a62c94665cc224320a62b5a9f990d2 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 134
   ğŸ“Š Token totali: 562
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 562 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 134
   ğŸ“Š Token conversazione finale: 134
   ğŸ“Š Token totali: 562
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 435 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2776 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:21.569360
====================================================================================================
ğŸ“‹ Session ID: classify_1756466301
â±ï¸  Processing Time: 0.929s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (435 chars):
   [UTENTE] Nr telefono x contattare palazzina 2 piano d3 [ASSISTENTE] Potresti specificare quale reparto o servizio desideri contattare nella palazzina 2, piano D3? In questo modo posso aiutarti a tr...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (160 chars):
    {"predicted_label": "info_contatti", "confidence": 0.9, "motivation": "Domanda sui contatti per un determinato reparto o servizio nella palazzina 2, piano D3"}

ğŸ“Š Parsed Response:
   predicted_label: info_contatti
   confidence: 0.9
   motivation: Domanda sui contatti per un determinato reparto o servizio nella palazzina 2, piano D3
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda sui contatti per un determinato reparto o servizio nella palazzina 2, piano D3
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 1e2c991c97eb119de0d72f26a9b3d704 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 206
   ğŸ“Š Token totali: 634
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 634 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 206
   ğŸ“Š Token conversazione finale: 206
   ğŸ“Š Token totali: 634
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 719 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2811 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:22.571870
====================================================================================================
ğŸ“‹ Session ID: classify_1756466302
â±ï¸  Processing Time: 0.897s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (719 chars):
   [UTENTE] Mi hanno contattato per eseguire una TAC con e senza mezzo di contrasto total body e encefalo e mi hanno detto di portare impegnativa del medico curante,ma essendo in Piemonte cambiano i c...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (167 chars):
    {"predicted_label": "info_esame", "confidence": 0.9, "motivation": "Domanda su un esame medico richiesto con codici di prestazione cambiati tra Piemonte e Lombardia"}

ğŸ“Š Parsed Response:
   predicted_label: info_esame
   confidence: 0.9
   motivation: Domanda su un esame medico richiesto con codici di prestazione cambiati tra Piemonte e Lombardia
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su un esame medico richiesto con codici di prestazione cambiati tra Piemonte e Lombardia
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 72538165c569a665b684b8aa9338228f classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 218
   ğŸ“Š Token totali: 646
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 646 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 218
   ğŸ“Š Token conversazione finale: 218
   ğŸ“Š Token totali: 646
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 772 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2674 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:23.430465
====================================================================================================
ğŸ“‹ Session ID: classify_1756466303
â±ï¸  Processing Time: 0.753s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (772 chars):
   [UTENTE] Non riesco a entrare in Humanitas con te [ASSISTENTE] Se non riesci ad accedere a [Humanitas con te](https://www.humanitasconte.it), ti consiglio di verificare di aver inserito correttamen...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [75 more lines] ...
     Line 79: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (117 chars):
    {"predicted_label": "problema_accesso", "confidence": 0.9, "motivation": "DifficoltÃ  di login al portale Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: problema_accesso
   confidence: 0.9
   motivation: DifficoltÃ  di login al portale Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   DifficoltÃ  di login al portale Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione df83d0f914ff37df70d454af9bd18217 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 454
   ğŸ’¬ Token conversazione: 386
   ğŸ“Š Token totali: 840
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 840 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 454
   ğŸ“Š Token conversazione originale: 386
   ğŸ“Š Token conversazione finale: 386
   ğŸ“Š Token totali: 840
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1331 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2885 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:24.437761
====================================================================================================
ğŸ“‹ Session ID: classify_1756466304
â±ï¸  Processing Time: 0.901s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1331 chars):
   [UTENTE] Non riesco a scaricare i referti del prelievo di di ieri [ASSISTENTE] Per aiutarti meglio, potresti dirmi se hai giÃ  verificato che il referto sia disponibile online? Inoltre, potresti spe...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (146 chars):
    {"predicted_label": "problema_accesso_portale", "confidence": 0.9, "motivation": "Domanda su un problema di accesso al portale Humanitas con te"}

ğŸ“Š Parsed Response:
   predicted_label: problema_accesso_portale
   confidence: 0.9
   motivation: Domanda su un problema di accesso al portale Humanitas con te
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su un problema di accesso al portale Humanitas con te
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 874b11ec176f522118ad8bbda2327557 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 614
   ğŸ“Š Token totali: 1062
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 1062 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 614
   ğŸ“Š Token conversazione finale: 614
   ğŸ“Š Token totali: 1062
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 2090 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2794 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:25.503889
====================================================================================================
ğŸ“‹ Session ID: classify_1756466305
â±ï¸  Processing Time: 0.961s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (2090 chars):
   [UTENTE] Buongiorno,ho problemi con la registrazione sull app per i referti online e nonostante ho inserito il mio codice fiscale non mi fa procedere .Come posso fare? [ASSISTENTE] Per risolvere il...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (169 chars):
    {"predicted_label": "problema_registrazione_portale", "confidence": 0.9, "motivation": "Domanda riguardante problemi nella registrazione sull'app per i referti online"}

ğŸ“Š Parsed Response:
   predicted_label: problema_registrazione_portale
   confidence: 0.9
   motivation: Domanda riguardante problemi nella registrazione sull'app per i referti online
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda riguardante problemi nella registrazione sull'app per i referti online
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 0b386d926824b95055bb1aa49c40f511 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 454
   ğŸ’¬ Token conversazione: 252
   ğŸ“Š Token totali: 706
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 706 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 454
   ğŸ“Š Token conversazione originale: 252
   ğŸ“Š Token conversazione finale: 252
   ğŸ“Š Token totali: 706
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 863 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2906 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:26.836688
====================================================================================================
ğŸ“‹ Session ID: classify_1756466306
â±ï¸  Processing Time: 1.228s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (863 chars):
   [UTENTE] DEVO SCARICARE I REFERTI ACCURSIO ROBERTO  CODICE FISCALE CCRRRT59H02E573E  NON RIESCO A REGISTRARMI CON QUESTO CODICE FISCALE [ASSISTENTE] Per scaricare i referti tramite il portale [Huma...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (270 chars):
    {"predicted_label": "info_ritiro_referto_cartella_clinica", "confidence": 0.8, "motivation": "Domanda su come scaricare i referti richiede l'accesso al portale Humanitas con te e il codice fiscale fornito Ã¨ necessario per identificare la cartella clinica del paziente"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: Domanda su come scaricare i referti richiede l'accesso al portale Humanitas con te e il codice fiscale fornito Ã¨ necessario per identificare la cartella clinica del paziente
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come scaricare i referti richiede l'accesso al portale Humanitas con te e il codice fiscale fornito Ã¨ necessario per identificare la cartella clinica del paziente
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione c638a5b6d4546dd719a04c9d86a1dff4 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 454
   ğŸ’¬ Token conversazione: 345
   ğŸ“Š Token totali: 799
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 799 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 454
   ğŸ“Š Token conversazione originale: 345
   ğŸ“Š Token conversazione finale: 345
   ğŸ“Š Token totali: 799
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1202 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2725 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:27.825958
====================================================================================================
ğŸ“‹ Session ID: classify_1756466307
â±ï¸  Processing Time: 0.884s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1202 chars):
   [UTENTE] Non riesco a trovare un referto . Dice che Ã¨ caricato su programma ARIeS.  [ASSISTENTE] Per consultare il referto tramite il programma ARIeS, Ã¨ necessario registrarsi al portale [Humanitas...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (193 chars):
    {"predicted_label": "info_ricerca_report", "confidence": 0.8, "motivation": "Domanda su come trovare un referto indicando nome, cognome, codice fiscale e motivo della richiesta di assistenza"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: Domanda su come trovare un referto indicando nome, cognome, codice fiscale e motivo della richiesta di assistenza
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come trovare un referto indicando nome, cognome, codice fiscale e motivo della richiesta di assistenza
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione cd9a2eefff211630621a6e69e82c9c5d classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 269
   ğŸ“Š Token totali: 697
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 697 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 269
   ğŸ“Š Token conversazione finale: 269
   ğŸ“Š Token totali: 697
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 954 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2716 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:28.806739
====================================================================================================
ğŸ“‹ Session ID: classify_1756466308
â±ï¸  Processing Time: 0.876s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (954 chars):
   [UTENTE] non riesco ad accedere a miei referti [ASSISTENTE] Se non riesci ad accedere ai tuoi referti, ti consiglio di verificare quanto segue:

1. Assicurati di essere registrato a [Humanitas con ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [77 more lines] ...
     Line 81: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (170 chars):
    {"predicted_label": "problema_accesso_portale", "confidence": 0.8, "motivation": "Domanda su come accedere ai propri referti, che richiede un accesso al portale online"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: Domanda su come accedere ai propri referti, che richiede un accesso al portale online
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come accedere ai propri referti, che richiede un accesso al portale online
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione b509f5411d19715cbc0081e5f61f2494 classificata tramite LLM diretto (classificazione=unknown)
   ğŸ“ˆ Progresso LLM: 150/166
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 283
   ğŸ“Š Token totali: 711
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 711 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 283
   ğŸ“Š Token conversazione finale: 283
   ğŸ“Š Token totali: 711
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 986 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2791 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:29.838116
====================================================================================================
ğŸ“‹ Session ID: classify_1756466309
â±ï¸  Processing Time: 0.925s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (986 chars):
   [UTENTE] p [ASSISTENTE] Potresti darmi qualche dettaglio in piÃ¹ su come posso aiutarti? Sono qui per rispondere alle tue domande! [UTENTE] Impossibile accedere all'allegato conferma mia visita per ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (165 chars):
    {"predicted_label": "problema_accesso_allegati", "confidence": 0.9, "motivation": "Domanda su come accedere ad un allegato della visita di ecografia transerettale"}

ğŸ“Š Parsed Response:
   predicted_label: problema_accesso_allegati
   confidence: 0.9
   motivation: Domanda su come accedere ad un allegato della visita di ecografia transerettale
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come accedere ad un allegato della visita di ecografia transerettale
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 8d818708dc983a5a33db1d5c67a63adc classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 452
   ğŸ’¬ Token conversazione: 595
   ğŸ“Š Token totali: 1047
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 1047 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 452
   ğŸ“Š Token conversazione originale: 595
   ğŸ“Š Token conversazione finale: 595
   ğŸ“Š Token totali: 1047
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 2113 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2805 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:30.765288
====================================================================================================
ğŸ“‹ Session ID: classify_1756466310
â±ï¸  Processing Time: 0.821s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (2113 chars):
   [UTENTE] Ho effettuato un esame di laboratorio al centro Humanitas cellini il 27/07/2025. Mi hanno consegnato il foglio per il ritiro referto con su scritto che sarebbe stato disponibile dal 12/08 ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (119 chars):
    {"predicted_label": "info_esame", "confidence": 0.9, "motivation": "Domanda sui risultati di un esame di laboratorio"}

ğŸ“Š Parsed Response:
   predicted_label: info_esame
   confidence: 0.9
   motivation: Domanda sui risultati di un esame di laboratorio
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda sui risultati di un esame di laboratorio
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione e01b9a94584be18bf844cffee0446986 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 454
   ğŸ’¬ Token conversazione: 372
   ğŸ“Š Token totali: 826
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 826 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 454
   ğŸ“Š Token conversazione originale: 372
   ğŸ“Š Token conversazione finale: 372
   ğŸ“Š Token totali: 826
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1236 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2706 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:31.866696
====================================================================================================
ğŸ“‹ Session ID: classify_1756466311
â±ï¸  Processing Time: 0.996s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1236 chars):
   [UTENTE] Buongiorno Giulia, sono giÃ  registrata ad Humanitas.it ed ho giÃ  App, ma non riesco piÃ¹ af [ASSISTENTE] Sembra che tu stia riscontrando un problema con l'accesso o l'utilizzo dell'app Huma...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (206 chars):
    {"predicted_label": "info_registrazione", "confidence": 0.8, "motivation": "L'utente si Ã¨ giÃ  registrato ad Humanitas e chiede ulteriore supporto, quindi la domanda puÃ² essere riferita alla registrazione"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: L'utente si Ã¨ giÃ  registrato ad Humanitas e chiede ulteriore supporto, quindi la domanda puÃ² essere riferita alla registrazione
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   L'utente si Ã¨ giÃ  registrato ad Humanitas e chiede ulteriore supporto, quindi la domanda puÃ² essere riferita alla registrazione
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 968dd21a7e9643528493a4271c8c40c7 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 510
   ğŸ“Š Token totali: 958
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 958 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 510
   ğŸ“Š Token conversazione finale: 510
   ğŸ“Š Token totali: 958
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1755 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2677 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:32.816634
====================================================================================================
ğŸ“‹ Session ID: classify_1756466312
â±ï¸  Processing Time: 0.844s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1755 chars):
   [UTENTE] Non riesco ad accedere ai referti. Il sistema Ã¨ bloccato. [ASSISTENTE] Ti chiedo scusa, adesso non posso risponderti perchÃ© impegnata in un aggiornamento.
Puoi riprovare piÃ¹ tardi? Grazie....

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (136 chars):
    {"predicted_label": "problema_accesso_portale", "confidence": 0.9, "motivation": "Domanda su un problema di accesso al portale online"}

ğŸ“Š Parsed Response:
   predicted_label: problema_accesso_portale
   confidence: 0.9
   motivation: Domanda su un problema di accesso al portale online
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su un problema di accesso al portale online
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 10f27252a6b4d20996adc3b6a9d2168a classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 235
   ğŸ“Š Token totali: 684
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 684 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 235
   ğŸ“Š Token conversazione finale: 235
   ğŸ“Š Token totali: 684
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 825 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2769 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:33.917432
====================================================================================================
ğŸ“‹ Session ID: classify_1756466313
â±ï¸  Processing Time: 0.995s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (825 chars):
   [UTENTE] Ciao ho perso il mio ID per ritirare cartella clinica  [ASSISTENTE] Per recuperare lâ€™ID necessario per accedere a [Humanitas con te](https://www.humanitasconte.it) e ritirare la tua cartel...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (179 chars):
    {"predicted_label": "info_ritiro_referto_cartella_clinica", "confidence": 0.9, "motivation": "Richiesta di informazioni su come recuperare l'ID per ritirare la cartella clinica"}

ğŸ“Š Parsed Response:
   predicted_label: info_ritiro_referto_cartella_clinica
   confidence: 0.9
   motivation: Richiesta di informazioni su come recuperare l'ID per ritirare la cartella clinica
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Richiesta di informazioni su come recuperare l'ID per ritirare la cartella clinica
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 82580dd0ef350a92549fe9dd0965ad16 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 447
   ğŸ’¬ Token conversazione: 205
   ğŸ“Š Token totali: 652
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 652 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 447
   ğŸ“Š Token conversazione originale: 205
   ğŸ“Š Token conversazione finale: 205
   ğŸ“Š Token totali: 652
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 711 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2652 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:34.807574
====================================================================================================
ğŸ“‹ Session ID: classify_1756466314
â±ï¸  Processing Time: 0.784s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (711 chars):
   [UTENTE] Vorrei il referto della risonanza fatta il 25 06 2025. Via Cellini Ti Porcelli Vilma [ASSISTENTE] Per ottenere il referto della risonanza, puoi accedere al portale [Humanitas con te](https...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [76 more lines] ...
     Line 80: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (118 chars):
    {"predicted_label": "info_esame", "confidence": 0.9, "motivation": "Richiesta di informazioni su un esame specifico"}

ğŸ“Š Parsed Response:
   predicted_label: info_esame
   confidence: 0.9
   motivation: Richiesta di informazioni su un esame specifico
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Richiesta di informazioni su un esame specifico
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 98c9a5eb179c84c5e6add022e6415c1f classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 529
   ğŸ“Š Token totali: 957
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 957 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 529
   ğŸ“Š Token conversazione finale: 529
   ğŸ“Š Token totali: 957
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1881 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2621 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:36.083356
====================================================================================================
ğŸ“‹ Session ID: classify_1756466316
â±ï¸  Processing Time: 1.168s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1881 chars):
   [UTENTE] come faccio a veder su humanitas con te la mia cartella clinica? [ASSISTENTE] Per visualizzare la tua cartella clinica su [Humanitas con te](https://www.humanitasconte.it), devi accedere a...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [73 more lines] ...
     Line 77: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (219 chars):
    {"predicted_label": "info_ritiro_referto_cartella_clinica", "confidence": 0.9, "motivation": "L'utente chiede di visualizzare la sua cartella clinica su Humanitas e l'aiuto richiesto Ã¨ quello di sapere come ritirarla"}

ğŸ“Š Parsed Response:
   predicted_label: info_ritiro_referto_cartella_clinica
   confidence: 0.9
   motivation: L'utente chiede di visualizzare la sua cartella clinica su Humanitas e l'aiuto richiesto Ã¨ quello di sapere come ritirarla
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede di visualizzare la sua cartella clinica su Humanitas e l'aiuto richiesto Ã¨ quello di sapere come ritirarla
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 23d103120352f5d0f0a9d88487bb7625 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 411
   ğŸ“Š Token totali: 859
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 859 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 411
   ğŸ“Š Token conversazione finale: 411
   ğŸ“Š Token totali: 859
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1452 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2862 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:37.094440
====================================================================================================
ğŸ“‹ Session ID: classify_1756466317
â±ï¸  Processing Time: 0.906s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1452 chars):
   [UTENTE] Non ho ancora ricevuto la mia cartella clinica  richiesta il 16 maggio 2025 con spedizione  [ASSISTENTE] Per verificare lo stato della spedizione della tua cartella clinica, ho bisogno di ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (150 chars):
    {"predicted_label": "info_ritiro_referto_cartella_clinica", "confidence": 0.9, "motivation": "Domanda su quando e dove ricevere la cartella clinica"}

ğŸ“Š Parsed Response:
   predicted_label: info_ritiro_referto_cartella_clinica
   confidence: 0.9
   motivation: Domanda su quando e dove ricevere la cartella clinica
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su quando e dove ricevere la cartella clinica
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 0e5d67420988db61559af76273e1af69 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 454
   ğŸ’¬ Token conversazione: 236
   ğŸ“Š Token totali: 690
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 690 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 454
   ğŸ“Š Token conversazione originale: 236
   ğŸ“Š Token conversazione finale: 236
   ğŸ“Š Token totali: 690
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 764 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2709 chars (debug_prompt=False)

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:37.962892
====================================================================================================
ğŸ“‹ Session ID: classify_1756466317
â±ï¸  Processing Time: 0.764s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (764 chars):
   [UTENTE] Non riesco a registrarmi su humanitas con te [ASSISTENTE] Per registrarti su [Humanitas con te](https://www.humanitasconte.it), segui questi passaggi:

1. Collegati al sito [Humanitas con ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (140 chars):
    {"predicted_label": "problema_registrazione_portale", "confidence": 0.8, "motivation": "Domanda su come registrarsi sul portale Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: altro
   confidence: 0.6000000000000001
   motivation: Domanda su come registrarsi sul portale Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.600
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come registrarsi sul portale Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 8a6ca01a6282509c195728935666e250 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 430
   ğŸ“Š Token totali: 878
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 878 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 430
   ğŸ“Š Token conversazione finale: 430
   ğŸ“Š Token totali: 878
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1423 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2727 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:38.880421
====================================================================================================
ğŸ“‹ Session ID: classify_1756466318
â±ï¸  Processing Time: 0.811s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1423 chars):
   [UTENTE] Ciao Giulia, come posso registrarmi al vostro portale? [ASSISTENTE] Per registrarti al portale [Humanitas con te](https://www.humanitasconte.it), devi essere maggiorenne e avere a disposiz...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (130 chars):
    {"predicted_label": "registrazione_portale", "confidence": 0.9, "motivation": "Domanda su come registrarsi al portale Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: registrazione_portale
   confidence: 0.9
   motivation: Domanda su come registrarsi al portale Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   Domanda su come registrarsi al portale Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 58b0b8d7c0a74d01c8dc249b39f6d835 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 454
   ğŸ’¬ Token conversazione: 368
   ğŸ“Š Token totali: 822
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 822 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 454
   ğŸ“Š Token conversazione originale: 368
   ğŸ“Š Token conversazione finale: 368
   ğŸ“Š Token totali: 822
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1178 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2782 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:39.843150
====================================================================================================
ğŸ“‹ Session ID: classify_1756466319
â±ï¸  Processing Time: 0.855s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (1178 chars):
   [UTENTE] Non riesco ad accedere ne registrarmi al servizio  [ASSISTENTE] Se riscontri problemi con la registrazione o l'accesso al portale [Humanitas con te](https://www.humanitasconte.it), ti cons...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (132 chars):
    {"predicted_label": "problema_accesso_portale", "confidence": 0.9, "motivation": "DifficoltÃ  di login al portale Humanitas con te"}

ğŸ“Š Parsed Response:
   predicted_label: problema_accesso_portale
   confidence: 0.9
   motivation: DifficoltÃ  di login al portale Humanitas con te
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   DifficoltÃ  di login al portale Humanitas con te
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 040d19bc04bc0edb2207fe1e51bda5f3 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 428
   ğŸ’¬ Token conversazione: 247
   ğŸ“Š Token totali: 675
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 675 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 428
   ğŸ“Š Token conversazione originale: 247
   ğŸ“Š Token conversazione finale: 247
   ğŸ“Š Token totali: 675
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 846 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2692 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:40.861329
====================================================================================================
ğŸ“‹ Session ID: classify_1756466320
â±ï¸  Processing Time: 0.914s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (846 chars):
   [UTENTE] Come mi registro per scaricare la cartella clinica [ASSISTENTE] Per registrarti e scaricare la cartella clinica, segui questi passaggi:

1. Collegati al portale [Humanitas con te](https://...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [75 more lines] ...
     Line 79: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (153 chars):
    {"predicted_label": "info_registrazione_portale", "confidence": 0.9, "motivation": "L'utente chiede come registrarsi per scaricare la cartella clinica"}

ğŸ“Š Parsed Response:
   predicted_label: info_registrazione_portale
   confidence: 0.9
   motivation: L'utente chiede come registrarsi per scaricare la cartella clinica
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede come registrarsi per scaricare la cartella clinica
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione 5fc082077ce4ac1530fca2c218c9e301 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 449
   ğŸ’¬ Token conversazione: 180
   ğŸ“Š Token totali: 629
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 629 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 449
   ğŸ“Š Token conversazione originale: 180
   ğŸ“Š Token conversazione finale: 180
   ğŸ“Š Token totali: 629
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 606 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2764 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:41.942282
====================================================================================================
ğŸ“‹ Session ID: classify_1756466321
â±ï¸  Processing Time: 0.976s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (606 chars):
   [UTENTE] Come avere lo sconto aereo con humanitas [ASSISTENTE] Per ottenere uno sconto sui viaggi aerei con Humanitas, puoi prenotare tramite l'ufficio viaggi dedicato. Ti consiglio di utilizzare i...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
----------------------------------------------------------------------------------------------------
ğŸ“¤ OUTPUT SECTION
--------------------------------------------------
ğŸ” Raw Response (154 chars):
    {"predicted_label": "info_sconto_aereo", "confidence": 0.9, "motivation": "L'utente chiede informazioni su come ottenere uno sconto aereo con Humanitas"}

ğŸ“Š Parsed Response:
   predicted_label: info_sconto_aereo
   confidence: 0.9
   motivation: L'utente chiede informazioni su come ottenere uno sconto aereo con Humanitas
----------------------------------------------------------------------------------------------------
ğŸ“ˆ ANALYSIS SECTION
--------------------------------------------------
ğŸ¯ Confidence Score: 0.900
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 90.0%

ğŸ§  Reasoning/Motivation:
   L'utente chiede informazioni su come ottenere uno sconto aereo con Humanitas
----------------------------------------------------------------------------------------------------
ğŸ” CONTEXT & METADATA
--------------------------------------------------
   model_used: mistral:7b
   cache_hit: False
   context_provided: False
   embedding_validation_enabled: True
   client_name: humanitas
----------------------------------------------------------------------------------------------------
âœ… LLM DEBUG COMPLETED
====================================================================================================

ğŸ¤– LLM DIRECT CLASSIFICATION: Sessione cf675f73ca3f991793d3343827b2e5e0 classificata tramite LLM diretto (classificazione=unknown)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 015007d9-d413-11ef-86a5-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 448
   ğŸ’¬ Token conversazione: 92
   ğŸ“Š Token totali: 540
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 540 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 448
   ğŸ“Š Token conversazione originale: 92
   ğŸ“Š Token conversazione finale: 92
   ğŸ“Š Token totali: 540
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 297 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM mistral:7b - 2785 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa

====================================================================================================
ğŸ¤– LLM DEBUG - CLASSIFICATION | 2025-08-29T11:18:42.972884
====================================================================================================
ğŸ“‹ Session ID: classify_1756466322
â±ï¸  Processing Time: 0.924s
----------------------------------------------------------------------------------------------------
ğŸ“¥ INPUT SECTION
--------------------------------------------------
ğŸ’¬ Original Text (297 chars):
   [UTENTE] sto provando a chiamare l'ufficio prenotazione viaggi ma non mi risponde nessuno [ASSISTENTE] Per contattare l'ufficio viaggi di Humanitas, ti consiglio di inviare una richiesta via email ...

ğŸ¯ Prompt Template:
   
     Line 1: <|system|>
     Line 2: Sei un classificatore esperto per l'ospedale Humanitas con profonda conoscenza del dominio sanitario
     Line 3: 
     ... [74 more lines] ...
     Line 78: <|assistant|>

âš™ï¸  Model Parameters:
   model: mistral:7b
   temperature: 0.1
   max_tokens: 150
   timeout: 300
