ğŸš€ UMAP disponibile per riduzione dimensionale!
ğŸš€ cuML GPU clustering disponibile!
ğŸ’¥ EmbeddingDestroyer inizializzato - Ready to destroy and rebuild!
ğŸ¯ SimpleEmbeddingManager inizializzato
ğŸ›ï¸ Configurazioni AI saranno salvate su DATABASE MySQL
ğŸ›ï¸ AIConfigurationService inizializzato
   ï¿½ Backend: DATABASE MySQL
   ğŸ”‘ OpenAI API Key: âœ… Configurata
ğŸ­ EmbeddingEngineFactory inizializzata
ğŸ¯ EmbeddingManager inizializzato
âœ… Blueprint esempi inizializzato correttamente
ğŸš€ Avvio server Flask - Debug: True
 * Serving Flask app 'server'
 * Debug mode: on
ğŸ” [DEBUG] GET /api/tenants - Avvio richiesta tenant
ğŸ” [DEBUG] Inizializzo MongoClassificationReader...
ğŸ” [DEBUG] Chiamo get_available_tenants()...
Recuperati 22 tenant dalla tabella TAG.tenants
ğŸ” [DEBUG] Recuperati 22 tenant dal database
ğŸ” [DEBUG] Primi 3 tenant: [{'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'nome': 'Alleanza'}, {'tenant_id': '6bc4f06f-742e-11f0-acb8-96000228e7fe', 'nome': 'BluPantheon'}, {'tenant_id': '0f9d6e90-d319-11ef-86a5-96000228e7fe', 'nome': 'Boots'}]
ğŸ” [DEBUG] Invio risposta con 22 tenant
ğŸ”§ Creazione MongoClassificationReader per cliente: humanitas
âœ… MongoClassificationReader humanitas creato con collection: humanitas_015007d9-d413-11ef-86a5-96000228e7fe
âœ… Connesso a MongoDB database: classificazioni
ğŸ” Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
ğŸ” [DEBUG] GET /api/tenants - Avvio richiesta tenant
ğŸ” [DEBUG] Inizializzo MongoClassificationReader...
ğŸ” [DEBUG] Chiamo get_available_tenants()...
Recuperati 22 tenant dalla tabella TAG.tenants
ğŸ” [DEBUG] Recuperati 22 tenant dal database
ğŸ” [DEBUG] Primi 3 tenant: [{'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'nome': 'Alleanza'}, {'tenant_id': '6bc4f06f-742e-11f0-acb8-96000228e7fe', 'nome': 'BluPantheon'}, {'tenant_id': '0f9d6e90-d319-11ef-86a5-96000228e7fe', 'nome': 'Boots'}]
ğŸ” [DEBUG] Invio risposta con 22 tenant
ğŸ” [DEBUG] GET /api/prompts/a0fd7600-f4f7-11ef-9315-96000228e7fe/status - Avvio richiesta
ğŸ” [DEBUG] API: Recupero status prompt per tenant: a0fd7600-f4f7-11ef-9315-96000228e7fe
âœ… [DEBUG] Riconosciuto come tenant_id UUID: a0fd7600-f4f7-11ef-9315-96000228e7fe
ğŸ” [DEBUG] Inizializzo PromptManager...
ğŸ” [DEBUG] Chiamo get_all_prompts_for_tenant(a0fd7600-f4f7-11ef-9315-96000228e7fe)...
ğŸ” [DEBUG] Recuperati 5 prompt dal PromptManager
ğŸ” [DEBUG] Statistiche: 5/5 attivi, 0 inattivi
âœ… [DEBUG] Status calcolato: {'success': True, 'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'tenant_name': 'Alleanza', 'total_prompts': 5, 'active_prompts': 5, 'inactive_prompts': 0, 'last_updated': '2025-08-25T08:54:43', 'status': 'ready', 'canOperate': True, 'requiredPrompts': [{'name': 'System Prompt', 'type': 'system', 'description': 'Prompt di sistema per la classificazione', 'exists': True}, {'name': 'User Template', 'type': 'user', 'description': 'Template per prompt utente', 'exists': True}, {'name': 'Classification Prompt', 'type': 'classification', 'description': 'Prompt per classificazione intelligente', 'exists': False}], 'missingCount': 1}
âœ… [DEBUG] Status prompt per tenant_id a0fd7600-f4f7-11ef-9315-96000228e7fe: 5/5 attivi
ğŸ” [DEBUG] Invio risposta JSON per status prompt
ğŸ” [DEBUG] GET /api/prompts/a0fd7600-f4f7-11ef-9315-96000228e7fe/status - Avvio richiesta
ğŸ” [DEBUG] API: Recupero status prompt per tenant: a0fd7600-f4f7-11ef-9315-96000228e7fe
âœ… [DEBUG] Riconosciuto come tenant_id UUID: a0fd7600-f4f7-11ef-9315-96000228e7fe
ğŸ” [DEBUG] Inizializzo PromptManager...
ğŸ” [DEBUG] Chiamo get_all_prompts_for_tenant(a0fd7600-f4f7-11ef-9315-96000228e7fe)...
ğŸ” [DEBUG] Recuperati 5 prompt dal PromptManager
ğŸ” [DEBUG] Statistiche: 5/5 attivi, 0 inattivi
âœ… [DEBUG] Status calcolato: {'success': True, 'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'tenant_name': 'Alleanza', 'total_prompts': 5, 'active_prompts': 5, 'inactive_prompts': 0, 'last_updated': '2025-08-25T08:54:43', 'status': 'ready', 'canOperate': True, 'requiredPrompts': [{'name': 'System Prompt', 'type': 'system', 'description': 'Prompt di sistema per la classificazione', 'exists': True}, {'name': 'User Template', 'type': 'user', 'description': 'Template per prompt utente', 'exists': True}, {'name': 'Classification Prompt', 'type': 'classification', 'description': 'Prompt per classificazione intelligente', 'exists': False}], 'missingCount': 1}
âœ… [DEBUG] Status prompt per tenant_id a0fd7600-f4f7-11ef-9315-96000228e7fe: 5/5 attivi
ğŸ” [DEBUG] Invio risposta JSON per status prompt
ğŸ”§ Creazione MongoClassificationReader per cliente: humanitas
ğŸ” [DEBUG] GET /api/prompts/015007d9-d413-11ef-86a5-96000228e7fe/status - Avvio richiesta
ğŸ” [DEBUG] API: Recupero status prompt per tenant: 015007d9-d413-11ef-86a5-96000228e7fe
âœ… [DEBUG] Riconosciuto come tenant_id UUID: 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ” [DEBUG] Inizializzo PromptManager...
ğŸ” [DEBUG] Chiamo get_all_prompts_for_tenant(015007d9-d413-11ef-86a5-96000228e7fe)...
ğŸ” [DEBUG] Recuperati 5 prompt dal PromptManager
ğŸ” [DEBUG] Statistiche: 5/5 attivi, 0 inattivi
âœ… [DEBUG] Status calcolato: {'success': True, 'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'total_prompts': 5, 'active_prompts': 5, 'inactive_prompts': 0, 'last_updated': '2025-08-26T15:04:08', 'status': 'ready', 'canOperate': True, 'requiredPrompts': [{'name': 'System Prompt', 'type': 'system', 'description': 'Prompt di sistema per la classificazione', 'exists': True}, {'name': 'User Template', 'type': 'user', 'description': 'Template per prompt utente', 'exists': True}, {'name': 'Classification Prompt', 'type': 'classification', 'description': 'Prompt per classificazione intelligente', 'exists': False}], 'missingCount': 1}
âœ… [DEBUG] Status prompt per tenant_id 015007d9-d413-11ef-86a5-96000228e7fe: 5/5 attivi
ğŸ” [DEBUG] Invio risposta JSON per status prompt
âœ… MongoClassificationReader humanitas creato con collection: humanitas_015007d9-d413-11ef-86a5-96000228e7fe
âœ… Connesso a MongoDB database: classificazioni
ğŸ” Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
ğŸ¯ TRAINING SUPERVISIONATO - Cliente: humanitas
ğŸ“‹ Parametri utente semplificati:
  ï¿½ Max sessioni review: 500
  ğŸ¯ Soglia confidenza: 0.9
  ğŸ”„ Forza review: False
  âš–ï¸  Soglia disagreement: 0.3
ğŸ”§ Inizializzazione pipeline per cliente: humanitas (con lock)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
âœ… Tenant risolto da slug (DB TAG locale): Humanitas (humanitas) UUID=015007d9-d413-11ef-86a5-96000228e7fe
âœ… [CONFIG] Configurazione base caricata da /home/ubuntu/classificatore/Utils/../config.yaml
ğŸ¯ [PIPELINE CLUSTERING CONFIG] Caricati parametri personalizzati per tenant 015007d9-d413-11ef-86a5-96000228e7fe:
   allow_single_cluster: non_definito -> False
   alpha: non_definito -> 0.7
   cluster_selection_epsilon: non_definito -> 0.13
   cluster_selection_method: non_definito -> leaf
   max_cluster_size: non_definito -> 0
   metric: non_definito -> euclidean
   min_cluster_size: 5 -> 21
   min_samples: 3 -> 14
   only_user: non_definito -> False
   umap_metric: non_definito -> cosine
   umap_min_dist: non_definito -> 0.05
   umap_n_components: non_definito -> 100
   umap_n_neighbors: non_definito -> 15
   umap_random_state: non_definito -> 42
   use_umap: non_definito -> True

ğŸš€ [FASE 1: INIZIALIZZAZIONE] Avvio pipeline...
ğŸ¥ [FASE 1: INIZIALIZZAZIONE] Tenant: humanitas
ğŸ¯ [FASE 1: INIZIALIZZAZIONE] Configurazione:
   ğŸ“Š Confidence threshold: 0.7
   ğŸ¤– Auto mode: True
   ğŸ”„ Auto retrain: False
ï¿½ [FASE 1: INIZIALIZZAZIONE] Inizializzazione lettore conversazioni...
ğŸ“– [LETTORE] Schema common: only_user = False (legacy - no tenant_id)
ï¿½ [FASE 1: INIZIALIZZAZIONE] Inizializzazione aggregator...
   ğŸ” Schema: 'humanitas'
   ğŸ†” Tenant ID: '015007d9-d413-11ef-86a5-96000228e7fe'
âœ… [CONFIG] Configurazione base caricata da /home/ubuntu/classificatore/Utils/../config.yaml
âœ… [CONFIG] Config personalizzata tenant 015007d9-d413-11ef-86a5-96000228e7fe: 15 parametri
ğŸ¯ [ONLY_USER] Tenant 015007d9-d413-11ef-86a5-96000228e7fe: False (da config personalizzata)
ğŸ¯ [LETTORE] Tenant 015007d9-d413-11ef-86a5-96000228e7fe: only_user = False (da config tenant)
ğŸ¯ [ONLY_USER] Tenant 015007d9-d413-11ef-86a5-96000228e7fe: False (da config personalizzata)
ğŸ¯ [ONLY_USER] Tenant 015007d9-d413-11ef-86a5-96000228e7fe: False (da config tenant)
ğŸ§  [FASE 1: INIZIALIZZAZIONE] Sistema embedder dinamico (lazy loading)
ğŸ”§ [FASE 1: INIZIALIZZAZIONE] Parametri clustering:
   ğŸ“Š Min cluster size: 21
   ğŸ“Š Min samples: 14
âœ… [CONFIG] Config personalizzata tenant 015007d9-d413-11ef-86a5-96000228e7fe: 15 parametri
ğŸ—‚ï¸  [UMAP] Parametri per tenant 015007d9-d413-11ef-86a5-96000228e7fe:
   use_umap: True
   n_neighbors: 15
   min_dist: 0.05
   n_components: 100
   metric: cosine
ğŸ”§ [FIX DEBUG] Parametri tenant passati a HDBSCANClusterer:
   min_cluster_size: 21
   min_samples: 14
   alpha: 0.7
   cluster_selection_method: leaf
   cluster_selection_epsilon: 0.13
   metric: euclidean
   allow_single_cluster: False
   max_cluster_size: 0
   ğŸ—‚ï¸  use_umap: True
   ğŸ—‚ï¸  umap_n_neighbors: 15
   ğŸ—‚ï¸  umap_min_dist: 0.05
   ğŸ—‚ï¸  umap_n_components: 100
ğŸ¯ [BERTOPIC] Parametri consistenti configurati:
   ğŸ“Š HDBSCAN: 10 parametri
   ğŸ“Š UMAP: 5 parametri
ğŸ”§ HDBSCANClusterer inizializzato:
   min_cluster_size: 21
   min_samples: 14
   metric: euclidean
   cluster_selection_epsilon: 0.13
   ğŸ—‚ï¸  UMAP enabled: True
     ğŸ“ n_neighbors: 15
     ğŸ“ min_dist: 0.05
     ğŸ“Š n_components: 100
     ğŸ¯ metric: cosine
   ğŸš€ GPU enabled: True
   ğŸ’¾ GPU memory limit: 80%
   ğŸ”„ CPU fallback: True
   âš ï¸  [GPU MODE] Limitazioni cuML HDBSCAN:
     ğŸš« leaf_size=40 sarÃ  IGNORATO su GPU
     âœ… Parametri supportati: cluster_selection_method, alpha, allow_single_cluster
ğŸ¯ [DEBUG REACT] Parametri configurati:
   cluster_selection_method: leaf
   alpha: 0.7
   allow_single_cluster: False
ğŸ§  Inizializzazione memoria semantica...
ğŸ”§ TokenizationManager inizializzato:
   ğŸ“Š Modello tokenizer: cl100k_base
   ğŸ”¢ Limite massimo token: 8000
   âœ‚ï¸  Strategia troncamento: start
âœ… TokenizationManager integrato in LaBSE per gestione conversazioni lunghe
ğŸš€ Inizializzazione LaBSE embedder su device: cuda
ğŸ“¥ Caricamento modello sentence-transformers/LaBSE...
ğŸš€ Caricamento diretto su GPU...
âœ… Modello caricato con successo!
ğŸ“Š Dimensione embedding: 768
ğŸ”§ Device: cuda
ğŸ® GPU: NVIDIA A10G
ğŸ’¾ GPU Memory: 23.7 GB
ğŸ“ˆ GPU Memory utilizzata: 1.89 GB
ï¿½ Primo parametro su device: cuda:0
ğŸ§ª Test del modello LaBSE...
ğŸ” Encoding 3 testi con LaBSE su device cuda...

ğŸ” TOKENIZZAZIONE PREVENTIVA LABSE CLUSTERING
============================================================
ğŸ” ELABORAZIONE CONVERSAZIONI PER CLUSTERING
   ğŸ“Š Numero conversazioni: 3
   ğŸ†” Session IDs forniti: No

ğŸ“Š STATISTICHE ELABORAZIONE:
   ğŸ”¢ Conversazioni totali: 3
   âœ‚ï¸  Conversazioni troncate: 0
   ğŸ“ Token originali totali: 20
   ğŸ“ Token finali totali: 20
   ğŸ“Š Range token: 6 - 7
âœ… Tokenizzazione LaBSE completata:
   ğŸ“Š Conversazioni processate: 3
   ğŸ“Š Conversazioni troncate: 0
   ğŸ“Š Token limite configurato: 8000
   âœ… Tutte le conversazioni entro i limiti, nessun troncamento
============================================================
âœ… Embedding generati: shape (3, 768)
âœ… Test modello completato con successo!
   Shape: (3, 768)
   Norme: [0.99999994 1.         1.        ]
   Device: cuda
ğŸ¯ Modello pronto per l'uso!
ğŸ§  SemanticMemoryManager inizializzato
  ğŸ¯ Soglia riutilizzo etichette: 0.8
  ğŸ” Soglia similaritÃ  semantica: 0.8
  ğŸ’¾ Cache path: semantic_cache/humanitas_015007d9_memory
ğŸ”— Inizializzazione ensemble classifier avanzato...
ğŸ” ML Ensemble Debugger inizializzato e ATTIVO
   ğŸ“ Debug file: ./debug_logs/ml_debug.log
ğŸ” ML Ensemble Debugger attivato
ğŸ”§ Tentativo di inizializzazione IntelligentClassifier tramite LLMFactory...
ğŸ§  GPU Memory prima di LLM: 1.8GB/22.1GB (free: 20.3GB)
âœ… Memoria GPU sufficiente, inizializzazione LLM tramite Factory...
ğŸ›ï¸ Configurazioni AI saranno salvate su DATABASE MySQL
ğŸ›ï¸ AIConfigurationService inizializzato
   ï¿½ Backend: DATABASE MySQL
   ğŸ”‘ OpenAI API Key: âœ… Configurata
ğŸ­ LLM Factory inizializzato con cache invalidation intelligente
ğŸ” LLM FACTORY DEBUG: Chiamata ai_config_service.get_tenant_configuration(humanitas) normale...
ğŸ”„ DatabaseAI: ModalitÃ  legacy - risolvo tenant_id humanitas
ğŸ” [DEBUG] Query eseguita per tenant_id: 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ” [DEBUG] Risultato database: {'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'tenant_slug': 'humanitas', 'embedding_engine': 'labse', 'llm_engine': 'mistral:7b', 'embedding_config': None, 'llm_config': None, 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 28, 16, 51, 54)}
ğŸ” [DEBUG AIConfig] db_config ricevuto: {'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'tenant_slug': 'humanitas', 'embedding_engine': 'labse', 'llm_engine': 'mistral:7b', 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 28, 16, 51, 54), 'embedding_config': {}, 'llm_config': {}}
ğŸ” [DEBUG AIConfig] llm_engine nel db_config: mistral:7b
ğŸ¯ LLM FACTORY DEBUG: Modello normale = 'mistral:7b'
ğŸ”§ Creazione LLM classifier mistral:7b per tenant humanitas
ğŸš€ LLM FACTORY DEBUG: Avvio creazione nuovo classifier modello 'mistral:7b'
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
âœ… Tenant risolto da slug (DB TAG locale): Humanitas (humanitas) UUID=015007d9-d413-11ef-86a5-96000228e7fe
ğŸ” LLM Debugger inizializzato e ATTIVO
   ğŸ“ Debug file: ./debug_logs/llm_debug.log
   ğŸ¨ Visual formatting: True
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa
ğŸ”§ TokenizationManager inizializzato:
   ğŸ“Š Modello tokenizer: cl100k_base
   ğŸ”¢ Limite massimo token: 8000
   âœ‚ï¸  Strategia troncamento: start
âœ… LLM FACTORY DEBUG: Nuovo classifier creato: mistral:7b
âœ… LLM Classifier mistral:7b (mistral:7b) creato e cached per tenant humanitas
ğŸ­ LLM classifier ottenuto tramite Factory per tenant humanitas
ğŸ¤– LLM classifier creato automaticamente nell'ensemble: mistral:7b
ğŸ’¡ Possibile fine-tuning per humanitas
ğŸ”— Advanced Ensemble Classifier inizializzato
   ğŸ§  LLM weight: 0.60
   ğŸ¤– ML weight: 0.40
   ğŸ¯ Confidence threshold: 0.7
   ğŸ”„ Adaptive weights: True
   ğŸ‘¤ Disaccordi gestiti da QualityGateEngine
âš ï¸ Nessun modello trovato per tenant 'humanitas' nella directory models/
â¸ï¸ Riaddestramento automatico disabilitato (modalitÃ  supervisione/API)
   ğŸ’¡ Per abilitare, usare auto_retrain=True nell'inizializzazione
âœ… Classificatore LLM disponibile nell'ensemble
ğŸ‘¤ Inizializzazione trainer interattivo...
ğŸ¯ SIMPLE MANAGER: Richiesta embedder per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ“¥ Primo embedder - creazione per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸš€ CREATING FRESH EMBEDDER per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ›ï¸ Configurazioni AI saranno salvate su DATABASE MySQL
ğŸ›ï¸ AIConfigurationService inizializzato
   ï¿½ Backend: DATABASE MySQL
   ğŸ”‘ OpenAI API Key: âœ… Configurata
ğŸ”„ DatabaseAI: ModalitÃ  legacy - risolvo tenant_id 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ”§ FORCE NO CACHE: Bypass cache per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ”¥ FORCE NO CACHE: Bypasso cache e leggo DIRETTAMENTE dal database per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ” [DEBUG] Query eseguita per tenant_id: 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ” [DEBUG] Risultato database: {'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'tenant_slug': 'humanitas', 'embedding_engine': 'labse', 'llm_engine': 'mistral:7b', 'embedding_config': None, 'llm_config': None, 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 28, 16, 51, 54)}
ğŸ” [DEBUG AIConfig] db_config ricevuto: {'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'tenant_slug': 'humanitas', 'embedding_engine': 'labse', 'llm_engine': 'mistral:7b', 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 28, 16, 51, 54), 'embedding_config': {}, 'llm_config': {}}
ğŸ” [DEBUG AIConfig] llm_engine nel db_config: mistral:7b
ğŸ” SIMPLE MANAGER: Engine da DB per 015007d9-d413-11ef-86a5-96000228e7fe = 'labse'
ğŸ¯ Engine configurato: labse
ğŸ”§ DIRECT CREATE: labse
ğŸ”§ TokenizationManager inizializzato:
   ğŸ“Š Modello tokenizer: cl100k_base
   ğŸ”¢ Limite massimo token: 8000
   âœ‚ï¸  Strategia troncamento: start
âœ… TokenizationManager integrato in LaBSE per gestione conversazioni lunghe
ğŸš€ Inizializzazione LaBSE embedder su device: cuda
ğŸ“¥ Caricamento modello sentence-transformers/LaBSE...
ğŸš€ Caricamento diretto su GPU...
âœ… Modello caricato con successo!
ğŸ“Š Dimensione embedding: 768
ğŸ”§ Device: cuda
ğŸ® GPU: NVIDIA A10G
ğŸ’¾ GPU Memory: 23.7 GB
ğŸ“ˆ GPU Memory utilizzata: 3.78 GB
ï¿½ Primo parametro su device: cuda:0
ğŸ§ª Test del modello LaBSE...
ğŸ” Encoding 3 testi con LaBSE su device cuda...

ğŸ” TOKENIZZAZIONE PREVENTIVA LABSE CLUSTERING
============================================================
ğŸ” ELABORAZIONE CONVERSAZIONI PER CLUSTERING
   ğŸ“Š Numero conversazioni: 3
   ğŸ†” Session IDs forniti: No

ğŸ“Š STATISTICHE ELABORAZIONE:
   ğŸ”¢ Conversazioni totali: 3
   âœ‚ï¸  Conversazioni troncate: 0
   ğŸ“ Token originali totali: 20
   ğŸ“ Token finali totali: 20
   ğŸ“Š Range token: 6 - 7
âœ… Tokenizzazione LaBSE completata:
   ğŸ“Š Conversazioni processate: 3
   ğŸ“Š Conversazioni troncate: 0
   ğŸ“Š Token limite configurato: 8000
   âœ… Tutte le conversazioni entro i limiti, nessun troncamento
============================================================
âœ… Embedding generati: shape (3, 768)
âœ… Test modello completato con successo!
   Shape: (3, 768)
   Norme: [0.99999994 1.         1.        ]
   Device: cuda
ğŸ¯ Modello pronto per l'uso!
âœ… FRESH EMBEDDER creato: LaBSEEmbedder per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ§  Inizializzazione dedupplicatore intelligente...
ğŸ’¾ [FASE 1: INIZIALIZZAZIONE] Caricamento memoria semantica...
ğŸ“¦ Memoria semantica caricata da cache (4089 sessioni)
   ğŸ“Š Campioni: 1797
   ğŸ·ï¸ Tag: 250
âœ… [FASE 1: INIZIALIZZAZIONE] Completata in 7.70s
ğŸ¯ [FASE 1: INIZIALIZZAZIONE] Pipeline pronta per l'uso!
âœ… Pipeline humanitas inizializzata
ğŸš€ TRAINING SUPERVISIONATO CON DATASET COMPLETO
  ğŸ“Š Estrazione: TUTTE le discussioni dal database
  ğŸ§© Clustering: Su tutto il dataset disponibile
  ğŸ‘¤ Review umana: Max 500 sessioni rappresentative
ğŸ¯ Confidence threshold aggiornato a: 0.9
ğŸ“ TRAINING SUPERVISIONATO AVANZATO
ï¿½ NUOVA LOGICA:
  ğŸ”„ Estrazione: TUTTE le discussioni dal database
  ğŸ§© Clustering: Su tutto il dataset completo
  ğŸ‘¤ Review umana: Massimo 500 sessioni rappresentative
--------------------------------------------------
ğŸ“Š FASE 1: ESTRAZIONE COMPLETA DATASET

ï¿½ [FASE 2: ESTRAZIONE] Avvio estrazione sessioni...
ğŸ¥ [FASE 2: ESTRAZIONE] Tenant: humanitas
ğŸ“… [FASE 2: ESTRAZIONE] Giorni indietro: 7
ğŸ”„ [FASE 2: ESTRAZIONE] ModalitÃ  COMPLETA attivata
ğŸ¯ [FASE 2: ESTRAZIONE] Ignorando limite - estrazione totale dataset
ï¿½ [FASE 2: ESTRAZIONE] ModalitÃ : COMPLETA
ï¿½ [FASE 2: ESTRAZIONE] Connessione database...
ğŸ“Š [DEBUG ONLY_USER] Estrazione sessioni aggregate dal schema 'humanitas'...
ğŸ¯ [DEBUG ONLY_USER] Parametro only_user = False (tenant_id: 015007d9-d413-11ef-86a5-96000228e7fe)
ğŸ“„ [DEBUG ONLY_USER] Estrazione completa (senza limite)
ğŸ“„ [DEBUG ONLY_USER] Filtraggio standard: messaggi USER e AGENT
ğŸ” [DEBUG ONLY_USER] Esecuzione query per leggere conversazioni dal schema 'humanitas'...
ğŸ¯ [DEBUG ONLY_USER] Parametro only_user = False
ğŸ“‹ [DEBUG ONLY_USER] Filtro applicato: WHERE csm.said_by IN ('USER', 'AGENT')
Connessione al database MySQL stabilita con successo
âœ… [DEBUG ONLY_USER] Query eseguita con successo!
ğŸ“Š [DEBUG ONLY_USER] Totale righe: 21129
ğŸ‘¤ [DEBUG ONLY_USER] Messaggi USER: 10546
ğŸ¤– [DEBUG ONLY_USER] Messaggi AGENT: 10583
âœ… [DEBUG ONLY_USER] Filtro funziona correttamente!
âœ… Trovate 21129 righe da aggregare
ğŸ”„ [DEBUG ONLY_USER] Inizio generazione testo completo per 4215 sessioni
ğŸ” [DEBUG ONLY_USER] Sessione 0008ef4f-c2f4-4f5e-933e-646574f3638c: 3 USER, 3 AGENT
ğŸ“ [DEBUG ONLY_USER] Sessione 0008ef4f-c2f4-4f5e-933e-646574f3638c testo finale:
   [UTENTE] tags: 2
   [ASSISTENTE] tags: 2
   Lunghezza testo: 554 caratteri
ğŸ” [DEBUG ONLY_USER] Sessione 000b61d7-4431-40d2-b83c-9abbb70c98be: 4 USER, 4 AGENT
ğŸ“ [DEBUG ONLY_USER] Sessione 000b61d7-4431-40d2-b83c-9abbb70c98be testo finale:
   [UTENTE] tags: 3
   [ASSISTENTE] tags: 3
   Lunghezza testo: 1133 caratteri
ğŸ” [DEBUG ONLY_USER] Sessione 00160700-ac7f-463d-8fa0-fe57f74a73e6: 4 USER, 4 AGENT
âœ… Aggregate 4215 sessioni uniche
ğŸ”„ Saltati 8430 messaggi di benvenuto (primi 2 per sessione)
ğŸ”„ Sessioni vuote (solo benvenuto): 887
ğŸ“¥ [FASE 2: ESTRAZIONE] Sessioni grezze: 4215
ğŸ” [FASE 2: ESTRAZIONE] Filtraggio sessioni...
ğŸ” Filtraggio sessioni vuote/irrilevanti...
âœ… Filtro completato:
  ğŸ“Š Sessioni originali: 4215
  âŒ Sessioni scartate: 887
  âœ… Sessioni valide: 3328
âœ… [FASE 2: ESTRAZIONE] Completata in 0.59s
ğŸ“Š [FASE 2: ESTRAZIONE] Dataset completo: 3328 sessioni
ğŸ—‘ï¸ [FASE 2: ESTRAZIONE] Filtrate: 887 sessioni vuote/irrilevanti
ğŸ¯ [FASE 2: ESTRAZIONE] Pronte per clustering completo
âœ… Dataset completo: 3328 sessioni totali

ğŸ“Š FASE 2: CLUSTERING COMPLETO

ğŸš€ [FASE 4: CLUSTERING] Avvio clustering intelligente...
ğŸ“Š [FASE 4: CLUSTERING] Dataset: 3328 sessioni
ğŸ¯ [FASE 4: CLUSTERING] ModalitÃ : INTELLIGENTE
ğŸ§  [FASE 4: CLUSTERING] Clustering incrementale (se possibile)...

ğŸš€ [FASE 3: EMBEDDINGS] Avvio generazione embeddings...
ï¿½ [FASE 3: EMBEDDINGS] Dataset: 3328 sessioni
ğŸ“Š [FASE 3: EMBEDDINGS] Caratteristiche testo:
   ğŸ“ Lunghezza media: 1011 caratteri
   ğŸ“ Lunghezza massima: 29104 caratteri
   ğŸ“ Lunghezza minima: 75 caratteri
ğŸ§  [FASE 3: EMBEDDINGS] Generazione embeddings...
ğŸ”„ LAZY LOADING: Caricamento embedder dinamico per tenant 'humanitas'
ğŸ¯ SimpleEmbeddingManager inizializzato
ğŸ”„ SIMPLE MANAGER: Normalizzato 'humanitas' -> '015007d9-d413-11ef-86a5-96000228e7fe'
ğŸ¯ SIMPLE MANAGER: Richiesta embedder per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ“¥ Primo embedder - creazione per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸš€ CREATING FRESH EMBEDDER per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ›ï¸ Configurazioni AI saranno salvate su DATABASE MySQL
ğŸ›ï¸ AIConfigurationService inizializzato
   ï¿½ Backend: DATABASE MySQL
   ğŸ”‘ OpenAI API Key: âœ… Configurata
ğŸ”„ DatabaseAI: ModalitÃ  legacy - risolvo tenant_id 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ”§ FORCE NO CACHE: Bypass cache per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ”¥ FORCE NO CACHE: Bypasso cache e leggo DIRETTAMENTE dal database per tenant 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ” [DEBUG] Query eseguita per tenant_id: 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ” [DEBUG] Risultato database: {'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'tenant_slug': 'humanitas', 'embedding_engine': 'labse', 'llm_engine': 'mistral:7b', 'embedding_config': None, 'llm_config': None, 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 28, 16, 51, 54)}
ğŸ” [DEBUG AIConfig] db_config ricevuto: {'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'tenant_slug': 'humanitas', 'embedding_engine': 'labse', 'llm_engine': 'mistral:7b', 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 28, 16, 51, 54), 'embedding_config': {}, 'llm_config': {}}
ğŸ” [DEBUG AIConfig] llm_engine nel db_config: mistral:7b
ğŸ” SIMPLE MANAGER: Engine da DB per 015007d9-d413-11ef-86a5-96000228e7fe = 'labse'
ğŸ¯ Engine configurato: labse
ğŸ”§ DIRECT CREATE: labse
ğŸ”§ TokenizationManager inizializzato:
   ğŸ“Š Modello tokenizer: cl100k_base
   ğŸ”¢ Limite massimo token: 8000
   âœ‚ï¸  Strategia troncamento: start
âœ… TokenizationManager integrato in LaBSE per gestione conversazioni lunghe
ğŸš€ Inizializzazione LaBSE embedder su device: cuda
ğŸ“¥ Caricamento modello sentence-transformers/LaBSE...
ğŸš€ Caricamento diretto su GPU...
âœ… Modello caricato con successo!
ğŸ“Š Dimensione embedding: 768
ğŸ”§ Device: cuda
ğŸ® GPU: NVIDIA A10G
ğŸ’¾ GPU Memory: 23.7 GB
ğŸ“ˆ GPU Memory utilizzata: 5.67 GB
ï¿½ Primo parametro su device: cuda:0
ğŸ§ª Test del modello LaBSE...
ğŸ” Encoding 3 testi con LaBSE su device cuda...

ğŸ” TOKENIZZAZIONE PREVENTIVA LABSE CLUSTERING
============================================================
ğŸ” ELABORAZIONE CONVERSAZIONI PER CLUSTERING
   ğŸ“Š Numero conversazioni: 3
   ğŸ†” Session IDs forniti: No

ğŸ“Š STATISTICHE ELABORAZIONE:
   ğŸ”¢ Conversazioni totali: 3
   âœ‚ï¸  Conversazioni troncate: 0
   ğŸ“ Token originali totali: 20
   ğŸ“ Token finali totali: 20
   ğŸ“Š Range token: 6 - 7
âœ… Tokenizzazione LaBSE completata:
   ğŸ“Š Conversazioni processate: 3
   ğŸ“Š Conversazioni troncate: 0
   ğŸ“Š Token limite configurato: 8000
   âœ… Tutte le conversazioni entro i limiti, nessun troncamento
============================================================
âœ… Embedding generati: shape (3, 768)
âœ… Test modello completato con successo!
   Shape: (3, 768)
   Norme: [0.99999994 1.         1.        ]
   Device: cuda
ğŸ¯ Modello pronto per l'uso!
âœ… FRESH EMBEDDER creato: LaBSEEmbedder per tenant 015007d9-d413-11ef-86a5-96000228e7fe
âœ… Embedder caricato per tenant UUID 'humanitas': LaBSEEmbedder
ğŸ” Encoding 3328 testi con LaBSE su device cuda...

ğŸ” TOKENIZZAZIONE PREVENTIVA LABSE CLUSTERING
============================================================
ğŸ” ELABORAZIONE CONVERSAZIONI PER CLUSTERING
   ğŸ“Š Numero conversazioni: 3328
   ğŸ†” Session IDs forniti: SÃ¬
âœ‚ï¸  TRONCAMENTO NECESSARIO:
   ğŸ“Š Token originali: 8588
   ğŸ¯ Target token: 8000
   âš¡ Strategia: start
   âœ… Token finali: 8000
   ğŸ“ Caratteri rimossi: 1927
   âœ‚ï¸  Conversazione 3fe6b43b-3d09-4ed4-9002-d8a1f2b64291: 8588 â†’ 8000 token
âœ‚ï¸  TRONCAMENTO NECESSARIO:
   ğŸ“Š Token originali: 8227
   ğŸ¯ Target token: 8000
   âš¡ Strategia: start
   âœ… Token finali: 8000
   ğŸ“ Caratteri rimossi: 710
   âœ‚ï¸  Conversazione dbd64c8d-dcd6-4b19-a8ab-7f3760898dfe: 8227 â†’ 8000 token

ğŸ“Š STATISTICHE ELABORAZIONE:
   ğŸ”¢ Conversazioni totali: 3328
   âœ‚ï¸  Conversazioni troncate: 2
   ğŸ“ Token originali totali: 1,011,590
   ğŸ“ Token finali totali: 1,010,775
   ğŸ“Š Range token: 26 - 8588
   ğŸ’¾ Riduzione totale: 0.1%
âœ… Tokenizzazione LaBSE completata:
   ğŸ“Š Conversazioni processate: 3328
   ğŸ“Š Conversazioni troncate: 2
   ğŸ“Š Token limite configurato: 8000
   âœ‚ï¸  2 conversazioni TRONCATE per rispettare limite token
============================================================
