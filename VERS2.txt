🚀 UMAP disponibile per riduzione dimensionale!
🚀 cuML GPU clustering disponibile!
💥 EmbeddingDestroyer inizializzato - Ready to destroy and rebuild!
🎯 SimpleEmbeddingManager inizializzato
🎛️ Configurazioni AI saranno salvate su DATABASE MySQL
🎛️ AIConfigurationService inizializzato
   � Backend: DATABASE MySQL
   🔑 OpenAI API Key: ✅ Configurata
🏭 EmbeddingEngineFactory inizializzata
🎯 EmbeddingManager inizializzato
✅ Blueprint esempi inizializzato correttamente
🚀 Avvio server Flask - Debug: True
 * Serving Flask app 'server'
 * Debug mode: on
🔍 [DEBUG] GET /api/tenants - Avvio richiesta tenant con oggetti Tenant
🔍 [DEBUG] Chiamo get_available_tenants() per oggetti Tenant...
🏢 Recuperati 22 oggetti Tenant dalla tabella TAG.tenants
🔍 [DEBUG] Recuperati 22 oggetti Tenant dal database
🔍 [DEBUG] Primi 3 tenant convertiti: [{'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'tenant_name': 'Alleanza', 'tenant_slug': 'alleanza', 'is_active': True}, {'tenant_id': '6bc4f06f-742e-11f0-acb8-96000228e7fe', 'tenant_name': 'BluPantheon', 'tenant_slug': 'blupantheon', 'is_active': True}, {'tenant_id': '0f9d6e90-d319-11ef-86a5-96000228e7fe', 'tenant_name': 'Boots', 'tenant_slug': 'boots', 'is_active': True}]
🔍 [DEBUG] Invio risposta con 22 tenant
🔧 Creazione MongoClassificationReader per cliente: 015007d9-d413-11ef-86a5-96000228e7fe
🔍 Risoluzione tenant da UUID: 015007d9-d413-11ef-86a5-96000228e7fe
🔍 [DEBUG] GET /api/tenants - Avvio richiesta tenant con oggetti Tenant
🔍 [DEBUG] Chiamo get_available_tenants() per oggetti Tenant...
🔍 [DEBUG] GET /api/prompts/a0fd7600-f4f7-11ef-9315-96000228e7fe/status - Avvio richiesta
🔍 [DEBUG] API: Recupero status prompt per tenant: a0fd7600-f4f7-11ef-9315-96000228e7fe
✅ [DEBUG] Riconosciuto come tenant_id UUID: a0fd7600-f4f7-11ef-9315-96000228e7fe
🔍 [DEBUG] Inizializzo PromptManager...
🔍 [DEBUG] Chiamo get_all_prompts_for_tenant(a0fd7600-f4f7-11ef-9315-96000228e7fe)...
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
✅ Tenant risolto (DB TAG locale): Humanitas (humanitas) UUID=015007d9-d413-11ef-86a5-96000228e7fe
✅ Tenant risolto: Humanitas (015007d9-d413-11ef-86a5-96000228e7fe)
📊 Collection generata: humanitas_015007d9-d413-11ef-86a5-96000228e7fe per tenant Humanitas
✅ MongoClassificationReader inizializzato per tenant: Humanitas
   📊 Collection: humanitas_015007d9-d413-11ef-86a5-96000228e7fe
   🏢 Database: classificazioni
✅ MongoClassificationReader creato per tenant: Humanitas (humanitas)
📊 Collection generata: humanitas_015007d9-d413-11ef-86a5-96000228e7fe per tenant Humanitas
   📊 Collection: humanitas_015007d9-d413-11ef-86a5-96000228e7fe
✅ Connesso a MongoDB database: classificazioni
📊 Collection generata: humanitas_015007d9-d413-11ef-86a5-96000228e7fe per tenant Humanitas
🔍 Review Queue recuperate 20 sessioni (representatives: True, propagated: True, outliers: True)
🏷️ Recupero etichette per tenant: Humanitas
🏢 Recuperati 22 oggetti Tenant dalla tabella TAG.tenants
🔍 [DEBUG] Recuperati 22 oggetti Tenant dal database
🔍 [DEBUG] Primi 3 tenant convertiti: [{'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'tenant_name': 'Alleanza', 'tenant_slug': 'alleanza', 'is_active': True}, {'tenant_id': '6bc4f06f-742e-11f0-acb8-96000228e7fe', 'tenant_name': 'BluPantheon', 'tenant_slug': 'blupantheon', 'is_active': True}, {'tenant_id': '0f9d6e90-d319-11ef-86a5-96000228e7fe', 'tenant_name': 'Boots', 'tenant_slug': 'boots', 'is_active': True}]
🔍 [DEBUG] Invio risposta con 22 tenant
📊 Calcolo statistiche per tenant: Humanitas
🔍 [DEBUG] Recuperati 5 prompt dal PromptManager
🔍 [DEBUG] Statistiche: 5/5 attivi, 0 inattivi
✅ [DEBUG] Status calcolato: {'success': True, 'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'tenant_name': 'Alleanza', 'total_prompts': 5, 'active_prompts': 5, 'inactive_prompts': 0, 'last_updated': '2025-08-25T08:54:43', 'status': 'ready', 'canOperate': True, 'requiredPrompts': [{'name': 'System Prompt', 'type': 'system', 'description': 'Prompt di sistema per la classificazione', 'exists': True}, {'name': 'User Template', 'type': 'user', 'description': 'Template per prompt utente', 'exists': True}, {'name': 'Classification Prompt', 'type': 'classification', 'description': 'Prompt per classificazione intelligente', 'exists': False}], 'missingCount': 1}
✅ [DEBUG] Status prompt per tenant_id a0fd7600-f4f7-11ef-9315-96000228e7fe: 5/5 attivi
🔍 [DEBUG] Invio risposta JSON per status prompt
🔍 [DEBUG] GET /api/prompts/a0fd7600-f4f7-11ef-9315-96000228e7fe/status - Avvio richiesta
🔍 [DEBUG] API: Recupero status prompt per tenant: a0fd7600-f4f7-11ef-9315-96000228e7fe
✅ [DEBUG] Riconosciuto come tenant_id UUID: a0fd7600-f4f7-11ef-9315-96000228e7fe
🔍 [DEBUG] Inizializzo PromptManager...
🔍 [DEBUG] Chiamo get_all_prompts_for_tenant(a0fd7600-f4f7-11ef-9315-96000228e7fe)...
🔍 [DEBUG] Recuperati 5 prompt dal PromptManager
🔍 [DEBUG] Statistiche: 5/5 attivi, 0 inattivi
✅ [DEBUG] Status calcolato: {'success': True, 'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'tenant_name': 'Alleanza', 'total_prompts': 5, 'active_prompts': 5, 'inactive_prompts': 0, 'last_updated': '2025-08-25T08:54:43', 'status': 'ready', 'canOperate': True, 'requiredPrompts': [{'name': 'System Prompt', 'type': 'system', 'description': 'Prompt di sistema per la classificazione', 'exists': True}, {'name': 'User Template', 'type': 'user', 'description': 'Template per prompt utente', 'exists': True}, {'name': 'Classification Prompt', 'type': 'classification', 'description': 'Prompt per classificazione intelligente', 'exists': False}], 'missingCount': 1}
✅ [DEBUG] Status prompt per tenant_id a0fd7600-f4f7-11ef-9315-96000228e7fe: 5/5 attivi
🔍 [DEBUG] Invio risposta JSON per status prompt
🔍 [DEBUG] GET /api/prompts/16c222a9-f293-11ef-9315-96000228e7fe/status - Avvio richiesta
🔍 [DEBUG] API: Recupero status prompt per tenant: 16c222a9-f293-11ef-9315-96000228e7fe
✅ [DEBUG] Riconosciuto come tenant_id UUID: 16c222a9-f293-11ef-9315-96000228e7fe
🔍 [DEBUG] Inizializzo PromptManager...
🔍 [DEBUG] Chiamo get_all_prompts_for_tenant(16c222a9-f293-11ef-9315-96000228e7fe)...
🔧 Creazione MongoClassificationReader per cliente: 16c222a9-f293-11ef-9315-96000228e7fe
🔍 Risoluzione tenant da UUID: 16c222a9-f293-11ef-9315-96000228e7fe
🔍 [DEBUG] Recuperati 5 prompt dal PromptManager
🔍 [DEBUG] Statistiche: 5/5 attivi, 0 inattivi
✅ [DEBUG] Status calcolato: {'success': True, 'tenant_id': '16c222a9-f293-11ef-9315-96000228e7fe', 'tenant_name': 'Wopta', 'total_prompts': 5, 'active_prompts': 5, 'inactive_prompts': 0, 'last_updated': '2025-08-26T15:04:42', 'status': 'ready', 'canOperate': True, 'requiredPrompts': [{'name': 'System Prompt', 'type': 'system', 'description': 'Prompt di sistema per la classificazione', 'exists': True}, {'name': 'User Template', 'type': 'user', 'description': 'Template per prompt utente', 'exists': True}, {'name': 'Classification Prompt', 'type': 'classification', 'description': 'Prompt per classificazione intelligente', 'exists': False}], 'missingCount': 1}
✅ [DEBUG] Status prompt per tenant_id 16c222a9-f293-11ef-9315-96000228e7fe: 5/5 attivi
🔍 [DEBUG] Invio risposta JSON per status prompt
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
✅ Tenant risolto (DB TAG locale): Wopta (wopta) UUID=16c222a9-f293-11ef-9315-96000228e7fe
✅ Tenant risolto: Wopta (16c222a9-f293-11ef-9315-96000228e7fe)
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
✅ MongoClassificationReader inizializzato per tenant: Wopta
   📊 Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   🏢 Database: classificazioni
✅ MongoClassificationReader creato per tenant: Wopta (wopta)
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
   📊 Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
✅ Connesso a MongoDB database: classificazioni
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
🔍 Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
🏷️ Recupero etichette per tenant: Wopta
📊 Calcolo statistiche per tenant: Wopta
🎯 TRAINING SUPERVISIONATO - Cliente: 16c222a9-f293-11ef-9315-96000228e7fe
📋 Parametri utente semplificati:
  � Max sessioni review: 500
  🎯 Soglia confidenza: 0.9
  🔄 Forza review: False
  ⚖️  Soglia disagreement: 0.3
🔧 Inizializzazione pipeline per cliente: 16c222a9-f293-11ef-9315-96000228e7fe (con lock)
⚠️ [PIPELINE] DEPRECATO: uso di tenant_slug '16c222a9-f293-11ef-9315-96000228e7fe' - convertendo a oggetto Tenant
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
✅ Tenant risolto (DB TAG locale): Wopta (wopta) UUID=16c222a9-f293-11ef-9315-96000228e7fe
🔄 [PIPELINE] Conversione completata: Wopta (16c222a9-f293-11ef-9315-96000228e7fe)
✅ [CONFIG] Configurazione base caricata da /home/ubuntu/classificatore/Utils/../config.yaml
🎯 [PIPELINE CLUSTERING CONFIG] Caricati parametri personalizzati per tenant 16c222a9-f293-11ef-9315-96000228e7fe:
   allow_single_cluster: non_definito -> False
   alpha: non_definito -> 1
   cluster_selection_epsilon: non_definito -> 0.2
   cluster_selection_method: non_definito -> leaf
   max_cluster_size: non_definito -> 0
   metric: non_definito -> euclidean
   min_cluster_size: 5 -> 5
   min_samples: 3 -> 5
   only_user: non_definito -> False
   umap_metric: non_definito -> cosine
   umap_min_dist: non_definito -> 0.1
   umap_n_components: non_definito -> 17
   umap_n_neighbors: non_definito -> 30
   umap_random_state: non_definito -> 42
   use_umap: non_definito -> True

🚀 [FASE 1: INIZIALIZZAZIONE] Avvio pipeline...
🏥 [FASE 1: INIZIALIZZAZIONE] Tenant: wopta
🎯 [FASE 1: INIZIALIZZAZIONE] Configurazione:
   📊 Confidence threshold: 0.7
   🤖 Auto mode: True
   🔄 Auto retrain: False
� [FASE 1: INIZIALIZZAZIONE] Inizializzazione lettore conversazioni...
✅ [CONFIG] Configurazione base caricata da /home/ubuntu/classificatore/Utils/../config.yaml
✅ [CONFIG] Config personalizzata tenant 16c222a9-f293-11ef-9315-96000228e7fe: 15 parametri
🎯 [ONLY_USER] Tenant 16c222a9-f293-11ef-9315-96000228e7fe: False (da config personalizzata)
🎯 [LETTORE] Tenant 16c222a9-f293-11ef-9315-96000228e7fe: only_user = False (da config tenant)
� [FASE 1: INIZIALIZZAZIONE] Inizializzazione aggregator...
   🔍 Schema: 'wopta'
   🆔 Tenant ID: '16c222a9-f293-11ef-9315-96000228e7fe'
🎯 [SESSION AGGREGATOR] Inizializzazione con oggetto Tenant: Wopta (16c222a9-f293-11ef-9315-96000228e7fe)
🎯 [ONLY_USER] Tenant 16c222a9-f293-11ef-9315-96000228e7fe: False (da config personalizzata)
🎯 [LETTORE] Tenant 16c222a9-f293-11ef-9315-96000228e7fe: only_user = False (da config tenant)
� [ONLY_USER] Schema None: False (legacy - no tenant_id)
🧠 [FASE 1: INIZIALIZZAZIONE] Sistema embedder dinamico (lazy loading)
🔧 [FASE 1: INIZIALIZZAZIONE] Parametri clustering:
   📊 Min cluster size: 5
   📊 Min samples: 5
🐛 DEBUG CLUSTER_ALPHA - PRIMA:
   📋 clustering_config.get('alpha', 1.0): 1
   📋 Type: <class 'int'>
🐛 DEBUG CLUSTER_ALPHA - DOPO CONVERSIONE:
   📋 cluster_alpha: 1.0
   📋 Type: <class 'float'>
🐛 DEBUG CLUSTER_ALPHA - FINALE:
   📋 cluster_alpha finale: 1.0
   📋 Type finale: <class 'float'>
   📋 Alpha > 0: True
✅ [CONFIG] Config personalizzata tenant 16c222a9-f293-11ef-9315-96000228e7fe: 15 parametri
🗂️  [UMAP] Parametri per tenant 16c222a9-f293-11ef-9315-96000228e7fe:
   use_umap: True
   n_neighbors: 30
   min_dist: 0.1
   n_components: 17
   metric: cosine
🔧 [FIX DEBUG] Parametri tenant passati a HDBSCANClusterer:
   min_cluster_size: 5
   min_samples: 5
   alpha: 1.0
   cluster_selection_method: leaf
   cluster_selection_epsilon: 0.2
   metric: euclidean
   allow_single_cluster: False
   max_cluster_size: 0
   🗂️  use_umap: True
   🗂️  umap_n_neighbors: 30
   🗂️  umap_min_dist: 0.1
   🗂️  umap_n_components: 17
🎯 [BERTOPIC] Parametri consistenti configurati:
   📊 HDBSCAN: 10 parametri
   📊 UMAP: 5 parametri
🔧 HDBSCANClusterer inizializzato:
   min_cluster_size: 5
   min_samples: 5
   metric: euclidean
   cluster_selection_epsilon: 0.2
   🗂️  UMAP enabled: True
     📏 n_neighbors: 30
     📐 min_dist: 0.1
     📊 n_components: 17
     🎯 metric: cosine
   🚀 GPU enabled: True
   💾 GPU memory limit: 80%
   🔄 CPU fallback: True
   ⚠️  [GPU MODE] Limitazioni cuML HDBSCAN:
     🚫 leaf_size=40 sarà IGNORATO su GPU
     ✅ Parametri supportati: cluster_selection_method, alpha, allow_single_cluster
🎯 [DEBUG REACT] Parametri configurati:
   cluster_selection_method: leaf
   alpha: 1.0
   allow_single_cluster: False
🧠 Inizializzazione memoria semantica...
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
✅ MongoClassificationReader inizializzato per tenant: Wopta
   📊 Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   🏢 Database: classificazioni
🔧 TokenizationManager inizializzato:
   📊 Modello tokenizer: cl100k_base
   🔢 Limite massimo token: 8000
   ✂️  Strategia troncamento: start
✅ TokenizationManager integrato in LaBSE per gestione conversazioni lunghe
🚀 Inizializzazione LaBSE embedder su device: cuda
📥 Caricamento modello sentence-transformers/LaBSE...
🚀 Caricamento diretto su GPU...
✅ Modello caricato con successo!
📊 Dimensione embedding: 768
🔧 Device: cuda
🎮 GPU: NVIDIA A10G
💾 GPU Memory: 23.7 GB
📈 GPU Memory utilizzata: 1.89 GB
� Primo parametro su device: cuda:0
🧪 Test del modello LaBSE...
🔍 Encoding 3 testi con LaBSE su device cuda...

🔍 TOKENIZZAZIONE PREVENTIVA LABSE CLUSTERING
============================================================
🔍 ELABORAZIONE CONVERSAZIONI PER CLUSTERING
   📊 Numero conversazioni: 3
   🆔 Session IDs forniti: No

📊 STATISTICHE ELABORAZIONE:
   🔢 Conversazioni totali: 3
   ✂️  Conversazioni troncate: 0
   📏 Token originali totali: 20
   📐 Token finali totali: 20
   📊 Range token: 6 - 7
✅ Tokenizzazione LaBSE completata:
   📊 Conversazioni processate: 3
   📊 Conversazioni troncate: 0
   📊 Token limite configurato: 8000
   ✅ Tutte le conversazioni entro i limiti, nessun troncamento
============================================================
✅ Embedding generati: shape (3, 768)
✅ Test modello completato con successo!
   Shape: (3, 768)
   Norme: [0.99999994 1.         1.        ]
   Device: cuda
🎯 Modello pronto per l'uso!
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
✅ MongoClassificationReader inizializzato per tenant: Wopta
   📊 Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   🏢 Database: classificazioni
🧠 SemanticMemoryManager inizializzato
  🎯 Soglia riutilizzo etichette: 0.8
  🔍 Soglia similarità semantica: 0.8
  💾 Cache path: semantic_cache/wopta_16c222a9_memory
🔗 Inizializzazione ensemble classifier avanzato...
🔍 ML Ensemble Debugger inizializzato e ATTIVO
   📝 Debug file: ./debug_logs/ml_debug.log
🔍 ML Ensemble Debugger attivato
🔧 Tentativo di inizializzazione IntelligentClassifier tramite LLMFactory...
🧠 GPU Memory prima di LLM: 1.8GB/22.1GB (free: 20.3GB)
✅ Memoria GPU sufficiente, inizializzazione LLM tramite Factory...
🎛️ Configurazioni AI saranno salvate su DATABASE MySQL
🎛️ AIConfigurationService inizializzato
   � Backend: DATABASE MySQL
   🔑 OpenAI API Key: ✅ Configurata
🏭 LLM Factory inizializzato con cache invalidation intelligente
🔍 LLM FACTORY DEBUG: Chiamata ai_config_service.get_tenant_configuration(wopta) normale...
🔄 DatabaseAI: Modalità legacy - risolvo tenant_id wopta
🔍 [DEBUG] Query eseguita per tenant_id: 16c222a9-f293-11ef-9315-96000228e7fe
🔍 [DEBUG] Risultato database: {'tenant_id': '16c222a9-f293-11ef-9315-96000228e7fe', 'tenant_name': 'Wopta', 'tenant_slug': 'wopta', 'embedding_engine': 'labse', 'llm_engine': 'gpt-oss:20b', 'embedding_config': None, 'llm_config': None, 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 29, 16, 40, 1)}
🔍 [DEBUG AIConfig] db_config ricevuto: {'tenant_id': '16c222a9-f293-11ef-9315-96000228e7fe', 'tenant_name': 'Wopta', 'tenant_slug': 'wopta', 'embedding_engine': 'labse', 'llm_engine': 'gpt-oss:20b', 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 29, 16, 40, 1), 'embedding_config': {}, 'llm_config': {}}
🔍 [DEBUG AIConfig] llm_engine nel db_config: gpt-oss:20b
🎯 LLM FACTORY DEBUG: Modello normale = 'gpt-oss:20b'
🔧 Creazione LLM classifier gpt-oss:20b per tenant wopta
🚀 LLM FACTORY DEBUG: Avvio creazione nuovo classifier modello 'gpt-oss:20b'
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
✅ Tenant risolto da slug (DB TAG locale): Wopta (wopta) UUID=16c222a9-f293-11ef-9315-96000228e7fe
🔍 LLM Debugger inizializzato e ATTIVO
   📝 Debug file: ./debug_logs/llm_debug.log
   🎨 Visual formatting: True
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
✅ MongoClassificationReader inizializzato per tenant: Wopta
   📊 Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   🏢 Database: classificazioni
🗄️ MongoClassificationReader inizializzato per tenant: Wopta
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
✅ MongoClassificationReader inizializzato per tenant: Wopta
   📊 Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   🏢 Database: classificazioni
Connessione al database TAG stabilita con successo
📋 Recuperati 0 tag dal database TAGS per tenant 16c222a9-f293-11ef-9315-96000228e7fe
Connessione al database TAG chiusa
🔧 TokenizationManager inizializzato:
   📊 Modello tokenizer: cl100k_base
   🔢 Limite massimo token: 8000
   ✂️  Strategia troncamento: start
✅ LLM FACTORY DEBUG: Nuovo classifier creato: gpt-oss:20b
✅ LLM Classifier gpt-oss:20b (gpt-oss:20b) creato e cached per tenant wopta
🏭 LLM classifier ottenuto tramite Factory per tenant wopta
🤖 LLM classifier creato automaticamente nell'ensemble: gpt-oss:20b
💡 Possibile fine-tuning per wopta
🔗 Advanced Ensemble Classifier inizializzato
   🧠 LLM weight: 0.60
   🤖 ML weight: 0.40
   🎯 Confidence threshold: 0.7
   🔄 Adaptive weights: True
   👤 Disaccordi gestiti da QualityGateEngine
⚠️ Nessun modello trovato per tenant 'wopta' nella directory models/
⏸️ Riaddestramento automatico disabilitato (modalità supervisione/API)
   💡 Per abilitare, usare auto_retrain=True nell'inizializzazione
✅ Classificatore LLM disponibile nell'ensemble
👤 Inizializzazione trainer interattivo...
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
✅ MongoClassificationReader inizializzato per tenant: Wopta
   📊 Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   🏢 Database: classificazioni
🎯 SIMPLE MANAGER: Richiesta embedder per tenant 16c222a9-f293-11ef-9315-96000228e7fe
📥 Primo embedder - creazione per tenant 16c222a9-f293-11ef-9315-96000228e7fe
🚀 CREATING FRESH EMBEDDER per tenant 16c222a9-f293-11ef-9315-96000228e7fe
🎛️ Configurazioni AI saranno salvate su DATABASE MySQL
🎛️ AIConfigurationService inizializzato
   � Backend: DATABASE MySQL
   🔑 OpenAI API Key: ✅ Configurata
🔄 DatabaseAI: Modalità legacy - risolvo tenant_id 16c222a9-f293-11ef-9315-96000228e7fe
🔧 FORCE NO CACHE: Bypass cache per tenant 16c222a9-f293-11ef-9315-96000228e7fe
🔥 FORCE NO CACHE: Bypasso cache e leggo DIRETTAMENTE dal database per tenant 16c222a9-f293-11ef-9315-96000228e7fe
🔍 [DEBUG] Query eseguita per tenant_id: 16c222a9-f293-11ef-9315-96000228e7fe
🔍 [DEBUG] Risultato database: {'tenant_id': '16c222a9-f293-11ef-9315-96000228e7fe', 'tenant_name': 'Wopta', 'tenant_slug': 'wopta', 'embedding_engine': 'labse', 'llm_engine': 'gpt-oss:20b', 'embedding_config': None, 'llm_config': None, 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 29, 16, 40, 1)}
🔍 [DEBUG AIConfig] db_config ricevuto: {'tenant_id': '16c222a9-f293-11ef-9315-96000228e7fe', 'tenant_name': 'Wopta', 'tenant_slug': 'wopta', 'embedding_engine': 'labse', 'llm_engine': 'gpt-oss:20b', 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 29, 16, 40, 1), 'embedding_config': {}, 'llm_config': {}}
🔍 [DEBUG AIConfig] llm_engine nel db_config: gpt-oss:20b
🔍 SIMPLE MANAGER: Engine da DB per 16c222a9-f293-11ef-9315-96000228e7fe = 'labse'
🎯 Engine configurato: labse
🔧 DIRECT CREATE: labse
🐳 Tentativo connessione a servizio LaBSE dockerizzato...
🔗 LaBSE Remote Client inizializzato
   📡 Service URL: http://localhost:8081
   ⏱️  Timeout: 300s
   🔄 Max retries: 3
   🛡️ Fallback locale: True
🔧 Inizializzazione client remoto LaBSE...
✅ Servizio embedding online e funzionante
✅ Client remoto LaBSE inizializzato con successo
✅ LaBSE Remote Client configurato con successo
✅ FRESH EMBEDDER creato: LaBSERemoteClient per tenant 16c222a9-f293-11ef-9315-96000228e7fe
🧠 Inizializzazione dedupplicatore intelligente...
💾 [FASE 1: INIZIALIZZAZIONE] Caricamento memoria semantica...
🔄 Caricamento memoria semantica dal database...
🔄 Caricamento memoria semantica da MongoDB...
❌ Errore caricamento memoria semantica: MongoClassificationReader.get_all_sessions() got an unexpected keyword argument 'client_name'
📭 Inizializzata memoria semantica vuota
   📊 Campioni: 0
   🏷️ Tag: 0
✅ [FASE 1: INIZIALIZZAZIONE] Completata in 4.66s
🎯 [FASE 1: INIZIALIZZAZIONE] Pipeline pronta per l'uso!
✅ Pipeline 16c222a9-f293-11ef-9315-96000228e7fe inizializzata
🚀 TRAINING SUPERVISIONATO CON DATASET COMPLETO
  📊 Estrazione: TUTTE le discussioni dal database
  🧩 Clustering: Su tutto il dataset disponibile
  👤 Review umana: Max 500 sessioni rappresentative
🎯 Confidence threshold aggiornato a: 0.9
🎓 TRAINING SUPERVISIONATO AVANZATO
� NUOVA LOGICA:
  🔄 Estrazione: TUTTE le discussioni dal database
  🧩 Clustering: Su tutto il dataset completo
  👤 Review umana: Massimo 500 sessioni rappresentative
--------------------------------------------------
📊 FASE 1: ESTRAZIONE COMPLETA DATASET

� [FASE 2: ESTRAZIONE] Avvio estrazione sessioni...
🏥 [FASE 2: ESTRAZIONE] Tenant: wopta
📅 [FASE 2: ESTRAZIONE] Giorni indietro: 7
🔄 [FASE 2: ESTRAZIONE] Modalità COMPLETA attivata
🎯 [FASE 2: ESTRAZIONE] Ignorando limite - estrazione totale dataset
� [FASE 2: ESTRAZIONE] Modalità: COMPLETA
� [FASE 2: ESTRAZIONE] Connessione database...
📊 [DEBUG ONLY_USER] Estrazione sessioni aggregate dal schema 'wopta'...
🎯 [DEBUG ONLY_USER] Parametro only_user = False (tenant_id: 16c222a9-f293-11ef-9315-96000228e7fe)
📄 [DEBUG ONLY_USER] Estrazione completa (senza limite)
📄 [DEBUG ONLY_USER] Filtraggio standard: messaggi USER e AGENT
🔍 [DEBUG ONLY_USER] Esecuzione query per leggere conversazioni dal schema 'wopta'...
🎯 [DEBUG ONLY_USER] Parametro only_user = False
📋 [DEBUG ONLY_USER] Filtro applicato: WHERE csm.said_by IN ('USER', 'AGENT')
Connessione al database MySQL stabilita con successo
✅ [DEBUG ONLY_USER] Query eseguita con successo!
📊 [DEBUG ONLY_USER] Totale righe: 12818
👤 [DEBUG ONLY_USER] Messaggi USER: 6247
🤖 [DEBUG ONLY_USER] Messaggi AGENT: 6571
✅ [DEBUG ONLY_USER] Filtro funziona correttamente!
✅ Trovate 12818 righe da aggregare
🔄 [DEBUG ONLY_USER] Inizio generazione testo completo per 2972 sessioni
🔍 [DEBUG ONLY_USER] Sessione 000ffe7d-c11c-45eb-9ffb-ac29cdedd20d: 1 USER, 1 AGENT
🔍 [DEBUG ONLY_USER] Sessione 00142b8f-f304-48c3-8269-7b9a6281f0e2: 4 USER, 7 AGENT
📝 [DEBUG ONLY_USER] Sessione 00142b8f-f304-48c3-8269-7b9a6281f0e2 testo finale:
   [UTENTE] tags: 3
   [ASSISTENTE] tags: 6
   Lunghezza testo: 1741 caratteri
🔍 [DEBUG ONLY_USER] Sessione 0015d3a2-da00-4682-a567-2463ac8b7a13: 3 USER, 3 AGENT
🚨 SESSIONE CORROTTA RILEVATA: 2a41a0df-1a39-477f-ab6a-a58ba42e45bc
   Lunghezza messaggio: 382,296 caratteri
   Sample: AAAAAAEA//////7//v/+//7//f/6//r/+//6//r/+f/8//7//P/8//z///8AAP//AAAAAAEA/v/9//7//v8AAP//AAD////////+
✅ Aggregate 2972 sessioni uniche
🔄 Saltati 5942 messaggi di benvenuto (primi 2 per sessione)
🔄 Sessioni vuote (solo benvenuto): 1658
🚨 Sessioni corrotte scartate: 1
📥 [FASE 2: ESTRAZIONE] Sessioni grezze: 2972
🔍 [FASE 2: ESTRAZIONE] Filtraggio sessioni...
🔍 Filtraggio sessioni vuote/irrilevanti...
✅ Filtro completato:
  📊 Sessioni originali: 2972
  ❌ Sessioni scartate: 1659
  ✅ Sessioni valide: 1313
✅ [FASE 2: ESTRAZIONE] Completata in 0.40s
📊 [FASE 2: ESTRAZIONE] Dataset completo: 1313 sessioni
🗑️ [FASE 2: ESTRAZIONE] Filtrate: 1659 sessioni vuote/irrilevanti
🎯 [FASE 2: ESTRAZIONE] Pronte per clustering completo
✅ Dataset completo: 1313 sessioni totali

📊 FASE 2: CLUSTERING COMPLETO

🚀 [FASE 4: CLUSTERING] Avvio clustering intelligente...
📊 [FASE 4: CLUSTERING] Dataset: 1313 sessioni
🎯 [FASE 4: CLUSTERING] Modalità: INTELLIGENTE
🧠 [FASE 4: CLUSTERING] Clustering incrementale (se possibile)...

🚀 [FASE 3: EMBEDDINGS] Avvio generazione embeddings...
� [FASE 3: EMBEDDINGS] Dataset: 1313 sessioni
📊 [FASE 3: EMBEDDINGS] Caratteristiche testo:
   📏 Lunghezza media: 694 caratteri
   📏 Lunghezza massima: 18923 caratteri
   📏 Lunghezza minima: 58 caratteri
🧠 [FASE 3: EMBEDDINGS] Generazione embeddings...
🔄 LAZY LOADING: Caricamento embedder dinamico per tenant 'wopta'
🎯 SimpleEmbeddingManager inizializzato
🔄 SIMPLE MANAGER: Normalizzato 'wopta' -> '16c222a9-f293-11ef-9315-96000228e7fe'
🎯 SIMPLE MANAGER: Richiesta embedder per tenant 16c222a9-f293-11ef-9315-96000228e7fe
📥 Primo embedder - creazione per tenant 16c222a9-f293-11ef-9315-96000228e7fe
🚀 CREATING FRESH EMBEDDER per tenant 16c222a9-f293-11ef-9315-96000228e7fe
🎛️ Configurazioni AI saranno salvate su DATABASE MySQL
🎛️ AIConfigurationService inizializzato
   � Backend: DATABASE MySQL
   🔑 OpenAI API Key: ✅ Configurata
🔄 DatabaseAI: Modalità legacy - risolvo tenant_id 16c222a9-f293-11ef-9315-96000228e7fe
🔧 FORCE NO CACHE: Bypass cache per tenant 16c222a9-f293-11ef-9315-96000228e7fe
🔥 FORCE NO CACHE: Bypasso cache e leggo DIRETTAMENTE dal database per tenant 16c222a9-f293-11ef-9315-96000228e7fe
🔍 [DEBUG] Query eseguita per tenant_id: 16c222a9-f293-11ef-9315-96000228e7fe
🔍 [DEBUG] Risultato database: {'tenant_id': '16c222a9-f293-11ef-9315-96000228e7fe', 'tenant_name': 'Wopta', 'tenant_slug': 'wopta', 'embedding_engine': 'labse', 'llm_engine': 'gpt-oss:20b', 'embedding_config': None, 'llm_config': None, 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 29, 16, 40, 1)}
🔍 [DEBUG AIConfig] db_config ricevuto: {'tenant_id': '16c222a9-f293-11ef-9315-96000228e7fe', 'tenant_name': 'Wopta', 'tenant_slug': 'wopta', 'embedding_engine': 'labse', 'llm_engine': 'gpt-oss:20b', 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 29, 16, 40, 1), 'embedding_config': {}, 'llm_config': {}}
🔍 [DEBUG AIConfig] llm_engine nel db_config: gpt-oss:20b
🔍 SIMPLE MANAGER: Engine da DB per 16c222a9-f293-11ef-9315-96000228e7fe = 'labse'
🎯 Engine configurato: labse
🔧 DIRECT CREATE: labse
🐳 Tentativo connessione a servizio LaBSE dockerizzato...
🔗 LaBSE Remote Client inizializzato
   📡 Service URL: http://localhost:8081
   ⏱️  Timeout: 300s
   🔄 Max retries: 3
   🛡️ Fallback locale: True
🔧 Inizializzazione client remoto LaBSE...
✅ Servizio embedding online e funzionante
✅ Client remoto LaBSE inizializzato con successo
✅ LaBSE Remote Client configurato con successo
✅ FRESH EMBEDDER creato: LaBSERemoteClient per tenant 16c222a9-f293-11ef-9315-96000228e7fe
✅ Embedder caricato per tenant UUID 'wopta': LaBSERemoteClient
📡 Richiesta embedding remoto per 1313 testi...
✅ Embedding remoto completato in 56.185s
   📊 Shape: (1313, 768)
   ⚡ Tempo servizio: 54.735s
✅ [FASE 3: EMBEDDINGS] Completata in 56.33s
📈 [FASE 3: EMBEDDINGS] Shape: (1313, 768)
⚡ [FASE 3: EMBEDDINGS] Throughput: 23.3 testi/secondo

📊 FASE 2A: TRAINING BERTOPIC ANTICIPATO

🚀 TRAINING BERTOPIC ANTICIPATO (NUOVO FLUSSO OTTIMIZZATO):
   📊 Dataset completo: 1313 sessioni
   📊 Embeddings shape: (1313, 768)
   🎯 Addestramento su TUTTO il dataset per features ottimali
   🔥 Esecuzione bertopic_provider.fit() su dataset completo...
📊 BERTopic training su 1313 campioni
   🎯 Embedder configurato: LaBSERemoteClient
   🔧 STRATEGIA: BERTopic userà embedder personalizzato via wrapper
   ✅ Wrapper embedder creato per BERTopic
   🔧 BERTopic userà embedder personalizzato interno
✅ BERTopic FIT completato su 1313 campioni
   🔧 SVD Training: Usando embedder personalizzato interno
✅ SVD addestrato su full probas (k=20)
   ✅ BERTopic FIT completato in 16.60 secondi
   🔄 Esecuzione bertopic_provider.transform() per features extraction...
🔧 Transform: BERTopic userà embedder personalizzato interno
   ✅ BERTopic TRANSFORM completato in 1.07 secondi
   📊 Topic probabilities shape: (1313, 20)
   📊 One-hot shape: None
   ✅ BERTopic provider addestrato con successo su 1313 sessioni
   ✅ BERTopic provider disponibile per augmentation features
   🔗 BERTopic model assegnato al trainer per validazione ALTRO

📊 FASE 2B: CLUSTERING HDBSCAN
🧠 Usando clustering INTELLIGENTE (LLM + ML senza pattern)
🗂️  [DEBUG] Caricamento config tenant-specific: /home/ubuntu/classificatore/tenant_configs/16c222a9-f293-11ef-9315-96000228e7fe_clustering.yaml
🗂️  [DEBUG] Config tenant caricato: ['allow_single_cluster', 'alpha', 'cluster_selection_epsilon', 'cluster_selection_method', 'max_cluster_size', 'metric', 'min_cluster_size', 'min_samples', 'only_user', 'umap_metric', 'umap_min_dist', 'umap_n_components', 'umap_n_neighbors', 'umap_random_state', 'use_umap']
🗂️  [DEBUG] UMAP config finale: use_umap=True, n_components=17, min_dist=0.1
🧠 Clustering intelligente configurato:
   🎯 Categorie intent suggerite: 12
   🤖 LLM primario: True
   📊 Min confidence: 0.8
   📈 Min conversations per intent: 2
   👥 Rappresentanti diversificati: True
   🔢 Max rappresentanti per cluster: 5
   🤝 Strategia consenso: majority
🧠 Avvio clustering intelligente OTTIMIZZATO di 1313 conversazioni...
📊 Fase 1: Clustering semantico con HDBSCAN...
🔧 HDBSCANClusterer inizializzato:
   min_cluster_size: 5
   min_samples: 5
   metric: euclidean
   cluster_selection_epsilon: 0.2
   🗂️  UMAP enabled: True
     📏 n_neighbors: 30
     📐 min_dist: 0.1
     📊 n_components: 17
     🎯 metric: cosine
   🚀 GPU enabled: True
   💾 GPU memory limit: 80%
   🔄 CPU fallback: True
   ⚠️  [GPU MODE] Limitazioni cuML HDBSCAN:
     🚫 leaf_size=40 sarà IGNORATO su GPU
     ✅ Parametri supportati: cluster_selection_method, alpha, allow_single_cluster
🎯 [DEBUG REACT] Parametri configurati:
   cluster_selection_method: eom
   alpha: 1.0
   allow_single_cluster: False
🔍 Clustering HDBSCAN su 1313 embedding (7.7MB)...
⚙️  Parametri: min_cluster_size=5, min_samples=5, metric=euclidean
📊 [DEBUG FIT_PREDICT] Embedding input:
   📏 Shape: (1313, 768)
   🔢 Dtype: float64
   📈 Range: [-0.1215, 0.0898]
   💾 Memory: 7.7MB

🗂️  [DEBUG FIT_PREDICT] STEP 1: Controllo applicazione UMAP...
🔍 [DEBUG UMAP] Controllo condizioni applicazione UMAP...
   ✅ self.use_umap = True
   ✅ UMAP_AVAILABLE = True
� [DEBUG UMAP] UMAP ABILITATO - Iniziando riduzione dimensionale...
   📏 Dimensioni input: (1313, 768)
   🔢 Tipo dati input: float64
   📊 Range valori input: [-0.1215, 0.0898]
   🎯 Parametri UMAP configurati:
     📐 n_neighbors: 30
     📏 min_dist: 0.1
     🔢 n_components: 17
     📈 metric: cosine
     🎲 random_state: 42
🔧 [DEBUG UMAP] Inizializzazione riduttore UMAP...
🆕 [DEBUG UMAP] Modalità TRAINING - fit nuovo reducer
✅ [DEBUG UMAP] Riduttore UMAP inizializzato con successo
⏳ [DEBUG UMAP] Applicazione fit_transform agli embeddings...
UMAP(angular_rp_forest=True, metric='cosine', n_components=17, n_jobs=1, n_neighbors=30, random_state=42, verbose=True)
Fri Aug 29 21:55:10 2025 Construct fuzzy simplicial set
Fri Aug 29 21:55:12 2025 Finding Nearest Neighbors
Fri Aug 29 21:55:12 2025 Finished Nearest Neighbor Search
Fri Aug 29 21:55:12 2025 Construct embedding
	completed  0  /  500 epochs
	completed  50  /  500 epochs
	completed  100  /  500 epochs
	completed  150  /  500 epochs
	completed  200  /  500 epochs
	completed  250  /  500 epochs
	completed  300  /  500 epochs
	completed  350  /  500 epochs
	completed  400  /  500 epochs
	completed  450  /  500 epochs
Fri Aug 29 21:55:16 2025 Finished embedding
✅ [DEBUG UMAP] UMAP COMPLETATO con SUCCESSO in 6.51s
   📐 Dimensioni output: (1313, 17)
   � Tipo dati output: float32
   �📊 Range valori output: [-15.2571, 15.9316]
   📈 Riduzione dimensionale: 768 → 17 dimensioni
   📉 Fattore riduzione: 45.2x
✅ [DEBUG UMAP] RIDUZIONE DIMENSIONALE CONFERMATA
✅ [DEBUG UMAP] Nessun NaN nel risultato UMAP
✅ [DEBUG UMAP] Nessun valore infinito nel risultato UMAP
📊 [DEBUG UMAP] Diversità embeddings ridotti: 1313/1313 righe uniche
✅ [DEBUG UMAP] Buona diversità negli embeddings ridotti
📋 [DEBUG UMAP] Info riduzione salvate nel clusterer
📋 [DEBUG FIT_PREDICT] Risultato UMAP:
   ✅ UMAP applicato: True
   📏 Shape post-UMAP: (1313, 17)
   📈 Range post-UMAP: [-15.2571, 15.9316]
   ⏱️  Tempo riduzione: 6.51s

🔧 [DEBUG FIT_PREDICT] STEP 2: Normalizzazione per metrica euclidean...
   🎯 Nessuna normalizzazione necessaria per metrica euclidean
   📏 Shape finale per clustering: (1313, 17)
   📈 Range finale: [-15.2571, 15.9316]
   🎯 Metrica effettiva clustering: euclidean
💾 Memoria GPU: 17.7GB disponibili, 0.0GB necessari
🚀 Utilizzo GPU per clustering accelerato

🚀 [DEBUG FIT_PREDICT] STEP 3: Avvio clustering...
   🖥️  Modalità: GPU
� [GPU CLUSTERING] Inizializzazione cuML HDBSCAN con parametri supportati...

✅ [DEBUG FIT_PREDICT] CLUSTERING COMPLETATO in 0.11s con 🚀 GPU!
📊 Risultati finali:
   🎯 Cluster trovati: 57
   🔍 Outlier: 253 (19.3%)
   📈 Silhouette score: 0.649

📋 [DEBUG FIT_PREDICT] RIEPILOGO TRASFORMAZIONI:
   🔤 Input originale: (1313, 768)
   🗂️  Dopo UMAP: (1313, 17)
   🔧 Dopo normalizzazione: (1313, 17)
   🎯 Utilizzato per clustering: (1313, 17) con metrica euclidean
   📈 Cluster HDBSCAN trovati: 57
   🔍 Outliers: 253
👥 Fase 2: Selezione rappresentanti per cluster...
   � Cluster 0: 39 sessioni, 4 rappresentanti selezionati
   � Cluster 1: 22 sessioni, 4 rappresentanti selezionati
   � Cluster 2: 15 sessioni, 4 rappresentanti selezionati
   � Cluster 3: 68 sessioni, 5 rappresentanti selezionati
   � Cluster 4: 11 sessioni, 4 rappresentanti selezionati
   � Cluster 5: 17 sessioni, 4 rappresentanti selezionati
   � Cluster 6: 117 sessioni, 5 rappresentanti selezionati
   � Cluster 7: 36 sessioni, 4 rappresentanti selezionati
   � Cluster 8: 60 sessioni, 5 rappresentanti selezionati
   � Cluster 9: 7 sessioni, 3 rappresentanti selezionati
   � Cluster 10: 16 sessioni, 4 rappresentanti selezionati
   � Cluster 11: 15 sessioni, 4 rappresentanti selezionati
   � Cluster 12: 50 sessioni, 4 rappresentanti selezionati
   � Cluster 13: 35 sessioni, 4 rappresentanti selezionati
   � Cluster 14: 7 sessioni, 3 rappresentanti selezionati
   � Cluster 15: 16 sessioni, 4 rappresentanti selezionati
   � Cluster 16: 15 sessioni, 4 rappresentanti selezionati
   � Cluster 17: 16 sessioni, 4 rappresentanti selezionati
   � Cluster 18: 10 sessioni, 3 rappresentanti selezionati
   � Cluster 19: 6 sessioni, 3 rappresentanti selezionati
   � Cluster 20: 6 sessioni, 3 rappresentanti selezionati
   � Cluster 21: 13 sessioni, 4 rappresentanti selezionati
   � Cluster 22: 12 sessioni, 4 rappresentanti selezionati
   � Cluster 23: 5 sessioni, 3 rappresentanti selezionati
   � Cluster 24: 41 sessioni, 4 rappresentanti selezionati
   � Cluster 25: 27 sessioni, 4 rappresentanti selezionati
   � Cluster 26: 18 sessioni, 4 rappresentanti selezionati
   � Cluster 27: 11 sessioni, 4 rappresentanti selezionati
   � Cluster 28: 10 sessioni, 3 rappresentanti selezionati
   � Cluster 29: 9 sessioni, 3 rappresentanti selezionati
   � Cluster 30: 8 sessioni, 3 rappresentanti selezionati
   � Cluster 31: 20 sessioni, 4 rappresentanti selezionati
   � Cluster 32: 5 sessioni, 3 rappresentanti selezionati
   � Cluster 33: 5 sessioni, 3 rappresentanti selezionati
   � Cluster 34: 5 sessioni, 3 rappresentanti selezionati
   � Cluster 35: 17 sessioni, 4 rappresentanti selezionati
   � Cluster 36: 24 sessioni, 4 rappresentanti selezionati
   � Cluster 37: 13 sessioni, 4 rappresentanti selezionati
   � Cluster 38: 17 sessioni, 4 rappresentanti selezionati
   � Cluster 39: 17 sessioni, 4 rappresentanti selezionati
   � Cluster 40: 10 sessioni, 3 rappresentanti selezionati
   � Cluster 41: 8 sessioni, 3 rappresentanti selezionati
   � Cluster 42: 6 sessioni, 3 rappresentanti selezionati
   � Cluster 43: 12 sessioni, 4 rappresentanti selezionati
   � Cluster 44: 11 sessioni, 4 rappresentanti selezionati
   � Cluster 45: 17 sessioni, 4 rappresentanti selezionati
   � Cluster 46: 7 sessioni, 3 rappresentanti selezionati
   � Cluster 47: 11 sessioni, 4 rappresentanti selezionati
   � Cluster 48: 8 sessioni, 3 rappresentanti selezionati
   � Cluster 49: 24 sessioni, 4 rappresentanti selezionati
   � Cluster 50: 16 sessioni, 4 rappresentanti selezionati
   � Cluster 51: 11 sessioni, 4 rappresentanti selezionati
   � Cluster 52: 18 sessioni, 4 rappresentanti selezionati
   � Cluster 53: 16 sessioni, 4 rappresentanti selezionati
   � Cluster 54: 7 sessioni, 3 rappresentanti selezionati
   � Cluster 55: 9 sessioni, 3 rappresentanti selezionati
   � Cluster 56: 8 sessioni, 3 rappresentanti selezionati
🤖 Fase 3: Analisi LLM di 211 rappresentanti...
🤖 Analisi LLM di 211 conversazioni...
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 26
   📊 Token totali: 440
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 440 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 26
   📊 Token conversazione finale: 26
   📊 Token totali: 440
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 70 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2518 chars (debug_prompt=False)
🔧 Creazione MongoClassificationReader per cliente: 16c222a9-f293-11ef-9315-96000228e7fe
🔍 Risoluzione tenant da UUID: 16c222a9-f293-11ef-9315-96000228e7fe
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
✅ Tenant risolto (DB TAG locale): Wopta (wopta) UUID=16c222a9-f293-11ef-9315-96000228e7fe
✅ Tenant risolto: Wopta (16c222a9-f293-11ef-9315-96000228e7fe)
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
✅ MongoClassificationReader inizializzato per tenant: Wopta
   📊 Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   🏢 Database: classificazioni
✅ MongoClassificationReader creato per tenant: Wopta (wopta)
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
   📊 Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
✅ Connesso a MongoDB database: classificazioni
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
🔍 Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
🏷️ Recupero etichette per tenant: Wopta
📊 Calcolo statistiche per tenant: Wopta
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 32
   📊 Token totali: 446
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 446 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 32
   📊 Token conversazione finale: 32
   📊 Token totali: 446
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 85 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2533 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 48
   📊 Token totali: 462
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 462 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 48
   📊 Token conversazione finale: 48
   📊 Token totali: 462
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 125 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2573 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 27
   📊 Token totali: 441
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 441 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 27
   📊 Token conversazione finale: 27
   📊 Token totali: 441
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 75 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2523 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 70
   📊 Token totali: 484
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 484 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 70
   📊 Token conversazione finale: 70
   📊 Token totali: 484
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 227 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2712 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 100
   📊 Token totali: 514
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 514 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 100
   📊 Token conversazione finale: 100
   📊 Token totali: 514
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 335 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2729 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 398
   📊 Token totali: 832
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 832 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 398
   📊 Token conversazione finale: 398
   📊 Token totali: 832
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 1340 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2728 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 82
   📊 Token totali: 496
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 496 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 82
   📊 Token conversazione finale: 82
   📊 Token totali: 496
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 264 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2749 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 46
   📊 Token totali: 460
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 460 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 46
   📊 Token conversazione finale: 46
   📊 Token totali: 460
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 129 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2580 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 32
   📊 Token totali: 446
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 446 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 32
   📊 Token conversazione finale: 32
   📊 Token totali: 446
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 99 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2569 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 44
   📊 Token totali: 458
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 458 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 44
   📊 Token conversazione finale: 44
   📊 Token totali: 458
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 125 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2582 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 37
   📊 Token totali: 451
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 451 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 37
   📊 Token conversazione finale: 37
   📊 Token totali: 451
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 102 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2569 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 25
   📊 Token totali: 439
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 439 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 25
   📊 Token conversazione finale: 25
   📊 Token totali: 439
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 65 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2513 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 27
   📊 Token totali: 441
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 441 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 27
   📊 Token conversazione finale: 27
   📊 Token totali: 441
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 79 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2537 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 31
   📊 Token totali: 445
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 445 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 31
   📊 Token conversazione finale: 31
   📊 Token totali: 445
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 80 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2528 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 26
   📊 Token totali: 440
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 440 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 26
   📊 Token conversazione finale: 26
   📊 Token totali: 440
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 69 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2517 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 26
   📊 Token totali: 440
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 440 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 26
   📊 Token conversazione finale: 26
   📊 Token totali: 440
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 66 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2514 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 70
   📊 Token totali: 484
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 484 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 70
   📊 Token conversazione finale: 70
   📊 Token totali: 484
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 227 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2712 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 438
   💬 Token conversazione: 121
   📊 Token totali: 559
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 559 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 438
   📊 Token conversazione originale: 121
   📊 Token conversazione finale: 121
   📊 Token totali: 559
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 354 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2715 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 62
   📊 Token totali: 476
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 476 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 62
   📊 Token conversazione finale: 62
   📊 Token totali: 476
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 176 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2627 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 95
   📊 Token totali: 509
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 509 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 95
   📊 Token conversazione finale: 95
   📊 Token totali: 509
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 279 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2730 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 22
   📊 Token totali: 436
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 436 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 22
   📊 Token conversazione finale: 22
   📊 Token totali: 436
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 58 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2506 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 30
   📊 Token totali: 444
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 444 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 30
   📊 Token conversazione finale: 30
   📊 Token totali: 444
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 95 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2582 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 25
   📊 Token totali: 439
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 439 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 25
   📊 Token conversazione finale: 25
   📊 Token totali: 439
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 63 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2511 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 24
   📊 Token totali: 438
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 438 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 24
   📊 Token conversazione finale: 24
   📊 Token totali: 438
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 62 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2510 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 174
   📊 Token totali: 588
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 588 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 174
   📊 Token conversazione finale: 174
   📊 Token totali: 588
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 487 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2755 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 186
   📊 Token totali: 620
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 620 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 186
   📊 Token conversazione finale: 186
   📊 Token totali: 620
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 611 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2857 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 121
   📊 Token totali: 555
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 555 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 121
   📊 Token conversazione finale: 121
   📊 Token totali: 555
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 419 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2824 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 63
   📊 Token totali: 477
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 477 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 63
   📊 Token conversazione finale: 63
   📊 Token totali: 477
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 204 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2715 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 57
   📊 Token totali: 471
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 471 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 57
   📊 Token conversazione finale: 57
   📊 Token totali: 471
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 184 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2668 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 239
   📊 Token totali: 673
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 673 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 239
   📊 Token conversazione finale: 239
   📊 Token totali: 673
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 797 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2822 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 117
   📊 Token totali: 531
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 531 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 117
   📊 Token conversazione finale: 117
   📊 Token totali: 531
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 390 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2541 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 435
   💬 Token conversazione: 2443
   📊 Token totali: 2878
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 2878 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 435
   📊 Token conversazione originale: 2443
   📊 Token conversazione finale: 2443
   📊 Token totali: 2878
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 8422 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2800 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 438
   💬 Token conversazione: 102
   📊 Token totali: 540
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 540 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 438
   📊 Token conversazione originale: 102
   📊 Token conversazione finale: 102
   📊 Token totali: 540
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 316 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2823 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 27
   📊 Token totali: 441
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 441 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 27
   📊 Token conversazione finale: 27
   📊 Token totali: 441
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 70 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2518 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 28
   📊 Token totali: 442
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 442 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 28
   📊 Token conversazione finale: 28
   📊 Token totali: 442
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 71 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2519 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 27
   📊 Token totali: 441
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 441 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 27
   📊 Token conversazione finale: 27
   📊 Token totali: 441
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 70 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2518 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 27
   📊 Token totali: 441
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 441 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 27
   📊 Token conversazione finale: 27
   📊 Token totali: 441
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 70 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2518 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 27
   📊 Token totali: 441
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 441 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 27
   📊 Token conversazione finale: 27
   📊 Token totali: 441
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 70 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2518 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 209
   📊 Token totali: 623
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 623 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 209
   📊 Token conversazione finale: 209
   📊 Token totali: 623
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 697 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2690 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 581
   📊 Token totali: 1015
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 1015 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 581
   📊 Token conversazione finale: 581
   📊 Token totali: 1015
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 1870 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2800 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 435
   💬 Token conversazione: 604
   📊 Token totali: 1039
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 1039 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 435
   📊 Token conversazione originale: 604
   📊 Token conversazione finale: 604
   📊 Token totali: 1039
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 2028 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2777 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 435
   💬 Token conversazione: 493
   📊 Token totali: 928
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 928 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 435
   📊 Token conversazione originale: 493
   📊 Token conversazione finale: 493
   📊 Token totali: 928
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 1607 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2696 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 149
   📊 Token totali: 563
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 563 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 149
   📊 Token conversazione finale: 149
   📊 Token totali: 563
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 483 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2782 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 229
   📊 Token totali: 663
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 663 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 229
   📊 Token conversazione finale: 229
   📊 Token totali: 663
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 719 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2855 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 460
   📊 Token totali: 894
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 894 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 460
   📊 Token conversazione finale: 460
   📊 Token totali: 894
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 1541 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2781 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 50
   📊 Token totali: 464
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 464 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 50
   📊 Token conversazione finale: 50
   📊 Token totali: 464
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 127 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2575 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 29
   📊 Token totali: 443
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 443 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 29
   📊 Token conversazione finale: 29
   📊 Token totali: 443
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 81 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2529 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 30
   📊 Token totali: 444
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 444 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 30
   📊 Token conversazione finale: 30
   📊 Token totali: 444
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 76 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2524 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 28
   📊 Token totali: 442
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 442 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 28
   📊 Token conversazione finale: 28
   📊 Token totali: 442
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 73 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2521 chars (debug_prompt=False)
   📈 Progresso LLM: 50/211
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 252
   📊 Token totali: 686
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 686 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 252
   📊 Token conversazione finale: 252
   📊 Token totali: 686
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 784 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2757 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 88
   📊 Token totali: 502
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 502 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 88
   📊 Token conversazione finale: 88
   📊 Token totali: 502
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 248 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2638 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 440
   💬 Token conversazione: 2934
   📊 Token totali: 3374
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 3374 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 440
   📊 Token conversazione originale: 2934
   📊 Token conversazione finale: 2934
   📊 Token totali: 3374
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 10029 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2765 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 927
   📊 Token totali: 1361
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 1361 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 927
   📊 Token conversazione finale: 927
   📊 Token totali: 1361
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 3131 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2819 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 86
   📊 Token totali: 500
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 500 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 86
   📊 Token conversazione finale: 86
   📊 Token totali: 500
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 285 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2722 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 123
   📊 Token totali: 537
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 537 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 123
   📊 Token conversazione finale: 123
   📊 Token totali: 537
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 417 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2624 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 114
   📊 Token totali: 528
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 528 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 114
   📊 Token conversazione finale: 114
   📊 Token totali: 528
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 387 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2777 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 135
   📊 Token totali: 549
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 549 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 135
   📊 Token conversazione finale: 135
   📊 Token totali: 549
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 417 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2752 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 3072
   📊 Token totali: 3486
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 3486 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 3072
   📊 Token conversazione finale: 3072
   📊 Token totali: 3486
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 10047 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2758 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 272
   📊 Token totali: 686
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 686 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 272
   📊 Token conversazione finale: 272
   📊 Token totali: 686
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 910 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2740 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 435
   💬 Token conversazione: 243
   📊 Token totali: 678
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 678 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 435
   📊 Token conversazione originale: 243
   📊 Token conversazione finale: 243
   📊 Token totali: 678
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 821 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2789 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 33
   📊 Token totali: 447
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 447 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 33
   📊 Token conversazione finale: 33
   📊 Token totali: 447
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 93 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2545 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 438
   💬 Token conversazione: 49
   📊 Token totali: 487
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 487 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 438
   📊 Token conversazione originale: 49
   📊 Token conversazione finale: 49
   📊 Token totali: 487
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 155 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2694 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 49
   📊 Token totali: 463
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 463 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 49
   📊 Token conversazione finale: 49
   📊 Token totali: 463
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 151 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2603 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 32
   📊 Token totali: 446
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 446 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 32
   📊 Token conversazione finale: 32
   📊 Token totali: 446
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 95 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2547 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 242
   📊 Token totali: 656
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 656 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 242
   📊 Token conversazione finale: 242
   📊 Token totali: 656
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 773 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2642 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 90
   📊 Token totali: 524
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 524 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 90
   📊 Token conversazione finale: 90
   📊 Token totali: 524
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 290 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2847 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 77
   📊 Token totali: 511
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 511 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 77
   📊 Token conversazione finale: 77
   📊 Token totali: 511
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 268 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2820 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 115
   📊 Token totali: 529
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 529 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 115
   📊 Token conversazione finale: 115
   📊 Token totali: 529
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 386 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2626 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 74
   📊 Token totali: 488
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 488 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 74
   📊 Token conversazione finale: 74
   📊 Token totali: 488
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 248 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2721 chars (debug_prompt=False)
🔧 Inizializzazione QualityGateEngine per cliente: sga (con lock)
❌ ERRORE: identifier deve essere un UUID valido. Ricevuto: 'sga'
💡 SOLUZIONE: Il frontend deve inviare tenant_id (UUID), non nomi o slug
❌ Errore risoluzione tenant UUID 'sga': ❌ ERRORE: identifier deve essere un UUID valido. Ricevuto: 'sga'
💡 Verifica che:
   1. Il tenant_id esista nel database TAG locale
   2. Il tenant sia attivo (is_active = 1)
   3. L'UUID sia nel formato corretto
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 148
   📊 Token totali: 582
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 582 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 148
   📊 Token conversazione finale: 148
   📊 Token totali: 582
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 509 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2779 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 66
   📊 Token totali: 480
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 480 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 66
   📊 Token conversazione finale: 66
   📊 Token totali: 480
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 225 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2700 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 72
   📊 Token totali: 486
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 486 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 72
   📊 Token conversazione finale: 72
   📊 Token totali: 486
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 252 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2725 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 267
   📊 Token totali: 681
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 681 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 267
   📊 Token conversazione finale: 267
   📊 Token totali: 681
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 894 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2755 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 435
   💬 Token conversazione: 162
   📊 Token totali: 597
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 597 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 435
   📊 Token conversazione originale: 162
   📊 Token conversazione finale: 162
   📊 Token totali: 597
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 582 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2851 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 323
   📊 Token totali: 737
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 737 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 323
   📊 Token conversazione finale: 323
   📊 Token totali: 737
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 1091 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2716 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 212
   📊 Token totali: 646
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 646 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 212
   📊 Token conversazione finale: 212
   📊 Token totali: 646
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 675 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2705 chars (debug_prompt=False)
🔧 Creazione MongoClassificationReader per cliente: 16c222a9-f293-11ef-9315-96000228e7fe
🔍 Risoluzione tenant da UUID: 16c222a9-f293-11ef-9315-96000228e7fe
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
✅ Tenant risolto (DB TAG locale): Wopta (wopta) UUID=16c222a9-f293-11ef-9315-96000228e7fe
✅ Tenant risolto: Wopta (16c222a9-f293-11ef-9315-96000228e7fe)
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
✅ MongoClassificationReader inizializzato per tenant: Wopta
   📊 Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   🏢 Database: classificazioni
✅ MongoClassificationReader creato per tenant: Wopta (wopta)
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
   📊 Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
✅ Connesso a MongoDB database: classificazioni
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
🔍 Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
🏷️ Recupero etichette per tenant: Wopta
📊 Calcolo statistiche per tenant: Wopta
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 559
   📊 Token totali: 993
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 993 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 559
   📊 Token conversazione finale: 559
   📊 Token totali: 993
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 1897 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2777 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 67
   📊 Token totali: 481
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 481 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 67
   📊 Token conversazione finale: 67
   📊 Token totali: 481
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 215 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2700 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 438
   📊 Token totali: 872
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 872 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 438
   📊 Token conversazione finale: 438
   📊 Token totali: 872
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 1435 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2821 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 142
   📊 Token totali: 556
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 556 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 142
   📊 Token conversazione finale: 142
   📊 Token totali: 556
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 407 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2709 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 1034
   📊 Token totali: 1448
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 1448 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 1034
   📊 Token conversazione finale: 1034
   📊 Token totali: 1448
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 3426 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2785 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 166
   📊 Token totali: 580
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 580 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 166
   📊 Token conversazione finale: 166
   📊 Token totali: 580
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 566 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2701 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 127
   📊 Token totali: 541
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 541 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 127
   📊 Token conversazione finale: 127
   📊 Token totali: 541
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 421 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2746 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 229
   📊 Token totali: 643
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 643 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 229
   📊 Token conversazione finale: 229
   📊 Token totali: 643
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 701 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2730 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 136
   📊 Token totali: 550
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 550 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 136
   📊 Token conversazione finale: 136
   📊 Token totali: 550
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 426 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2596 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 435
   💬 Token conversazione: 2766
   📊 Token totali: 3201
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 3201 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 435
   📊 Token conversazione originale: 2766
   📊 Token conversazione finale: 2766
   📊 Token totali: 3201
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 8721 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2830 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 95
   📊 Token totali: 529
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 529 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 95
   📊 Token conversazione finale: 95
   📊 Token totali: 529
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 305 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2883 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 227
   📊 Token totali: 641
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 641 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 227
   📊 Token conversazione finale: 227
   📊 Token totali: 641
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 726 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2658 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 811
   📊 Token totali: 1225
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 1225 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 811
   📊 Token conversazione finale: 811
   📊 Token totali: 1225
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 2653 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2516 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 613
   📊 Token totali: 1047
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 1047 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 613
   📊 Token conversazione finale: 613
   📊 Token totali: 1047
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 2000 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2715 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 95
   📊 Token totali: 529
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 529 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 95
   📊 Token conversazione finale: 95
   📊 Token totali: 529
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 335 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2759 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 435
   💬 Token conversazione: 119
   📊 Token totali: 554
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 554 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 435
   📊 Token conversazione originale: 119
   📊 Token conversazione finale: 119
   📊 Token totali: 554
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 419 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2878 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 56
   📊 Token totali: 470
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 470 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 56
   📊 Token conversazione finale: 56
   📊 Token totali: 470
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 144 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2592 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 46
   📊 Token totali: 480
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 480 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 46
   📊 Token conversazione finale: 46
   📊 Token totali: 480
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 140 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2670 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 52
   📊 Token totali: 486
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 486 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 52
   📊 Token conversazione finale: 52
   📊 Token totali: 486
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 147 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2667 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 68
   📊 Token totali: 482
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 482 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 68
   📊 Token conversazione finale: 68
   📊 Token totali: 482
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 203 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2639 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 52
   📊 Token totali: 466
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 466 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 52
   📊 Token conversazione finale: 52
   📊 Token totali: 466
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 139 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2587 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 32
   📊 Token totali: 446
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 446 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 32
   📊 Token conversazione finale: 32
   📊 Token totali: 446
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 89 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2576 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 49
   📊 Token totali: 463
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 463 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 49
   📊 Token conversazione finale: 49
   📊 Token totali: 463
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 130 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2578 chars (debug_prompt=False)
   📈 Progresso LLM: 100/211
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 48
   📊 Token totali: 462
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 462 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 48
   📊 Token conversazione finale: 48
   📊 Token totali: 462
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 128 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2576 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 293
   📊 Token totali: 707
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 707 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 293
   📊 Token conversazione finale: 293
   📊 Token totali: 707
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 930 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2798 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 146
   📊 Token totali: 580
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 580 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 146
   📊 Token conversazione finale: 146
   📊 Token totali: 580
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 443 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2880 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 160
   📊 Token totali: 574
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 574 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 160
   📊 Token conversazione finale: 160
   📊 Token totali: 574
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 518 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2653 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 438
   💬 Token conversazione: 2364
   📊 Token totali: 2802
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 2802 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 438
   📊 Token conversazione originale: 2364
   📊 Token conversazione finale: 2364
   📊 Token totali: 2802
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 7946 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2863 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 140
   📊 Token totali: 554
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 554 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 140
   📊 Token conversazione finale: 140
   📊 Token totali: 554
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 431 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2695 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 182
   📊 Token totali: 596
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 596 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 182
   📊 Token conversazione finale: 182
   📊 Token totali: 596
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 588 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2716 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 145
   📊 Token totali: 559
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 559 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 145
   📊 Token conversazione finale: 145
   📊 Token totali: 559
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 432 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2688 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 334
   📊 Token totali: 768
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 768 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 334
   📊 Token conversazione finale: 334
   📊 Token totali: 768
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 980 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2808 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 34
   📊 Token totali: 448
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 448 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 34
   📊 Token conversazione finale: 34
   📊 Token totali: 448
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 98 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2550 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 47
   📊 Token totali: 461
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 461 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 47
   📊 Token conversazione finale: 47
   📊 Token totali: 461
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 145 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2597 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 68
   📊 Token totali: 482
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 482 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 68
   📊 Token conversazione finale: 68
   📊 Token totali: 482
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 201 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2653 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 40
   📊 Token totali: 454
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 454 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 40
   📊 Token conversazione finale: 40
   📊 Token totali: 454
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 112 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2597 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 82
   📊 Token totali: 496
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 496 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 82
   📊 Token conversazione finale: 82
   📊 Token totali: 496
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 252 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2737 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 48
   📊 Token totali: 462
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 462 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 48
   📊 Token conversazione finale: 48
   📊 Token totali: 462
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 129 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2614 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 299
   📊 Token totali: 733
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 733 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 299
   📊 Token conversazione finale: 299
   📊 Token totali: 733
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 1016 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2660 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 104
   📊 Token totali: 538
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 538 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 104
   📊 Token conversazione finale: 104
   📊 Token totali: 538
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 335 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2729 chars (debug_prompt=False)
🔍 [DEBUG] GET /api/tenants - Avvio richiesta tenant con oggetti Tenant
🔍 [DEBUG] Chiamo get_available_tenants() per oggetti Tenant...
🏢 Recuperati 22 oggetti Tenant dalla tabella TAG.tenants
🔍 [DEBUG] Recuperati 22 oggetti Tenant dal database
🔍 [DEBUG] Primi 3 tenant convertiti: [{'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'tenant_name': 'Alleanza', 'tenant_slug': 'alleanza', 'is_active': True}, {'tenant_id': '6bc4f06f-742e-11f0-acb8-96000228e7fe', 'tenant_name': 'BluPantheon', 'tenant_slug': 'blupantheon', 'is_active': True}, {'tenant_id': '0f9d6e90-d319-11ef-86a5-96000228e7fe', 'tenant_name': 'Boots', 'tenant_slug': 'boots', 'is_active': True}]
🔍 [DEBUG] Invio risposta con 22 tenant
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 373
   📊 Token totali: 807
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 807 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 373
   📊 Token conversazione finale: 373
   📊 Token totali: 807
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 1226 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2713 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 94
   📊 Token totali: 508
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 508 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 94
   📊 Token conversazione finale: 94
   📊 Token totali: 508
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 292 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2737 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 78
   📊 Token totali: 492
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 492 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 78
   📊 Token conversazione finale: 78
   📊 Token totali: 492
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 258 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2703 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 489
   📊 Token totali: 903
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 903 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 489
   📊 Token conversazione finale: 489
   📊 Token totali: 903
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 1588 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2788 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 218
   📊 Token totali: 632
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 632 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 218
   📊 Token conversazione finale: 218
   📊 Token totali: 632
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 644 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2745 chars (debug_prompt=False)
🔍 [DEBUG] GET /api/tenants - Avvio richiesta tenant con oggetti Tenant
🔍 [DEBUG] Chiamo get_available_tenants() per oggetti Tenant...
🏢 Recuperati 22 oggetti Tenant dalla tabella TAG.tenants
🔍 [DEBUG] Recuperati 22 oggetti Tenant dal database
🔍 [DEBUG] Primi 3 tenant convertiti: [{'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'tenant_name': 'Alleanza', 'tenant_slug': 'alleanza', 'is_active': True}, {'tenant_id': '6bc4f06f-742e-11f0-acb8-96000228e7fe', 'tenant_name': 'BluPantheon', 'tenant_slug': 'blupantheon', 'is_active': True}, {'tenant_id': '0f9d6e90-d319-11ef-86a5-96000228e7fe', 'tenant_name': 'Boots', 'tenant_slug': 'boots', 'is_active': True}]
🔍 [DEBUG] Invio risposta con 22 tenant
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 199
   📊 Token totali: 613
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 613 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 199
   📊 Token conversazione finale: 199
   📊 Token totali: 613
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 614 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2698 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 435
   💬 Token conversazione: 339
   📊 Token totali: 774
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 774 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 435
   📊 Token conversazione originale: 339
   📊 Token conversazione finale: 339
   📊 Token totali: 774
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 1101 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2827 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 273
   📊 Token totali: 707
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 707 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 273
   📊 Token conversazione finale: 273
   📊 Token totali: 707
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 820 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2812 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 77
   📊 Token totali: 491
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 491 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 77
   📊 Token conversazione finale: 77
   📊 Token totali: 491
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 199 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2647 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 53
   📊 Token totali: 467
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 467 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 53
   📊 Token conversazione finale: 53
   📊 Token totali: 467
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 140 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2588 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 59
   📊 Token totali: 473
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 473 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 59
   📊 Token conversazione finale: 59
   📊 Token totali: 473
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 157 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2605 chars (debug_prompt=False)
🔧 Inizializzazione QualityGateEngine per cliente: 16c222a9-f293-11ef-9315-96000228e7fe (con lock)
🔍 Risoluzione tenant da UUID: 16c222a9-f293-11ef-9315-96000228e7fe
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
✅ Tenant risolto (DB TAG locale): Wopta (wopta) UUID=16c222a9-f293-11ef-9315-96000228e7fe
✅ Tenant risolto: Wopta (16c222a9-f293-11ef-9315-96000228e7fe)
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
✅ MongoClassificationReader inizializzato per tenant: Wopta
   📊 Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   🏢 Database: classificazioni
✅ Connesso a MongoDB database: classificazioni
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
✅ MongoClassificationReader inizializzato per tenant: Wopta
   📊 Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   🏢 Database: classificazioni
🔧 TokenizationManager inizializzato:
   📊 Modello tokenizer: cl100k_base
   🔢 Limite massimo token: 8000
   ✂️  Strategia troncamento: start
✅ TokenizationManager integrato in LaBSE per gestione conversazioni lunghe
🚀 Inizializzazione LaBSE embedder su device: cuda
📥 Caricamento modello sentence-transformers/LaBSE...
🚀 Caricamento diretto su GPU...
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 210
   📊 Token totali: 644
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 644 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 210
   📊 Token conversazione finale: 210
   📊 Token totali: 644
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 598 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2857 chars (debug_prompt=False)
✅ Modello caricato con successo!
📊 Dimensione embedding: 768
🔧 Device: cuda
🎮 GPU: NVIDIA A10G
💾 GPU Memory: 23.7 GB
📈 GPU Memory utilizzata: 3.88 GB
� Primo parametro su device: cuda:0
🧪 Test del modello LaBSE...
🔍 Encoding 3 testi con LaBSE su device cuda...

🔍 TOKENIZZAZIONE PREVENTIVA LABSE CLUSTERING
============================================================
🔍 ELABORAZIONE CONVERSAZIONI PER CLUSTERING
   📊 Numero conversazioni: 3
   🆔 Session IDs forniti: No

📊 STATISTICHE ELABORAZIONE:
   🔢 Conversazioni totali: 3
   ✂️  Conversazioni troncate: 0
   📏 Token originali totali: 20
   📐 Token finali totali: 20
   📊 Range token: 6 - 7
✅ Tokenizzazione LaBSE completata:
   📊 Conversazioni processate: 3
   📊 Conversazioni troncate: 0
   📊 Token limite configurato: 8000
   ✅ Tutte le conversazioni entro i limiti, nessun troncamento
============================================================
✅ Embedding generati: shape (3, 768)
✅ Test modello completato con successo!
   Shape: (3, 768)
   Norme: [0.99999994 1.         1.        ]
   Device: cuda
🎯 Modello pronto per l'uso!
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
✅ MongoClassificationReader inizializzato per tenant: Wopta
   📊 Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   🏢 Database: classificazioni
🧠 SemanticMemoryManager inizializzato
  🎯 Soglia riutilizzo etichette: 0.8
  🔍 Soglia similarità semantica: 0.8
  💾 Cache path: semantic_cache/wopta_16c222a9_memory
🔄 Caricamento memoria semantica dal database...
🔄 Caricamento memoria semantica da MongoDB...
❌ Errore caricamento memoria semantica: MongoClassificationReader.get_all_sessions() got an unexpected keyword argument 'client_name'
📭 Inizializzata memoria semantica vuota
✅ QualityGateEngine 16c222a9-f293-11ef-9315-96000228e7fe inizializzato con soglie: confidence=0.9, disagreement=0.3
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 87
   📊 Token totali: 501
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 501 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 87
   📊 Token conversazione finale: 87
   📊 Token totali: 501
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 243 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2725 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 177
   📊 Token totali: 611
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 611 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 177
   📊 Token conversazione finale: 177
   📊 Token totali: 611
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 510 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2860 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 225
   📊 Token totali: 639
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 639 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 225
   📊 Token conversazione finale: 225
   📊 Token totali: 639
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 755 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2762 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 139
   📊 Token totali: 553
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 553 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 139
   📊 Token conversazione finale: 139
   📊 Token totali: 553
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 451 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2785 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 779
   📊 Token totali: 1193
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 1193 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 779
   📊 Token conversazione finale: 779
   📊 Token totali: 1193
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 2550 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2570 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 514
   📊 Token totali: 928
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 928 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 514
   📊 Token conversazione finale: 514
   📊 Token totali: 928
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 1636 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2724 chars (debug_prompt=False)
🔧 Creazione MongoClassificationReader per cliente: 16c222a9-f293-11ef-9315-96000228e7fe
🔍 Risoluzione tenant da UUID: 16c222a9-f293-11ef-9315-96000228e7fe
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
✅ Tenant risolto (DB TAG locale): Wopta (wopta) UUID=16c222a9-f293-11ef-9315-96000228e7fe
✅ Tenant risolto: Wopta (16c222a9-f293-11ef-9315-96000228e7fe)
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
✅ MongoClassificationReader inizializzato per tenant: Wopta
   📊 Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   🏢 Database: classificazioni
✅ MongoClassificationReader creato per tenant: Wopta (wopta)
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
   📊 Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
✅ Connesso a MongoDB database: classificazioni
📊 Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
🔍 Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
🏷️ Recupero etichette per tenant: Wopta
📊 Calcolo statistiche per tenant: Wopta
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 84
   📊 Token totali: 518
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 518 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 84
   📊 Token conversazione finale: 84
   📊 Token totali: 518
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 276 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2800 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 435
   💬 Token conversazione: 1460
   📊 Token totali: 1895
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 1895 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 435
   📊 Token conversazione originale: 1460
   📊 Token conversazione finale: 1460
   📊 Token totali: 1895
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 4869 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2638 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 81
   📊 Token totali: 515
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 515 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 81
   📊 Token conversazione finale: 81
   📊 Token totali: 515
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 252 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2764 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 99
   📊 Token totali: 513
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 513 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 99
   📊 Token conversazione finale: 99
   📊 Token totali: 513
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 325 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2548 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 85
   📊 Token totali: 499
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 499 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 85
   📊 Token conversazione finale: 85
   📊 Token totali: 499
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 214 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2671 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 65
   📊 Token totali: 499
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 499 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 65
   📊 Token conversazione finale: 65
   📊 Token totali: 499
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 183 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2712 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 200
   📊 Token totali: 614
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 614 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 200
   📊 Token conversazione finale: 200
   📊 Token totali: 614
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 551 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2646 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 433
   💬 Token conversazione: 81
   📊 Token totali: 514
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 514 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 433
   📊 Token conversazione originale: 81
   📊 Token conversazione finale: 81
   📊 Token totali: 514
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 216 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2737 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 28
   📊 Token totali: 442
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 442 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 28
   📊 Token conversazione finale: 28
   📊 Token totali: 442
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 71 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2519 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 27
   📊 Token totali: 441
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 441 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 27
   📊 Token conversazione finale: 27
   📊 Token totali: 441
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 66 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2514 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 29
   📊 Token totali: 443
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 443 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 29
   📊 Token conversazione finale: 29
   📊 Token totali: 443
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 71 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2519 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 28
   📊 Token totali: 442
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 442 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 28
   📊 Token conversazione finale: 28
   📊 Token totali: 442
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 73 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2521 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 225
   📊 Token totali: 639
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 639 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 225
   📊 Token conversazione finale: 225
   📊 Token totali: 639
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 674 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2772 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 244
   📊 Token totali: 658
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 658 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 244
   📊 Token conversazione finale: 244
   📊 Token totali: 658
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 804 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2785 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 135
   📊 Token totali: 549
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 549 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 135
   📊 Token conversazione finale: 135
   📊 Token totali: 549
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 423 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2778 chars (debug_prompt=False)
   📈 Progresso LLM: 150/211
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 312
   📊 Token totali: 746
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 746 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 312
   📊 Token conversazione finale: 312
   📊 Token totali: 746
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 994 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2825 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 434
   💬 Token conversazione: 762
   📊 Token totali: 1196
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 1196 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 434
   📊 Token conversazione originale: 762
   📊 Token conversazione finale: 762
   📊 Token totali: 1196
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 2381 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2698 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 268
   📊 Token totali: 682
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 682 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 268
   📊 Token conversazione finale: 268
   📊 Token totali: 682
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 848 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2758 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 248
   📊 Token totali: 662
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 662 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 248
   📊 Token conversazione finale: 248
   📊 Token totali: 662
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 793 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2703 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 251
   📊 Token totali: 665
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 665 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 251
   📊 Token conversazione finale: 251
   📊 Token totali: 665
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 822 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2778 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
🤖 System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

🔍 TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
🤖 ELABORAZIONE CONVERSAZIONE PER LLM
   🆔 Session ID: llm_conversation
   📝 Token prompt: 414
   💬 Token conversazione: 414
   📊 Token totali: 828
   🎯 Limite massimo: 8000
   ✅ Conversazione OK: 828 ≤ 8000
✅ Tokenizzazione LLM completata:
   📊 Token prompt base: 414
   📊 Token conversazione originale: 414
   📊 Token conversazione finale: 414
   📊 Token totali: 828
   📊 Limite configurato: 8000
   ✅ Conversazione entro i limiti, nessun troncamento
============================================================
👤 User prompt generato per conversazione 1287 chars (debug_prompt=False)
🚀 Prompt finale generato per LLM gpt-oss:20b - 2779 chars (debug_prompt=False)
