🚀 UMAP disponibile per riduzione dimensionale!
🚀 cuML GPU clustering disponibile!
💥 EmbeddingDestroyer inizializzato - Ready to destroy and rebuild!
🎯 SimpleEmbeddingManager inizializzato
🎛️ Configurazioni AI saranno salvate su DATABASE MySQL
🎛️ AIConfigurationService inizializzato
   � Backend: DATABASE MySQL
   🔑 OpenAI API Key: ✅ Configurata
🏭 EmbeddingEngineFactory inizializzata
🎯 EmbeddingManager inizializzato
✅ Blueprint esempi inizializzato correttamente
🚀 Avvio server Flask - Debug: True
 * Serving Flask app 'server'
 * Debug mode: on
🔍 [DEBUG] GET /api/tenants - Avvio richiesta tenant
🔍 [DEBUG] Inizializzo MongoClassificationReader...
🔍 [DEBUG] Chiamo get_available_tenants()...
Recuperati 22 tenant dalla tabella TAG.tenants
🔍 [DEBUG] Recuperati 22 tenant dal database
🔍 [DEBUG] Primi 3 tenant: [{'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'nome': 'Alleanza'}, {'tenant_id': '6bc4f06f-742e-11f0-acb8-96000228e7fe', 'nome': 'BluPantheon'}, {'tenant_id': '0f9d6e90-d319-11ef-86a5-96000228e7fe', 'nome': 'Boots'}]
🔍 [DEBUG] Invio risposta con 22 tenant
🔧 Creazione MongoClassificationReader per cliente: humanitas
✅ MongoClassificationReader humanitas creato con collection: humanitas_015007d9-d413-11ef-86a5-96000228e7fe
✅ Connesso a MongoDB database: classificazioni
🔍 Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
🔍 [DEBUG] GET /api/tenants - Avvio richiesta tenant
🔍 [DEBUG] Inizializzo MongoClassificationReader...
🔍 [DEBUG] Chiamo get_available_tenants()...
Recuperati 22 tenant dalla tabella TAG.tenants
🔍 [DEBUG] Recuperati 22 tenant dal database
🔍 [DEBUG] Primi 3 tenant: [{'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'nome': 'Alleanza'}, {'tenant_id': '6bc4f06f-742e-11f0-acb8-96000228e7fe', 'nome': 'BluPantheon'}, {'tenant_id': '0f9d6e90-d319-11ef-86a5-96000228e7fe', 'nome': 'Boots'}]
🔍 [DEBUG] Invio risposta con 22 tenant
🔍 [DEBUG] GET /api/prompts/a0fd7600-f4f7-11ef-9315-96000228e7fe/status - Avvio richiesta
🔍 [DEBUG] API: Recupero status prompt per tenant: a0fd7600-f4f7-11ef-9315-96000228e7fe
✅ [DEBUG] Riconosciuto come tenant_id UUID: a0fd7600-f4f7-11ef-9315-96000228e7fe
🔍 [DEBUG] Inizializzo PromptManager...
🔍 [DEBUG] Chiamo get_all_prompts_for_tenant(a0fd7600-f4f7-11ef-9315-96000228e7fe)...
🔍 [DEBUG] Recuperati 5 prompt dal PromptManager
🔍 [DEBUG] Statistiche: 5/5 attivi, 0 inattivi
✅ [DEBUG] Status calcolato: {'success': True, 'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'tenant_name': 'Alleanza', 'total_prompts': 5, 'active_prompts': 5, 'inactive_prompts': 0, 'last_updated': '2025-08-25T08:54:43', 'status': 'ready', 'canOperate': True, 'requiredPrompts': [{'name': 'System Prompt', 'type': 'system', 'description': 'Prompt di sistema per la classificazione', 'exists': True}, {'name': 'User Template', 'type': 'user', 'description': 'Template per prompt utente', 'exists': True}, {'name': 'Classification Prompt', 'type': 'classification', 'description': 'Prompt per classificazione intelligente', 'exists': False}], 'missingCount': 1}
✅ [DEBUG] Status prompt per tenant_id a0fd7600-f4f7-11ef-9315-96000228e7fe: 5/5 attivi
🔍 [DEBUG] Invio risposta JSON per status prompt
🔍 [DEBUG] GET /api/prompts/a0fd7600-f4f7-11ef-9315-96000228e7fe/status - Avvio richiesta
🔍 [DEBUG] API: Recupero status prompt per tenant: a0fd7600-f4f7-11ef-9315-96000228e7fe
✅ [DEBUG] Riconosciuto come tenant_id UUID: a0fd7600-f4f7-11ef-9315-96000228e7fe
🔍 [DEBUG] Inizializzo PromptManager...
🔍 [DEBUG] Chiamo get_all_prompts_for_tenant(a0fd7600-f4f7-11ef-9315-96000228e7fe)...
🔍 [DEBUG] Recuperati 5 prompt dal PromptManager
🔍 [DEBUG] Statistiche: 5/5 attivi, 0 inattivi
✅ [DEBUG] Status calcolato: {'success': True, 'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'tenant_name': 'Alleanza', 'total_prompts': 5, 'active_prompts': 5, 'inactive_prompts': 0, 'last_updated': '2025-08-25T08:54:43', 'status': 'ready', 'canOperate': True, 'requiredPrompts': [{'name': 'System Prompt', 'type': 'system', 'description': 'Prompt di sistema per la classificazione', 'exists': True}, {'name': 'User Template', 'type': 'user', 'description': 'Template per prompt utente', 'exists': True}, {'name': 'Classification Prompt', 'type': 'classification', 'description': 'Prompt per classificazione intelligente', 'exists': False}], 'missingCount': 1}
✅ [DEBUG] Status prompt per tenant_id a0fd7600-f4f7-11ef-9315-96000228e7fe: 5/5 attivi
🔍 [DEBUG] Invio risposta JSON per status prompt
🔧 Creazione MongoClassificationReader per cliente: humanitas
🔍 [DEBUG] GET /api/prompts/015007d9-d413-11ef-86a5-96000228e7fe/status - Avvio richiesta
🔍 [DEBUG] API: Recupero status prompt per tenant: 015007d9-d413-11ef-86a5-96000228e7fe
✅ [DEBUG] Riconosciuto come tenant_id UUID: 015007d9-d413-11ef-86a5-96000228e7fe
🔍 [DEBUG] Inizializzo PromptManager...
🔍 [DEBUG] Chiamo get_all_prompts_for_tenant(015007d9-d413-11ef-86a5-96000228e7fe)...
🔍 [DEBUG] Recuperati 5 prompt dal PromptManager
🔍 [DEBUG] Statistiche: 5/5 attivi, 0 inattivi
✅ [DEBUG] Status calcolato: {'success': True, 'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'total_prompts': 5, 'active_prompts': 5, 'inactive_prompts': 0, 'last_updated': '2025-08-26T15:04:08', 'status': 'ready', 'canOperate': True, 'requiredPrompts': [{'name': 'System Prompt', 'type': 'system', 'description': 'Prompt di sistema per la classificazione', 'exists': True}, {'name': 'User Template', 'type': 'user', 'description': 'Template per prompt utente', 'exists': True}, {'name': 'Classification Prompt', 'type': 'classification', 'description': 'Prompt per classificazione intelligente', 'exists': False}], 'missingCount': 1}
✅ [DEBUG] Status prompt per tenant_id 015007d9-d413-11ef-86a5-96000228e7fe: 5/5 attivi
🔍 [DEBUG] Invio risposta JSON per status prompt
✅ MongoClassificationReader humanitas creato con collection: humanitas_015007d9-d413-11ef-86a5-96000228e7fe
✅ Connesso a MongoDB database: classificazioni
🔍 Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
🎯 TRAINING SUPERVISIONATO - Cliente: humanitas
📋 Parametri utente semplificati:
  � Max sessioni review: 500
  🎯 Soglia confidenza: 0.9
  🔄 Forza review: False
  ⚖️  Soglia disagreement: 0.3
🔧 Inizializzazione pipeline per cliente: humanitas (con lock)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
✅ Tenant risolto da slug (DB TAG locale): Humanitas (humanitas) UUID=015007d9-d413-11ef-86a5-96000228e7fe
✅ [CONFIG] Configurazione base caricata da /home/ubuntu/classificatore/Utils/../config.yaml
🎯 [PIPELINE CLUSTERING CONFIG] Caricati parametri personalizzati per tenant 015007d9-d413-11ef-86a5-96000228e7fe:
   allow_single_cluster: non_definito -> False
   alpha: non_definito -> 0.7
   cluster_selection_epsilon: non_definito -> 0.13
   cluster_selection_method: non_definito -> leaf
   max_cluster_size: non_definito -> 0
   metric: non_definito -> euclidean
   min_cluster_size: 5 -> 21
   min_samples: 3 -> 14
   only_user: non_definito -> False
   umap_metric: non_definito -> cosine
   umap_min_dist: non_definito -> 0.05
   umap_n_components: non_definito -> 100
   umap_n_neighbors: non_definito -> 15
   umap_random_state: non_definito -> 42
   use_umap: non_definito -> True

🚀 [FASE 1: INIZIALIZZAZIONE] Avvio pipeline...
🏥 [FASE 1: INIZIALIZZAZIONE] Tenant: humanitas
🎯 [FASE 1: INIZIALIZZAZIONE] Configurazione:
   📊 Confidence threshold: 0.7
   🤖 Auto mode: True
   🔄 Auto retrain: False
� [FASE 1: INIZIALIZZAZIONE] Inizializzazione lettore conversazioni...
📖 [LETTORE] Schema common: only_user = False (legacy - no tenant_id)
� [FASE 1: INIZIALIZZAZIONE] Inizializzazione aggregator...
   🔍 Schema: 'humanitas'
   🆔 Tenant ID: '015007d9-d413-11ef-86a5-96000228e7fe'
✅ [CONFIG] Configurazione base caricata da /home/ubuntu/classificatore/Utils/../config.yaml
✅ [CONFIG] Config personalizzata tenant 015007d9-d413-11ef-86a5-96000228e7fe: 15 parametri
🎯 [ONLY_USER] Tenant 015007d9-d413-11ef-86a5-96000228e7fe: False (da config personalizzata)
🎯 [LETTORE] Tenant 015007d9-d413-11ef-86a5-96000228e7fe: only_user = False (da config tenant)
🎯 [ONLY_USER] Tenant 015007d9-d413-11ef-86a5-96000228e7fe: False (da config personalizzata)
🎯 [ONLY_USER] Tenant 015007d9-d413-11ef-86a5-96000228e7fe: False (da config tenant)
🧠 [FASE 1: INIZIALIZZAZIONE] Sistema embedder dinamico (lazy loading)
🔧 [FASE 1: INIZIALIZZAZIONE] Parametri clustering:
   📊 Min cluster size: 21
   📊 Min samples: 14
✅ [CONFIG] Config personalizzata tenant 015007d9-d413-11ef-86a5-96000228e7fe: 15 parametri
🗂️  [UMAP] Parametri per tenant 015007d9-d413-11ef-86a5-96000228e7fe:
   use_umap: True
   n_neighbors: 15
   min_dist: 0.05
   n_components: 100
   metric: cosine
🔧 [FIX DEBUG] Parametri tenant passati a HDBSCANClusterer:
   min_cluster_size: 21
   min_samples: 14
   alpha: 0.7
   cluster_selection_method: leaf
   cluster_selection_epsilon: 0.13
   metric: euclidean
   allow_single_cluster: False
   max_cluster_size: 0
   🗂️  use_umap: True
   🗂️  umap_n_neighbors: 15
   🗂️  umap_min_dist: 0.05
   🗂️  umap_n_components: 100
🎯 [BERTOPIC] Parametri consistenti configurati:
   📊 HDBSCAN: 10 parametri
   📊 UMAP: 5 parametri
🔧 HDBSCANClusterer inizializzato:
   min_cluster_size: 21
   min_samples: 14
   metric: euclidean
   cluster_selection_epsilon: 0.13
   🗂️  UMAP enabled: True
     📏 n_neighbors: 15
     📐 min_dist: 0.05
     📊 n_components: 100
     🎯 metric: cosine
   🚀 GPU enabled: True
   💾 GPU memory limit: 80%
   🔄 CPU fallback: True
   ⚠️  [GPU MODE] Limitazioni cuML HDBSCAN:
     🚫 leaf_size=40 sarà IGNORATO su GPU
     ✅ Parametri supportati: cluster_selection_method, alpha, allow_single_cluster
🎯 [DEBUG REACT] Parametri configurati:
   cluster_selection_method: leaf
   alpha: 0.7
   allow_single_cluster: False
🧠 Inizializzazione memoria semantica...
🔧 TokenizationManager inizializzato:
   📊 Modello tokenizer: cl100k_base
   🔢 Limite massimo token: 8000
   ✂️  Strategia troncamento: start
✅ TokenizationManager integrato in LaBSE per gestione conversazioni lunghe
🚀 Inizializzazione LaBSE embedder su device: cuda
📥 Caricamento modello sentence-transformers/LaBSE...
🚀 Caricamento diretto su GPU...
✅ Modello caricato con successo!
📊 Dimensione embedding: 768
🔧 Device: cuda
🎮 GPU: NVIDIA A10G
💾 GPU Memory: 23.7 GB
📈 GPU Memory utilizzata: 1.89 GB
� Primo parametro su device: cuda:0
🧪 Test del modello LaBSE...
🔍 Encoding 3 testi con LaBSE su device cuda...

🔍 TOKENIZZAZIONE PREVENTIVA LABSE CLUSTERING
============================================================
🔍 ELABORAZIONE CONVERSAZIONI PER CLUSTERING
   📊 Numero conversazioni: 3
   🆔 Session IDs forniti: No

📊 STATISTICHE ELABORAZIONE:
   🔢 Conversazioni totali: 3
   ✂️  Conversazioni troncate: 0
   📏 Token originali totali: 20
   📐 Token finali totali: 20
   📊 Range token: 6 - 7
✅ Tokenizzazione LaBSE completata:
   📊 Conversazioni processate: 3
   📊 Conversazioni troncate: 0
   📊 Token limite configurato: 8000
   ✅ Tutte le conversazioni entro i limiti, nessun troncamento
============================================================
✅ Embedding generati: shape (3, 768)
✅ Test modello completato con successo!
   Shape: (3, 768)
   Norme: [0.99999994 1.         1.        ]
   Device: cuda
🎯 Modello pronto per l'uso!
🧠 SemanticMemoryManager inizializzato
  🎯 Soglia riutilizzo etichette: 0.8
  🔍 Soglia similarità semantica: 0.8
  💾 Cache path: semantic_cache/humanitas_015007d9_memory
🔗 Inizializzazione ensemble classifier avanzato...
🔍 ML Ensemble Debugger inizializzato e ATTIVO
   📝 Debug file: ./debug_logs/ml_debug.log
🔍 ML Ensemble Debugger attivato
🔧 Tentativo di inizializzazione IntelligentClassifier tramite LLMFactory...
🧠 GPU Memory prima di LLM: 1.8GB/22.1GB (free: 20.3GB)
✅ Memoria GPU sufficiente, inizializzazione LLM tramite Factory...
🎛️ Configurazioni AI saranno salvate su DATABASE MySQL
🎛️ AIConfigurationService inizializzato
   � Backend: DATABASE MySQL
   🔑 OpenAI API Key: ✅ Configurata
🏭 LLM Factory inizializzato con cache invalidation intelligente
🔍 LLM FACTORY DEBUG: Chiamata ai_config_service.get_tenant_configuration(humanitas) normale...
🔄 DatabaseAI: Modalità legacy - risolvo tenant_id humanitas
🔍 [DEBUG] Query eseguita per tenant_id: 015007d9-d413-11ef-86a5-96000228e7fe
🔍 [DEBUG] Risultato database: {'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'tenant_slug': 'humanitas', 'embedding_engine': 'labse', 'llm_engine': 'mistral:7b', 'embedding_config': None, 'llm_config': None, 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 28, 16, 51, 54)}
🔍 [DEBUG AIConfig] db_config ricevuto: {'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'tenant_slug': 'humanitas', 'embedding_engine': 'labse', 'llm_engine': 'mistral:7b', 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 28, 16, 51, 54), 'embedding_config': {}, 'llm_config': {}}
🔍 [DEBUG AIConfig] llm_engine nel db_config: mistral:7b
🎯 LLM FACTORY DEBUG: Modello normale = 'mistral:7b'
🔧 Creazione LLM classifier mistral:7b per tenant humanitas
🚀 LLM FACTORY DEBUG: Avvio creazione nuovo classifier modello 'mistral:7b'
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
✅ Tenant risolto da slug (DB TAG locale): Humanitas (humanitas) UUID=015007d9-d413-11ef-86a5-96000228e7fe
🔍 LLM Debugger inizializzato e ATTIVO
   📝 Debug file: ./debug_logs/llm_debug.log
   🎨 Visual formatting: True
Connessione al database TAG stabilita con successo
📋 Recuperati 0 tag dal database TAGS per tenant 015007d9-d413-11ef-86a5-96000228e7fe
Connessione al database TAG chiusa
🔧 TokenizationManager inizializzato:
   📊 Modello tokenizer: cl100k_base
   🔢 Limite massimo token: 8000
   ✂️  Strategia troncamento: start
✅ LLM FACTORY DEBUG: Nuovo classifier creato: mistral:7b
✅ LLM Classifier mistral:7b (mistral:7b) creato e cached per tenant humanitas
🏭 LLM classifier ottenuto tramite Factory per tenant humanitas
🤖 LLM classifier creato automaticamente nell'ensemble: mistral:7b
💡 Possibile fine-tuning per humanitas
🔗 Advanced Ensemble Classifier inizializzato
   🧠 LLM weight: 0.60
   🤖 ML weight: 0.40
   🎯 Confidence threshold: 0.7
   🔄 Adaptive weights: True
   👤 Disaccordi gestiti da QualityGateEngine
⚠️ Nessun modello trovato per tenant 'humanitas' nella directory models/
⏸️ Riaddestramento automatico disabilitato (modalità supervisione/API)
   💡 Per abilitare, usare auto_retrain=True nell'inizializzazione
✅ Classificatore LLM disponibile nell'ensemble
👤 Inizializzazione trainer interattivo...
🎯 SIMPLE MANAGER: Richiesta embedder per tenant 015007d9-d413-11ef-86a5-96000228e7fe
📥 Primo embedder - creazione per tenant 015007d9-d413-11ef-86a5-96000228e7fe
🚀 CREATING FRESH EMBEDDER per tenant 015007d9-d413-11ef-86a5-96000228e7fe
🎛️ Configurazioni AI saranno salvate su DATABASE MySQL
🎛️ AIConfigurationService inizializzato
   � Backend: DATABASE MySQL
   🔑 OpenAI API Key: ✅ Configurata
🔄 DatabaseAI: Modalità legacy - risolvo tenant_id 015007d9-d413-11ef-86a5-96000228e7fe
🔧 FORCE NO CACHE: Bypass cache per tenant 015007d9-d413-11ef-86a5-96000228e7fe
🔥 FORCE NO CACHE: Bypasso cache e leggo DIRETTAMENTE dal database per tenant 015007d9-d413-11ef-86a5-96000228e7fe
🔍 [DEBUG] Query eseguita per tenant_id: 015007d9-d413-11ef-86a5-96000228e7fe
🔍 [DEBUG] Risultato database: {'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'tenant_slug': 'humanitas', 'embedding_engine': 'labse', 'llm_engine': 'mistral:7b', 'embedding_config': None, 'llm_config': None, 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 28, 16, 51, 54)}
🔍 [DEBUG AIConfig] db_config ricevuto: {'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'tenant_slug': 'humanitas', 'embedding_engine': 'labse', 'llm_engine': 'mistral:7b', 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 28, 16, 51, 54), 'embedding_config': {}, 'llm_config': {}}
🔍 [DEBUG AIConfig] llm_engine nel db_config: mistral:7b
🔍 SIMPLE MANAGER: Engine da DB per 015007d9-d413-11ef-86a5-96000228e7fe = 'labse'
🎯 Engine configurato: labse
🔧 DIRECT CREATE: labse
🔧 TokenizationManager inizializzato:
   📊 Modello tokenizer: cl100k_base
   🔢 Limite massimo token: 8000
   ✂️  Strategia troncamento: start
✅ TokenizationManager integrato in LaBSE per gestione conversazioni lunghe
🚀 Inizializzazione LaBSE embedder su device: cuda
📥 Caricamento modello sentence-transformers/LaBSE...
🚀 Caricamento diretto su GPU...
✅ Modello caricato con successo!
📊 Dimensione embedding: 768
🔧 Device: cuda
🎮 GPU: NVIDIA A10G
💾 GPU Memory: 23.7 GB
📈 GPU Memory utilizzata: 3.78 GB
� Primo parametro su device: cuda:0
🧪 Test del modello LaBSE...
🔍 Encoding 3 testi con LaBSE su device cuda...

🔍 TOKENIZZAZIONE PREVENTIVA LABSE CLUSTERING
============================================================
🔍 ELABORAZIONE CONVERSAZIONI PER CLUSTERING
   📊 Numero conversazioni: 3
   🆔 Session IDs forniti: No

📊 STATISTICHE ELABORAZIONE:
   🔢 Conversazioni totali: 3
   ✂️  Conversazioni troncate: 0
   📏 Token originali totali: 20
   📐 Token finali totali: 20
   📊 Range token: 6 - 7
✅ Tokenizzazione LaBSE completata:
   📊 Conversazioni processate: 3
   📊 Conversazioni troncate: 0
   📊 Token limite configurato: 8000
   ✅ Tutte le conversazioni entro i limiti, nessun troncamento
============================================================
✅ Embedding generati: shape (3, 768)
✅ Test modello completato con successo!
   Shape: (3, 768)
   Norme: [0.99999994 1.         1.        ]
   Device: cuda
🎯 Modello pronto per l'uso!
✅ FRESH EMBEDDER creato: LaBSEEmbedder per tenant 015007d9-d413-11ef-86a5-96000228e7fe
🧠 Inizializzazione dedupplicatore intelligente...
💾 [FASE 1: INIZIALIZZAZIONE] Caricamento memoria semantica...
📦 Memoria semantica caricata da cache (4089 sessioni)
   📊 Campioni: 1797
   🏷️ Tag: 250
✅ [FASE 1: INIZIALIZZAZIONE] Completata in 7.70s
🎯 [FASE 1: INIZIALIZZAZIONE] Pipeline pronta per l'uso!
✅ Pipeline humanitas inizializzata
🚀 TRAINING SUPERVISIONATO CON DATASET COMPLETO
  📊 Estrazione: TUTTE le discussioni dal database
  🧩 Clustering: Su tutto il dataset disponibile
  👤 Review umana: Max 500 sessioni rappresentative
🎯 Confidence threshold aggiornato a: 0.9
🎓 TRAINING SUPERVISIONATO AVANZATO
� NUOVA LOGICA:
  🔄 Estrazione: TUTTE le discussioni dal database
  🧩 Clustering: Su tutto il dataset completo
  👤 Review umana: Massimo 500 sessioni rappresentative
--------------------------------------------------
📊 FASE 1: ESTRAZIONE COMPLETA DATASET

� [FASE 2: ESTRAZIONE] Avvio estrazione sessioni...
🏥 [FASE 2: ESTRAZIONE] Tenant: humanitas
📅 [FASE 2: ESTRAZIONE] Giorni indietro: 7
🔄 [FASE 2: ESTRAZIONE] Modalità COMPLETA attivata
🎯 [FASE 2: ESTRAZIONE] Ignorando limite - estrazione totale dataset
� [FASE 2: ESTRAZIONE] Modalità: COMPLETA
� [FASE 2: ESTRAZIONE] Connessione database...
📊 [DEBUG ONLY_USER] Estrazione sessioni aggregate dal schema 'humanitas'...
🎯 [DEBUG ONLY_USER] Parametro only_user = False (tenant_id: 015007d9-d413-11ef-86a5-96000228e7fe)
📄 [DEBUG ONLY_USER] Estrazione completa (senza limite)
📄 [DEBUG ONLY_USER] Filtraggio standard: messaggi USER e AGENT
🔍 [DEBUG ONLY_USER] Esecuzione query per leggere conversazioni dal schema 'humanitas'...
🎯 [DEBUG ONLY_USER] Parametro only_user = False
📋 [DEBUG ONLY_USER] Filtro applicato: WHERE csm.said_by IN ('USER', 'AGENT')
Connessione al database MySQL stabilita con successo
✅ [DEBUG ONLY_USER] Query eseguita con successo!
📊 [DEBUG ONLY_USER] Totale righe: 21129
👤 [DEBUG ONLY_USER] Messaggi USER: 10546
🤖 [DEBUG ONLY_USER] Messaggi AGENT: 10583
✅ [DEBUG ONLY_USER] Filtro funziona correttamente!
✅ Trovate 21129 righe da aggregare
🔄 [DEBUG ONLY_USER] Inizio generazione testo completo per 4215 sessioni
🔍 [DEBUG ONLY_USER] Sessione 0008ef4f-c2f4-4f5e-933e-646574f3638c: 3 USER, 3 AGENT
📝 [DEBUG ONLY_USER] Sessione 0008ef4f-c2f4-4f5e-933e-646574f3638c testo finale:
   [UTENTE] tags: 2
   [ASSISTENTE] tags: 2
   Lunghezza testo: 554 caratteri
🔍 [DEBUG ONLY_USER] Sessione 000b61d7-4431-40d2-b83c-9abbb70c98be: 4 USER, 4 AGENT
📝 [DEBUG ONLY_USER] Sessione 000b61d7-4431-40d2-b83c-9abbb70c98be testo finale:
   [UTENTE] tags: 3
   [ASSISTENTE] tags: 3
   Lunghezza testo: 1133 caratteri
🔍 [DEBUG ONLY_USER] Sessione 00160700-ac7f-463d-8fa0-fe57f74a73e6: 4 USER, 4 AGENT
✅ Aggregate 4215 sessioni uniche
🔄 Saltati 8430 messaggi di benvenuto (primi 2 per sessione)
🔄 Sessioni vuote (solo benvenuto): 887
📥 [FASE 2: ESTRAZIONE] Sessioni grezze: 4215
🔍 [FASE 2: ESTRAZIONE] Filtraggio sessioni...
🔍 Filtraggio sessioni vuote/irrilevanti...
✅ Filtro completato:
  📊 Sessioni originali: 4215
  ❌ Sessioni scartate: 887
  ✅ Sessioni valide: 3328
✅ [FASE 2: ESTRAZIONE] Completata in 0.59s
📊 [FASE 2: ESTRAZIONE] Dataset completo: 3328 sessioni
🗑️ [FASE 2: ESTRAZIONE] Filtrate: 887 sessioni vuote/irrilevanti
🎯 [FASE 2: ESTRAZIONE] Pronte per clustering completo
✅ Dataset completo: 3328 sessioni totali

📊 FASE 2: CLUSTERING COMPLETO

🚀 [FASE 4: CLUSTERING] Avvio clustering intelligente...
📊 [FASE 4: CLUSTERING] Dataset: 3328 sessioni
🎯 [FASE 4: CLUSTERING] Modalità: INTELLIGENTE
🧠 [FASE 4: CLUSTERING] Clustering incrementale (se possibile)...

🚀 [FASE 3: EMBEDDINGS] Avvio generazione embeddings...
� [FASE 3: EMBEDDINGS] Dataset: 3328 sessioni
📊 [FASE 3: EMBEDDINGS] Caratteristiche testo:
   📏 Lunghezza media: 1011 caratteri
   📏 Lunghezza massima: 29104 caratteri
   📏 Lunghezza minima: 75 caratteri
🧠 [FASE 3: EMBEDDINGS] Generazione embeddings...
🔄 LAZY LOADING: Caricamento embedder dinamico per tenant 'humanitas'
🎯 SimpleEmbeddingManager inizializzato
🔄 SIMPLE MANAGER: Normalizzato 'humanitas' -> '015007d9-d413-11ef-86a5-96000228e7fe'
🎯 SIMPLE MANAGER: Richiesta embedder per tenant 015007d9-d413-11ef-86a5-96000228e7fe
📥 Primo embedder - creazione per tenant 015007d9-d413-11ef-86a5-96000228e7fe
🚀 CREATING FRESH EMBEDDER per tenant 015007d9-d413-11ef-86a5-96000228e7fe
🎛️ Configurazioni AI saranno salvate su DATABASE MySQL
🎛️ AIConfigurationService inizializzato
   � Backend: DATABASE MySQL
   🔑 OpenAI API Key: ✅ Configurata
🔄 DatabaseAI: Modalità legacy - risolvo tenant_id 015007d9-d413-11ef-86a5-96000228e7fe
🔧 FORCE NO CACHE: Bypass cache per tenant 015007d9-d413-11ef-86a5-96000228e7fe
🔥 FORCE NO CACHE: Bypasso cache e leggo DIRETTAMENTE dal database per tenant 015007d9-d413-11ef-86a5-96000228e7fe
🔍 [DEBUG] Query eseguita per tenant_id: 015007d9-d413-11ef-86a5-96000228e7fe
🔍 [DEBUG] Risultato database: {'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'tenant_slug': 'humanitas', 'embedding_engine': 'labse', 'llm_engine': 'mistral:7b', 'embedding_config': None, 'llm_config': None, 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 28, 16, 51, 54)}
🔍 [DEBUG AIConfig] db_config ricevuto: {'tenant_id': '015007d9-d413-11ef-86a5-96000228e7fe', 'tenant_name': 'Humanitas', 'tenant_slug': 'humanitas', 'embedding_engine': 'labse', 'llm_engine': 'mistral:7b', 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 28, 16, 51, 54), 'embedding_config': {}, 'llm_config': {}}
🔍 [DEBUG AIConfig] llm_engine nel db_config: mistral:7b
🔍 SIMPLE MANAGER: Engine da DB per 015007d9-d413-11ef-86a5-96000228e7fe = 'labse'
🎯 Engine configurato: labse
🔧 DIRECT CREATE: labse
🔧 TokenizationManager inizializzato:
   📊 Modello tokenizer: cl100k_base
   🔢 Limite massimo token: 8000
   ✂️  Strategia troncamento: start
✅ TokenizationManager integrato in LaBSE per gestione conversazioni lunghe
🚀 Inizializzazione LaBSE embedder su device: cuda
📥 Caricamento modello sentence-transformers/LaBSE...
🚀 Caricamento diretto su GPU...
✅ Modello caricato con successo!
📊 Dimensione embedding: 768
🔧 Device: cuda
🎮 GPU: NVIDIA A10G
💾 GPU Memory: 23.7 GB
📈 GPU Memory utilizzata: 5.67 GB
� Primo parametro su device: cuda:0
🧪 Test del modello LaBSE...
🔍 Encoding 3 testi con LaBSE su device cuda...

🔍 TOKENIZZAZIONE PREVENTIVA LABSE CLUSTERING
============================================================
🔍 ELABORAZIONE CONVERSAZIONI PER CLUSTERING
   📊 Numero conversazioni: 3
   🆔 Session IDs forniti: No

📊 STATISTICHE ELABORAZIONE:
   🔢 Conversazioni totali: 3
   ✂️  Conversazioni troncate: 0
   📏 Token originali totali: 20
   📐 Token finali totali: 20
   📊 Range token: 6 - 7
✅ Tokenizzazione LaBSE completata:
   📊 Conversazioni processate: 3
   📊 Conversazioni troncate: 0
   📊 Token limite configurato: 8000
   ✅ Tutte le conversazioni entro i limiti, nessun troncamento
============================================================
✅ Embedding generati: shape (3, 768)
✅ Test modello completato con successo!
   Shape: (3, 768)
   Norme: [0.99999994 1.         1.        ]
   Device: cuda
🎯 Modello pronto per l'uso!
✅ FRESH EMBEDDER creato: LaBSEEmbedder per tenant 015007d9-d413-11ef-86a5-96000228e7fe
✅ Embedder caricato per tenant UUID 'humanitas': LaBSEEmbedder
🔍 Encoding 3328 testi con LaBSE su device cuda...

🔍 TOKENIZZAZIONE PREVENTIVA LABSE CLUSTERING
============================================================
🔍 ELABORAZIONE CONVERSAZIONI PER CLUSTERING
   📊 Numero conversazioni: 3328
   🆔 Session IDs forniti: Sì
✂️  TRONCAMENTO NECESSARIO:
   📊 Token originali: 8588
   🎯 Target token: 8000
   ⚡ Strategia: start
   ✅ Token finali: 8000
   📏 Caratteri rimossi: 1927
   ✂️  Conversazione 3fe6b43b-3d09-4ed4-9002-d8a1f2b64291: 8588 → 8000 token
✂️  TRONCAMENTO NECESSARIO:
   📊 Token originali: 8227
   🎯 Target token: 8000
   ⚡ Strategia: start
   ✅ Token finali: 8000
   📏 Caratteri rimossi: 710
   ✂️  Conversazione dbd64c8d-dcd6-4b19-a8ab-7f3760898dfe: 8227 → 8000 token

📊 STATISTICHE ELABORAZIONE:
   🔢 Conversazioni totali: 3328
   ✂️  Conversazioni troncate: 2
   📏 Token originali totali: 1,011,590
   📐 Token finali totali: 1,010,775
   📊 Range token: 26 - 8588
   💾 Riduzione totale: 0.1%
✅ Tokenizzazione LaBSE completata:
   📊 Conversazioni processate: 3328
   📊 Conversazioni troncate: 2
   📊 Token limite configurato: 8000
   ✂️  2 conversazioni TRONCATE per rispettare limite token
============================================================
