ğŸš€ UMAP disponibile per riduzione dimensionale!
ğŸš€ cuML GPU clustering disponibile!
ğŸ’¥ EmbeddingDestroyer inizializzato - Ready to destroy and rebuild!
ğŸ¯ SimpleEmbeddingManager inizializzato
ğŸ›ï¸ Configurazioni AI saranno salvate su DATABASE MySQL
ğŸ›ï¸ AIConfigurationService inizializzato
   ï¿½ Backend: DATABASE MySQL
   ğŸ”‘ OpenAI API Key: âœ… Configurata
ğŸ­ EmbeddingEngineFactory inizializzata
ğŸ¯ EmbeddingManager inizializzato
âœ… Blueprint esempi inizializzato correttamente
ğŸš€ Avvio server Flask - Debug: True
 * Serving Flask app 'server'
 * Debug mode: on
ğŸ” [DEBUG] GET /api/tenants - Avvio richiesta tenant con oggetti Tenant
ğŸ” [DEBUG] Chiamo get_available_tenants() per oggetti Tenant...
ğŸ¢ Recuperati 22 oggetti Tenant dalla tabella TAG.tenants
ğŸ” [DEBUG] Recuperati 22 oggetti Tenant dal database
ğŸ” [DEBUG] Primi 3 tenant convertiti: [{'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'tenant_name': 'Alleanza', 'tenant_slug': 'alleanza', 'is_active': True}, {'tenant_id': '6bc4f06f-742e-11f0-acb8-96000228e7fe', 'tenant_name': 'BluPantheon', 'tenant_slug': 'blupantheon', 'is_active': True}, {'tenant_id': '0f9d6e90-d319-11ef-86a5-96000228e7fe', 'tenant_name': 'Boots', 'tenant_slug': 'boots', 'is_active': True}]
ğŸ” [DEBUG] Invio risposta con 22 tenant
ğŸ”§ Creazione MongoClassificationReader per cliente: 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ” Risoluzione tenant da UUID: 015007d9-d413-11ef-86a5-96000228e7fe
ğŸ” [DEBUG] GET /api/tenants - Avvio richiesta tenant con oggetti Tenant
ğŸ” [DEBUG] Chiamo get_available_tenants() per oggetti Tenant...
ğŸ” [DEBUG] GET /api/prompts/a0fd7600-f4f7-11ef-9315-96000228e7fe/status - Avvio richiesta
ğŸ” [DEBUG] API: Recupero status prompt per tenant: a0fd7600-f4f7-11ef-9315-96000228e7fe
âœ… [DEBUG] Riconosciuto come tenant_id UUID: a0fd7600-f4f7-11ef-9315-96000228e7fe
ğŸ” [DEBUG] Inizializzo PromptManager...
ğŸ” [DEBUG] Chiamo get_all_prompts_for_tenant(a0fd7600-f4f7-11ef-9315-96000228e7fe)...
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
âœ… Tenant risolto (DB TAG locale): Humanitas (humanitas) UUID=015007d9-d413-11ef-86a5-96000228e7fe
âœ… Tenant risolto: Humanitas (015007d9-d413-11ef-86a5-96000228e7fe)
ğŸ“Š Collection generata: humanitas_015007d9-d413-11ef-86a5-96000228e7fe per tenant Humanitas
âœ… MongoClassificationReader inizializzato per tenant: Humanitas
   ğŸ“Š Collection: humanitas_015007d9-d413-11ef-86a5-96000228e7fe
   ğŸ¢ Database: classificazioni
âœ… MongoClassificationReader creato per tenant: Humanitas (humanitas)
ğŸ“Š Collection generata: humanitas_015007d9-d413-11ef-86a5-96000228e7fe per tenant Humanitas
   ğŸ“Š Collection: humanitas_015007d9-d413-11ef-86a5-96000228e7fe
âœ… Connesso a MongoDB database: classificazioni
ğŸ“Š Collection generata: humanitas_015007d9-d413-11ef-86a5-96000228e7fe per tenant Humanitas
ğŸ” Review Queue recuperate 20 sessioni (representatives: True, propagated: True, outliers: True)
ğŸ·ï¸ Recupero etichette per tenant: Humanitas
ğŸ¢ Recuperati 22 oggetti Tenant dalla tabella TAG.tenants
ğŸ” [DEBUG] Recuperati 22 oggetti Tenant dal database
ğŸ” [DEBUG] Primi 3 tenant convertiti: [{'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'tenant_name': 'Alleanza', 'tenant_slug': 'alleanza', 'is_active': True}, {'tenant_id': '6bc4f06f-742e-11f0-acb8-96000228e7fe', 'tenant_name': 'BluPantheon', 'tenant_slug': 'blupantheon', 'is_active': True}, {'tenant_id': '0f9d6e90-d319-11ef-86a5-96000228e7fe', 'tenant_name': 'Boots', 'tenant_slug': 'boots', 'is_active': True}]
ğŸ” [DEBUG] Invio risposta con 22 tenant
ğŸ“Š Calcolo statistiche per tenant: Humanitas
ğŸ” [DEBUG] Recuperati 5 prompt dal PromptManager
ğŸ” [DEBUG] Statistiche: 5/5 attivi, 0 inattivi
âœ… [DEBUG] Status calcolato: {'success': True, 'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'tenant_name': 'Alleanza', 'total_prompts': 5, 'active_prompts': 5, 'inactive_prompts': 0, 'last_updated': '2025-08-25T08:54:43', 'status': 'ready', 'canOperate': True, 'requiredPrompts': [{'name': 'System Prompt', 'type': 'system', 'description': 'Prompt di sistema per la classificazione', 'exists': True}, {'name': 'User Template', 'type': 'user', 'description': 'Template per prompt utente', 'exists': True}, {'name': 'Classification Prompt', 'type': 'classification', 'description': 'Prompt per classificazione intelligente', 'exists': False}], 'missingCount': 1}
âœ… [DEBUG] Status prompt per tenant_id a0fd7600-f4f7-11ef-9315-96000228e7fe: 5/5 attivi
ğŸ” [DEBUG] Invio risposta JSON per status prompt
ğŸ” [DEBUG] GET /api/prompts/a0fd7600-f4f7-11ef-9315-96000228e7fe/status - Avvio richiesta
ğŸ” [DEBUG] API: Recupero status prompt per tenant: a0fd7600-f4f7-11ef-9315-96000228e7fe
âœ… [DEBUG] Riconosciuto come tenant_id UUID: a0fd7600-f4f7-11ef-9315-96000228e7fe
ğŸ” [DEBUG] Inizializzo PromptManager...
ğŸ” [DEBUG] Chiamo get_all_prompts_for_tenant(a0fd7600-f4f7-11ef-9315-96000228e7fe)...
ğŸ” [DEBUG] Recuperati 5 prompt dal PromptManager
ğŸ” [DEBUG] Statistiche: 5/5 attivi, 0 inattivi
âœ… [DEBUG] Status calcolato: {'success': True, 'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'tenant_name': 'Alleanza', 'total_prompts': 5, 'active_prompts': 5, 'inactive_prompts': 0, 'last_updated': '2025-08-25T08:54:43', 'status': 'ready', 'canOperate': True, 'requiredPrompts': [{'name': 'System Prompt', 'type': 'system', 'description': 'Prompt di sistema per la classificazione', 'exists': True}, {'name': 'User Template', 'type': 'user', 'description': 'Template per prompt utente', 'exists': True}, {'name': 'Classification Prompt', 'type': 'classification', 'description': 'Prompt per classificazione intelligente', 'exists': False}], 'missingCount': 1}
âœ… [DEBUG] Status prompt per tenant_id a0fd7600-f4f7-11ef-9315-96000228e7fe: 5/5 attivi
ğŸ” [DEBUG] Invio risposta JSON per status prompt
ğŸ” [DEBUG] GET /api/prompts/16c222a9-f293-11ef-9315-96000228e7fe/status - Avvio richiesta
ğŸ” [DEBUG] API: Recupero status prompt per tenant: 16c222a9-f293-11ef-9315-96000228e7fe
âœ… [DEBUG] Riconosciuto come tenant_id UUID: 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ” [DEBUG] Inizializzo PromptManager...
ğŸ” [DEBUG] Chiamo get_all_prompts_for_tenant(16c222a9-f293-11ef-9315-96000228e7fe)...
ğŸ”§ Creazione MongoClassificationReader per cliente: 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ” Risoluzione tenant da UUID: 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ” [DEBUG] Recuperati 5 prompt dal PromptManager
ğŸ” [DEBUG] Statistiche: 5/5 attivi, 0 inattivi
âœ… [DEBUG] Status calcolato: {'success': True, 'tenant_id': '16c222a9-f293-11ef-9315-96000228e7fe', 'tenant_name': 'Wopta', 'total_prompts': 5, 'active_prompts': 5, 'inactive_prompts': 0, 'last_updated': '2025-08-26T15:04:42', 'status': 'ready', 'canOperate': True, 'requiredPrompts': [{'name': 'System Prompt', 'type': 'system', 'description': 'Prompt di sistema per la classificazione', 'exists': True}, {'name': 'User Template', 'type': 'user', 'description': 'Template per prompt utente', 'exists': True}, {'name': 'Classification Prompt', 'type': 'classification', 'description': 'Prompt per classificazione intelligente', 'exists': False}], 'missingCount': 1}
âœ… [DEBUG] Status prompt per tenant_id 16c222a9-f293-11ef-9315-96000228e7fe: 5/5 attivi
ğŸ” [DEBUG] Invio risposta JSON per status prompt
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
âœ… Tenant risolto (DB TAG locale): Wopta (wopta) UUID=16c222a9-f293-11ef-9315-96000228e7fe
âœ… Tenant risolto: Wopta (16c222a9-f293-11ef-9315-96000228e7fe)
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
âœ… MongoClassificationReader inizializzato per tenant: Wopta
   ğŸ“Š Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   ğŸ¢ Database: classificazioni
âœ… MongoClassificationReader creato per tenant: Wopta (wopta)
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
   ğŸ“Š Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
âœ… Connesso a MongoDB database: classificazioni
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
ğŸ” Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
ğŸ·ï¸ Recupero etichette per tenant: Wopta
ğŸ“Š Calcolo statistiche per tenant: Wopta
ğŸ¯ TRAINING SUPERVISIONATO - Cliente: 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ“‹ Parametri utente semplificati:
  ï¿½ Max sessioni review: 500
  ğŸ¯ Soglia confidenza: 0.9
  ğŸ”„ Forza review: False
  âš–ï¸  Soglia disagreement: 0.3
ğŸ”§ Inizializzazione pipeline per cliente: 16c222a9-f293-11ef-9315-96000228e7fe (con lock)
âš ï¸ [PIPELINE] DEPRECATO: uso di tenant_slug '16c222a9-f293-11ef-9315-96000228e7fe' - convertendo a oggetto Tenant
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
âœ… Tenant risolto (DB TAG locale): Wopta (wopta) UUID=16c222a9-f293-11ef-9315-96000228e7fe
ğŸ”„ [PIPELINE] Conversione completata: Wopta (16c222a9-f293-11ef-9315-96000228e7fe)
âœ… [CONFIG] Configurazione base caricata da /home/ubuntu/classificatore/Utils/../config.yaml
ğŸ¯ [PIPELINE CLUSTERING CONFIG] Caricati parametri personalizzati per tenant 16c222a9-f293-11ef-9315-96000228e7fe:
   allow_single_cluster: non_definito -> False
   alpha: non_definito -> 1
   cluster_selection_epsilon: non_definito -> 0.2
   cluster_selection_method: non_definito -> leaf
   max_cluster_size: non_definito -> 0
   metric: non_definito -> euclidean
   min_cluster_size: 5 -> 5
   min_samples: 3 -> 5
   only_user: non_definito -> False
   umap_metric: non_definito -> cosine
   umap_min_dist: non_definito -> 0.1
   umap_n_components: non_definito -> 17
   umap_n_neighbors: non_definito -> 30
   umap_random_state: non_definito -> 42
   use_umap: non_definito -> True

ğŸš€ [FASE 1: INIZIALIZZAZIONE] Avvio pipeline...
ğŸ¥ [FASE 1: INIZIALIZZAZIONE] Tenant: wopta
ğŸ¯ [FASE 1: INIZIALIZZAZIONE] Configurazione:
   ğŸ“Š Confidence threshold: 0.7
   ğŸ¤– Auto mode: True
   ğŸ”„ Auto retrain: False
ï¿½ [FASE 1: INIZIALIZZAZIONE] Inizializzazione lettore conversazioni...
âœ… [CONFIG] Configurazione base caricata da /home/ubuntu/classificatore/Utils/../config.yaml
âœ… [CONFIG] Config personalizzata tenant 16c222a9-f293-11ef-9315-96000228e7fe: 15 parametri
ğŸ¯ [ONLY_USER] Tenant 16c222a9-f293-11ef-9315-96000228e7fe: False (da config personalizzata)
ğŸ¯ [LETTORE] Tenant 16c222a9-f293-11ef-9315-96000228e7fe: only_user = False (da config tenant)
ï¿½ [FASE 1: INIZIALIZZAZIONE] Inizializzazione aggregator...
   ğŸ” Schema: 'wopta'
   ğŸ†” Tenant ID: '16c222a9-f293-11ef-9315-96000228e7fe'
ğŸ¯ [SESSION AGGREGATOR] Inizializzazione con oggetto Tenant: Wopta (16c222a9-f293-11ef-9315-96000228e7fe)
ğŸ¯ [ONLY_USER] Tenant 16c222a9-f293-11ef-9315-96000228e7fe: False (da config personalizzata)
ğŸ¯ [LETTORE] Tenant 16c222a9-f293-11ef-9315-96000228e7fe: only_user = False (da config tenant)
ï¿½ [ONLY_USER] Schema None: False (legacy - no tenant_id)
ğŸ§  [FASE 1: INIZIALIZZAZIONE] Sistema embedder dinamico (lazy loading)
ğŸ”§ [FASE 1: INIZIALIZZAZIONE] Parametri clustering:
   ğŸ“Š Min cluster size: 5
   ğŸ“Š Min samples: 5
ğŸ› DEBUG CLUSTER_ALPHA - PRIMA:
   ğŸ“‹ clustering_config.get('alpha', 1.0): 1
   ğŸ“‹ Type: <class 'int'>
ğŸ› DEBUG CLUSTER_ALPHA - DOPO CONVERSIONE:
   ğŸ“‹ cluster_alpha: 1.0
   ğŸ“‹ Type: <class 'float'>
ğŸ› DEBUG CLUSTER_ALPHA - FINALE:
   ğŸ“‹ cluster_alpha finale: 1.0
   ğŸ“‹ Type finale: <class 'float'>
   ğŸ“‹ Alpha > 0: True
âœ… [CONFIG] Config personalizzata tenant 16c222a9-f293-11ef-9315-96000228e7fe: 15 parametri
ğŸ—‚ï¸  [UMAP] Parametri per tenant 16c222a9-f293-11ef-9315-96000228e7fe:
   use_umap: True
   n_neighbors: 30
   min_dist: 0.1
   n_components: 17
   metric: cosine
ğŸ”§ [FIX DEBUG] Parametri tenant passati a HDBSCANClusterer:
   min_cluster_size: 5
   min_samples: 5
   alpha: 1.0
   cluster_selection_method: leaf
   cluster_selection_epsilon: 0.2
   metric: euclidean
   allow_single_cluster: False
   max_cluster_size: 0
   ğŸ—‚ï¸  use_umap: True
   ğŸ—‚ï¸  umap_n_neighbors: 30
   ğŸ—‚ï¸  umap_min_dist: 0.1
   ğŸ—‚ï¸  umap_n_components: 17
ğŸ¯ [BERTOPIC] Parametri consistenti configurati:
   ğŸ“Š HDBSCAN: 10 parametri
   ğŸ“Š UMAP: 5 parametri
ğŸ”§ HDBSCANClusterer inizializzato:
   min_cluster_size: 5
   min_samples: 5
   metric: euclidean
   cluster_selection_epsilon: 0.2
   ğŸ—‚ï¸  UMAP enabled: True
     ğŸ“ n_neighbors: 30
     ğŸ“ min_dist: 0.1
     ğŸ“Š n_components: 17
     ğŸ¯ metric: cosine
   ğŸš€ GPU enabled: True
   ğŸ’¾ GPU memory limit: 80%
   ğŸ”„ CPU fallback: True
   âš ï¸  [GPU MODE] Limitazioni cuML HDBSCAN:
     ğŸš« leaf_size=40 sarÃ  IGNORATO su GPU
     âœ… Parametri supportati: cluster_selection_method, alpha, allow_single_cluster
ğŸ¯ [DEBUG REACT] Parametri configurati:
   cluster_selection_method: leaf
   alpha: 1.0
   allow_single_cluster: False
ğŸ§  Inizializzazione memoria semantica...
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
âœ… MongoClassificationReader inizializzato per tenant: Wopta
   ğŸ“Š Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   ğŸ¢ Database: classificazioni
ğŸ”§ TokenizationManager inizializzato:
   ğŸ“Š Modello tokenizer: cl100k_base
   ğŸ”¢ Limite massimo token: 8000
   âœ‚ï¸  Strategia troncamento: start
âœ… TokenizationManager integrato in LaBSE per gestione conversazioni lunghe
ğŸš€ Inizializzazione LaBSE embedder su device: cuda
ğŸ“¥ Caricamento modello sentence-transformers/LaBSE...
ğŸš€ Caricamento diretto su GPU...
âœ… Modello caricato con successo!
ğŸ“Š Dimensione embedding: 768
ğŸ”§ Device: cuda
ğŸ® GPU: NVIDIA A10G
ğŸ’¾ GPU Memory: 23.7 GB
ğŸ“ˆ GPU Memory utilizzata: 1.89 GB
ï¿½ Primo parametro su device: cuda:0
ğŸ§ª Test del modello LaBSE...
ğŸ” Encoding 3 testi con LaBSE su device cuda...

ğŸ” TOKENIZZAZIONE PREVENTIVA LABSE CLUSTERING
============================================================
ğŸ” ELABORAZIONE CONVERSAZIONI PER CLUSTERING
   ğŸ“Š Numero conversazioni: 3
   ğŸ†” Session IDs forniti: No

ğŸ“Š STATISTICHE ELABORAZIONE:
   ğŸ”¢ Conversazioni totali: 3
   âœ‚ï¸  Conversazioni troncate: 0
   ğŸ“ Token originali totali: 20
   ğŸ“ Token finali totali: 20
   ğŸ“Š Range token: 6 - 7
âœ… Tokenizzazione LaBSE completata:
   ğŸ“Š Conversazioni processate: 3
   ğŸ“Š Conversazioni troncate: 0
   ğŸ“Š Token limite configurato: 8000
   âœ… Tutte le conversazioni entro i limiti, nessun troncamento
============================================================
âœ… Embedding generati: shape (3, 768)
âœ… Test modello completato con successo!
   Shape: (3, 768)
   Norme: [0.99999994 1.         1.        ]
   Device: cuda
ğŸ¯ Modello pronto per l'uso!
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
âœ… MongoClassificationReader inizializzato per tenant: Wopta
   ğŸ“Š Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   ğŸ¢ Database: classificazioni
ğŸ§  SemanticMemoryManager inizializzato
  ğŸ¯ Soglia riutilizzo etichette: 0.8
  ğŸ” Soglia similaritÃ  semantica: 0.8
  ğŸ’¾ Cache path: semantic_cache/wopta_16c222a9_memory
ğŸ”— Inizializzazione ensemble classifier avanzato...
ğŸ” ML Ensemble Debugger inizializzato e ATTIVO
   ğŸ“ Debug file: ./debug_logs/ml_debug.log
ğŸ” ML Ensemble Debugger attivato
ğŸ”§ Tentativo di inizializzazione IntelligentClassifier tramite LLMFactory...
ğŸ§  GPU Memory prima di LLM: 1.8GB/22.1GB (free: 20.3GB)
âœ… Memoria GPU sufficiente, inizializzazione LLM tramite Factory...
ğŸ›ï¸ Configurazioni AI saranno salvate su DATABASE MySQL
ğŸ›ï¸ AIConfigurationService inizializzato
   ï¿½ Backend: DATABASE MySQL
   ğŸ”‘ OpenAI API Key: âœ… Configurata
ğŸ­ LLM Factory inizializzato con cache invalidation intelligente
ğŸ” LLM FACTORY DEBUG: Chiamata ai_config_service.get_tenant_configuration(wopta) normale...
ğŸ”„ DatabaseAI: ModalitÃ  legacy - risolvo tenant_id wopta
ğŸ” [DEBUG] Query eseguita per tenant_id: 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ” [DEBUG] Risultato database: {'tenant_id': '16c222a9-f293-11ef-9315-96000228e7fe', 'tenant_name': 'Wopta', 'tenant_slug': 'wopta', 'embedding_engine': 'labse', 'llm_engine': 'gpt-oss:20b', 'embedding_config': None, 'llm_config': None, 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 29, 16, 40, 1)}
ğŸ” [DEBUG AIConfig] db_config ricevuto: {'tenant_id': '16c222a9-f293-11ef-9315-96000228e7fe', 'tenant_name': 'Wopta', 'tenant_slug': 'wopta', 'embedding_engine': 'labse', 'llm_engine': 'gpt-oss:20b', 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 29, 16, 40, 1), 'embedding_config': {}, 'llm_config': {}}
ğŸ” [DEBUG AIConfig] llm_engine nel db_config: gpt-oss:20b
ğŸ¯ LLM FACTORY DEBUG: Modello normale = 'gpt-oss:20b'
ğŸ”§ Creazione LLM classifier gpt-oss:20b per tenant wopta
ğŸš€ LLM FACTORY DEBUG: Avvio creazione nuovo classifier modello 'gpt-oss:20b'
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
âœ… Tenant risolto da slug (DB TAG locale): Wopta (wopta) UUID=16c222a9-f293-11ef-9315-96000228e7fe
ğŸ” LLM Debugger inizializzato e ATTIVO
   ğŸ“ Debug file: ./debug_logs/llm_debug.log
   ğŸ¨ Visual formatting: True
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
âœ… MongoClassificationReader inizializzato per tenant: Wopta
   ğŸ“Š Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   ğŸ¢ Database: classificazioni
ğŸ—„ï¸ MongoClassificationReader inizializzato per tenant: Wopta
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
âœ… MongoClassificationReader inizializzato per tenant: Wopta
   ğŸ“Š Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   ğŸ¢ Database: classificazioni
Connessione al database TAG stabilita con successo
ğŸ“‹ Recuperati 0 tag dal database TAGS per tenant 16c222a9-f293-11ef-9315-96000228e7fe
Connessione al database TAG chiusa
ğŸ”§ TokenizationManager inizializzato:
   ğŸ“Š Modello tokenizer: cl100k_base
   ğŸ”¢ Limite massimo token: 8000
   âœ‚ï¸  Strategia troncamento: start
âœ… LLM FACTORY DEBUG: Nuovo classifier creato: gpt-oss:20b
âœ… LLM Classifier gpt-oss:20b (gpt-oss:20b) creato e cached per tenant wopta
ğŸ­ LLM classifier ottenuto tramite Factory per tenant wopta
ğŸ¤– LLM classifier creato automaticamente nell'ensemble: gpt-oss:20b
ğŸ’¡ Possibile fine-tuning per wopta
ğŸ”— Advanced Ensemble Classifier inizializzato
   ğŸ§  LLM weight: 0.60
   ğŸ¤– ML weight: 0.40
   ğŸ¯ Confidence threshold: 0.7
   ğŸ”„ Adaptive weights: True
   ğŸ‘¤ Disaccordi gestiti da QualityGateEngine
âš ï¸ Nessun modello trovato per tenant 'wopta' nella directory models/
â¸ï¸ Riaddestramento automatico disabilitato (modalitÃ  supervisione/API)
   ğŸ’¡ Per abilitare, usare auto_retrain=True nell'inizializzazione
âœ… Classificatore LLM disponibile nell'ensemble
ğŸ‘¤ Inizializzazione trainer interattivo...
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
âœ… MongoClassificationReader inizializzato per tenant: Wopta
   ğŸ“Š Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   ğŸ¢ Database: classificazioni
ğŸ¯ SIMPLE MANAGER: Richiesta embedder per tenant 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ“¥ Primo embedder - creazione per tenant 16c222a9-f293-11ef-9315-96000228e7fe
ğŸš€ CREATING FRESH EMBEDDER per tenant 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ›ï¸ Configurazioni AI saranno salvate su DATABASE MySQL
ğŸ›ï¸ AIConfigurationService inizializzato
   ï¿½ Backend: DATABASE MySQL
   ğŸ”‘ OpenAI API Key: âœ… Configurata
ğŸ”„ DatabaseAI: ModalitÃ  legacy - risolvo tenant_id 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ”§ FORCE NO CACHE: Bypass cache per tenant 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ”¥ FORCE NO CACHE: Bypasso cache e leggo DIRETTAMENTE dal database per tenant 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ” [DEBUG] Query eseguita per tenant_id: 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ” [DEBUG] Risultato database: {'tenant_id': '16c222a9-f293-11ef-9315-96000228e7fe', 'tenant_name': 'Wopta', 'tenant_slug': 'wopta', 'embedding_engine': 'labse', 'llm_engine': 'gpt-oss:20b', 'embedding_config': None, 'llm_config': None, 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 29, 16, 40, 1)}
ğŸ” [DEBUG AIConfig] db_config ricevuto: {'tenant_id': '16c222a9-f293-11ef-9315-96000228e7fe', 'tenant_name': 'Wopta', 'tenant_slug': 'wopta', 'embedding_engine': 'labse', 'llm_engine': 'gpt-oss:20b', 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 29, 16, 40, 1), 'embedding_config': {}, 'llm_config': {}}
ğŸ” [DEBUG AIConfig] llm_engine nel db_config: gpt-oss:20b
ğŸ” SIMPLE MANAGER: Engine da DB per 16c222a9-f293-11ef-9315-96000228e7fe = 'labse'
ğŸ¯ Engine configurato: labse
ğŸ”§ DIRECT CREATE: labse
ğŸ³ Tentativo connessione a servizio LaBSE dockerizzato...
ğŸ”— LaBSE Remote Client inizializzato
   ğŸ“¡ Service URL: http://localhost:8081
   â±ï¸  Timeout: 300s
   ğŸ”„ Max retries: 3
   ğŸ›¡ï¸ Fallback locale: True
ğŸ”§ Inizializzazione client remoto LaBSE...
âœ… Servizio embedding online e funzionante
âœ… Client remoto LaBSE inizializzato con successo
âœ… LaBSE Remote Client configurato con successo
âœ… FRESH EMBEDDER creato: LaBSERemoteClient per tenant 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ§  Inizializzazione dedupplicatore intelligente...
ğŸ’¾ [FASE 1: INIZIALIZZAZIONE] Caricamento memoria semantica...
ğŸ”„ Caricamento memoria semantica dal database...
ğŸ”„ Caricamento memoria semantica da MongoDB...
âŒ Errore caricamento memoria semantica: MongoClassificationReader.get_all_sessions() got an unexpected keyword argument 'client_name'
ğŸ“­ Inizializzata memoria semantica vuota
   ğŸ“Š Campioni: 0
   ğŸ·ï¸ Tag: 0
âœ… [FASE 1: INIZIALIZZAZIONE] Completata in 4.66s
ğŸ¯ [FASE 1: INIZIALIZZAZIONE] Pipeline pronta per l'uso!
âœ… Pipeline 16c222a9-f293-11ef-9315-96000228e7fe inizializzata
ğŸš€ TRAINING SUPERVISIONATO CON DATASET COMPLETO
  ğŸ“Š Estrazione: TUTTE le discussioni dal database
  ğŸ§© Clustering: Su tutto il dataset disponibile
  ğŸ‘¤ Review umana: Max 500 sessioni rappresentative
ğŸ¯ Confidence threshold aggiornato a: 0.9
ğŸ“ TRAINING SUPERVISIONATO AVANZATO
ï¿½ NUOVA LOGICA:
  ğŸ”„ Estrazione: TUTTE le discussioni dal database
  ğŸ§© Clustering: Su tutto il dataset completo
  ğŸ‘¤ Review umana: Massimo 500 sessioni rappresentative
--------------------------------------------------
ğŸ“Š FASE 1: ESTRAZIONE COMPLETA DATASET

ï¿½ [FASE 2: ESTRAZIONE] Avvio estrazione sessioni...
ğŸ¥ [FASE 2: ESTRAZIONE] Tenant: wopta
ğŸ“… [FASE 2: ESTRAZIONE] Giorni indietro: 7
ğŸ”„ [FASE 2: ESTRAZIONE] ModalitÃ  COMPLETA attivata
ğŸ¯ [FASE 2: ESTRAZIONE] Ignorando limite - estrazione totale dataset
ï¿½ [FASE 2: ESTRAZIONE] ModalitÃ : COMPLETA
ï¿½ [FASE 2: ESTRAZIONE] Connessione database...
ğŸ“Š [DEBUG ONLY_USER] Estrazione sessioni aggregate dal schema 'wopta'...
ğŸ¯ [DEBUG ONLY_USER] Parametro only_user = False (tenant_id: 16c222a9-f293-11ef-9315-96000228e7fe)
ğŸ“„ [DEBUG ONLY_USER] Estrazione completa (senza limite)
ğŸ“„ [DEBUG ONLY_USER] Filtraggio standard: messaggi USER e AGENT
ğŸ” [DEBUG ONLY_USER] Esecuzione query per leggere conversazioni dal schema 'wopta'...
ğŸ¯ [DEBUG ONLY_USER] Parametro only_user = False
ğŸ“‹ [DEBUG ONLY_USER] Filtro applicato: WHERE csm.said_by IN ('USER', 'AGENT')
Connessione al database MySQL stabilita con successo
âœ… [DEBUG ONLY_USER] Query eseguita con successo!
ğŸ“Š [DEBUG ONLY_USER] Totale righe: 12818
ğŸ‘¤ [DEBUG ONLY_USER] Messaggi USER: 6247
ğŸ¤– [DEBUG ONLY_USER] Messaggi AGENT: 6571
âœ… [DEBUG ONLY_USER] Filtro funziona correttamente!
âœ… Trovate 12818 righe da aggregare
ğŸ”„ [DEBUG ONLY_USER] Inizio generazione testo completo per 2972 sessioni
ğŸ” [DEBUG ONLY_USER] Sessione 000ffe7d-c11c-45eb-9ffb-ac29cdedd20d: 1 USER, 1 AGENT
ğŸ” [DEBUG ONLY_USER] Sessione 00142b8f-f304-48c3-8269-7b9a6281f0e2: 4 USER, 7 AGENT
ğŸ“ [DEBUG ONLY_USER] Sessione 00142b8f-f304-48c3-8269-7b9a6281f0e2 testo finale:
   [UTENTE] tags: 3
   [ASSISTENTE] tags: 6
   Lunghezza testo: 1741 caratteri
ğŸ” [DEBUG ONLY_USER] Sessione 0015d3a2-da00-4682-a567-2463ac8b7a13: 3 USER, 3 AGENT
ğŸš¨ SESSIONE CORROTTA RILEVATA: 2a41a0df-1a39-477f-ab6a-a58ba42e45bc
   Lunghezza messaggio: 382,296 caratteri
   Sample: AAAAAAEA//////7//v/+//7//f/6//r/+//6//r/+f/8//7//P/8//z///8AAP//AAAAAAEA/v/9//7//v8AAP//AAD////////+
âœ… Aggregate 2972 sessioni uniche
ğŸ”„ Saltati 5942 messaggi di benvenuto (primi 2 per sessione)
ğŸ”„ Sessioni vuote (solo benvenuto): 1658
ğŸš¨ Sessioni corrotte scartate: 1
ğŸ“¥ [FASE 2: ESTRAZIONE] Sessioni grezze: 2972
ğŸ” [FASE 2: ESTRAZIONE] Filtraggio sessioni...
ğŸ” Filtraggio sessioni vuote/irrilevanti...
âœ… Filtro completato:
  ğŸ“Š Sessioni originali: 2972
  âŒ Sessioni scartate: 1659
  âœ… Sessioni valide: 1313
âœ… [FASE 2: ESTRAZIONE] Completata in 0.40s
ğŸ“Š [FASE 2: ESTRAZIONE] Dataset completo: 1313 sessioni
ğŸ—‘ï¸ [FASE 2: ESTRAZIONE] Filtrate: 1659 sessioni vuote/irrilevanti
ğŸ¯ [FASE 2: ESTRAZIONE] Pronte per clustering completo
âœ… Dataset completo: 1313 sessioni totali

ğŸ“Š FASE 2: CLUSTERING COMPLETO

ğŸš€ [FASE 4: CLUSTERING] Avvio clustering intelligente...
ğŸ“Š [FASE 4: CLUSTERING] Dataset: 1313 sessioni
ğŸ¯ [FASE 4: CLUSTERING] ModalitÃ : INTELLIGENTE
ğŸ§  [FASE 4: CLUSTERING] Clustering incrementale (se possibile)...

ğŸš€ [FASE 3: EMBEDDINGS] Avvio generazione embeddings...
ï¿½ [FASE 3: EMBEDDINGS] Dataset: 1313 sessioni
ğŸ“Š [FASE 3: EMBEDDINGS] Caratteristiche testo:
   ğŸ“ Lunghezza media: 694 caratteri
   ğŸ“ Lunghezza massima: 18923 caratteri
   ğŸ“ Lunghezza minima: 58 caratteri
ğŸ§  [FASE 3: EMBEDDINGS] Generazione embeddings...
ğŸ”„ LAZY LOADING: Caricamento embedder dinamico per tenant 'wopta'
ğŸ¯ SimpleEmbeddingManager inizializzato
ğŸ”„ SIMPLE MANAGER: Normalizzato 'wopta' -> '16c222a9-f293-11ef-9315-96000228e7fe'
ğŸ¯ SIMPLE MANAGER: Richiesta embedder per tenant 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ“¥ Primo embedder - creazione per tenant 16c222a9-f293-11ef-9315-96000228e7fe
ğŸš€ CREATING FRESH EMBEDDER per tenant 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ›ï¸ Configurazioni AI saranno salvate su DATABASE MySQL
ğŸ›ï¸ AIConfigurationService inizializzato
   ï¿½ Backend: DATABASE MySQL
   ğŸ”‘ OpenAI API Key: âœ… Configurata
ğŸ”„ DatabaseAI: ModalitÃ  legacy - risolvo tenant_id 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ”§ FORCE NO CACHE: Bypass cache per tenant 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ”¥ FORCE NO CACHE: Bypasso cache e leggo DIRETTAMENTE dal database per tenant 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ” [DEBUG] Query eseguita per tenant_id: 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ” [DEBUG] Risultato database: {'tenant_id': '16c222a9-f293-11ef-9315-96000228e7fe', 'tenant_name': 'Wopta', 'tenant_slug': 'wopta', 'embedding_engine': 'labse', 'llm_engine': 'gpt-oss:20b', 'embedding_config': None, 'llm_config': None, 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 29, 16, 40, 1)}
ğŸ” [DEBUG AIConfig] db_config ricevuto: {'tenant_id': '16c222a9-f293-11ef-9315-96000228e7fe', 'tenant_name': 'Wopta', 'tenant_slug': 'wopta', 'embedding_engine': 'labse', 'llm_engine': 'gpt-oss:20b', 'is_active': 1, 'updated_at': datetime.datetime(2025, 8, 29, 16, 40, 1), 'embedding_config': {}, 'llm_config': {}}
ğŸ” [DEBUG AIConfig] llm_engine nel db_config: gpt-oss:20b
ğŸ” SIMPLE MANAGER: Engine da DB per 16c222a9-f293-11ef-9315-96000228e7fe = 'labse'
ğŸ¯ Engine configurato: labse
ğŸ”§ DIRECT CREATE: labse
ğŸ³ Tentativo connessione a servizio LaBSE dockerizzato...
ğŸ”— LaBSE Remote Client inizializzato
   ğŸ“¡ Service URL: http://localhost:8081
   â±ï¸  Timeout: 300s
   ğŸ”„ Max retries: 3
   ğŸ›¡ï¸ Fallback locale: True
ğŸ”§ Inizializzazione client remoto LaBSE...
âœ… Servizio embedding online e funzionante
âœ… Client remoto LaBSE inizializzato con successo
âœ… LaBSE Remote Client configurato con successo
âœ… FRESH EMBEDDER creato: LaBSERemoteClient per tenant 16c222a9-f293-11ef-9315-96000228e7fe
âœ… Embedder caricato per tenant UUID 'wopta': LaBSERemoteClient
ğŸ“¡ Richiesta embedding remoto per 1313 testi...
âœ… Embedding remoto completato in 56.185s
   ğŸ“Š Shape: (1313, 768)
   âš¡ Tempo servizio: 54.735s
âœ… [FASE 3: EMBEDDINGS] Completata in 56.33s
ğŸ“ˆ [FASE 3: EMBEDDINGS] Shape: (1313, 768)
âš¡ [FASE 3: EMBEDDINGS] Throughput: 23.3 testi/secondo

ğŸ“Š FASE 2A: TRAINING BERTOPIC ANTICIPATO

ğŸš€ TRAINING BERTOPIC ANTICIPATO (NUOVO FLUSSO OTTIMIZZATO):
   ğŸ“Š Dataset completo: 1313 sessioni
   ğŸ“Š Embeddings shape: (1313, 768)
   ğŸ¯ Addestramento su TUTTO il dataset per features ottimali
   ğŸ”¥ Esecuzione bertopic_provider.fit() su dataset completo...
ğŸ“Š BERTopic training su 1313 campioni
   ğŸ¯ Embedder configurato: LaBSERemoteClient
   ğŸ”§ STRATEGIA: BERTopic userÃ  embedder personalizzato via wrapper
   âœ… Wrapper embedder creato per BERTopic
   ğŸ”§ BERTopic userÃ  embedder personalizzato interno
âœ… BERTopic FIT completato su 1313 campioni
   ğŸ”§ SVD Training: Usando embedder personalizzato interno
âœ… SVD addestrato su full probas (k=20)
   âœ… BERTopic FIT completato in 16.60 secondi
   ğŸ”„ Esecuzione bertopic_provider.transform() per features extraction...
ğŸ”§ Transform: BERTopic userÃ  embedder personalizzato interno
   âœ… BERTopic TRANSFORM completato in 1.07 secondi
   ğŸ“Š Topic probabilities shape: (1313, 20)
   ğŸ“Š One-hot shape: None
   âœ… BERTopic provider addestrato con successo su 1313 sessioni
   âœ… BERTopic provider disponibile per augmentation features
   ğŸ”— BERTopic model assegnato al trainer per validazione ALTRO

ğŸ“Š FASE 2B: CLUSTERING HDBSCAN
ğŸ§  Usando clustering INTELLIGENTE (LLM + ML senza pattern)
ğŸ—‚ï¸  [DEBUG] Caricamento config tenant-specific: /home/ubuntu/classificatore/tenant_configs/16c222a9-f293-11ef-9315-96000228e7fe_clustering.yaml
ğŸ—‚ï¸  [DEBUG] Config tenant caricato: ['allow_single_cluster', 'alpha', 'cluster_selection_epsilon', 'cluster_selection_method', 'max_cluster_size', 'metric', 'min_cluster_size', 'min_samples', 'only_user', 'umap_metric', 'umap_min_dist', 'umap_n_components', 'umap_n_neighbors', 'umap_random_state', 'use_umap']
ğŸ—‚ï¸  [DEBUG] UMAP config finale: use_umap=True, n_components=17, min_dist=0.1
ğŸ§  Clustering intelligente configurato:
   ğŸ¯ Categorie intent suggerite: 12
   ğŸ¤– LLM primario: True
   ğŸ“Š Min confidence: 0.8
   ğŸ“ˆ Min conversations per intent: 2
   ğŸ‘¥ Rappresentanti diversificati: True
   ğŸ”¢ Max rappresentanti per cluster: 5
   ğŸ¤ Strategia consenso: majority
ğŸ§  Avvio clustering intelligente OTTIMIZZATO di 1313 conversazioni...
ğŸ“Š Fase 1: Clustering semantico con HDBSCAN...
ğŸ”§ HDBSCANClusterer inizializzato:
   min_cluster_size: 5
   min_samples: 5
   metric: euclidean
   cluster_selection_epsilon: 0.2
   ğŸ—‚ï¸  UMAP enabled: True
     ğŸ“ n_neighbors: 30
     ğŸ“ min_dist: 0.1
     ğŸ“Š n_components: 17
     ğŸ¯ metric: cosine
   ğŸš€ GPU enabled: True
   ğŸ’¾ GPU memory limit: 80%
   ğŸ”„ CPU fallback: True
   âš ï¸  [GPU MODE] Limitazioni cuML HDBSCAN:
     ğŸš« leaf_size=40 sarÃ  IGNORATO su GPU
     âœ… Parametri supportati: cluster_selection_method, alpha, allow_single_cluster
ğŸ¯ [DEBUG REACT] Parametri configurati:
   cluster_selection_method: eom
   alpha: 1.0
   allow_single_cluster: False
ğŸ” Clustering HDBSCAN su 1313 embedding (7.7MB)...
âš™ï¸  Parametri: min_cluster_size=5, min_samples=5, metric=euclidean
ğŸ“Š [DEBUG FIT_PREDICT] Embedding input:
   ğŸ“ Shape: (1313, 768)
   ğŸ”¢ Dtype: float64
   ğŸ“ˆ Range: [-0.1215, 0.0898]
   ğŸ’¾ Memory: 7.7MB

ğŸ—‚ï¸  [DEBUG FIT_PREDICT] STEP 1: Controllo applicazione UMAP...
ğŸ” [DEBUG UMAP] Controllo condizioni applicazione UMAP...
   âœ… self.use_umap = True
   âœ… UMAP_AVAILABLE = True
ï¿½ [DEBUG UMAP] UMAP ABILITATO - Iniziando riduzione dimensionale...
   ğŸ“ Dimensioni input: (1313, 768)
   ğŸ”¢ Tipo dati input: float64
   ğŸ“Š Range valori input: [-0.1215, 0.0898]
   ğŸ¯ Parametri UMAP configurati:
     ğŸ“ n_neighbors: 30
     ğŸ“ min_dist: 0.1
     ğŸ”¢ n_components: 17
     ğŸ“ˆ metric: cosine
     ğŸ² random_state: 42
ğŸ”§ [DEBUG UMAP] Inizializzazione riduttore UMAP...
ğŸ†• [DEBUG UMAP] ModalitÃ  TRAINING - fit nuovo reducer
âœ… [DEBUG UMAP] Riduttore UMAP inizializzato con successo
â³ [DEBUG UMAP] Applicazione fit_transform agli embeddings...
UMAP(angular_rp_forest=True, metric='cosine', n_components=17, n_jobs=1, n_neighbors=30, random_state=42, verbose=True)
Fri Aug 29 21:55:10 2025 Construct fuzzy simplicial set
Fri Aug 29 21:55:12 2025 Finding Nearest Neighbors
Fri Aug 29 21:55:12 2025 Finished Nearest Neighbor Search
Fri Aug 29 21:55:12 2025 Construct embedding
	completed  0  /  500 epochs
	completed  50  /  500 epochs
	completed  100  /  500 epochs
	completed  150  /  500 epochs
	completed  200  /  500 epochs
	completed  250  /  500 epochs
	completed  300  /  500 epochs
	completed  350  /  500 epochs
	completed  400  /  500 epochs
	completed  450  /  500 epochs
Fri Aug 29 21:55:16 2025 Finished embedding
âœ… [DEBUG UMAP] UMAP COMPLETATO con SUCCESSO in 6.51s
   ğŸ“ Dimensioni output: (1313, 17)
   ï¿½ Tipo dati output: float32
   ï¿½ğŸ“Š Range valori output: [-15.2571, 15.9316]
   ğŸ“ˆ Riduzione dimensionale: 768 â†’ 17 dimensioni
   ğŸ“‰ Fattore riduzione: 45.2x
âœ… [DEBUG UMAP] RIDUZIONE DIMENSIONALE CONFERMATA
âœ… [DEBUG UMAP] Nessun NaN nel risultato UMAP
âœ… [DEBUG UMAP] Nessun valore infinito nel risultato UMAP
ğŸ“Š [DEBUG UMAP] DiversitÃ  embeddings ridotti: 1313/1313 righe uniche
âœ… [DEBUG UMAP] Buona diversitÃ  negli embeddings ridotti
ğŸ“‹ [DEBUG UMAP] Info riduzione salvate nel clusterer
ğŸ“‹ [DEBUG FIT_PREDICT] Risultato UMAP:
   âœ… UMAP applicato: True
   ğŸ“ Shape post-UMAP: (1313, 17)
   ğŸ“ˆ Range post-UMAP: [-15.2571, 15.9316]
   â±ï¸  Tempo riduzione: 6.51s

ğŸ”§ [DEBUG FIT_PREDICT] STEP 2: Normalizzazione per metrica euclidean...
   ğŸ¯ Nessuna normalizzazione necessaria per metrica euclidean
   ğŸ“ Shape finale per clustering: (1313, 17)
   ğŸ“ˆ Range finale: [-15.2571, 15.9316]
   ğŸ¯ Metrica effettiva clustering: euclidean
ğŸ’¾ Memoria GPU: 17.7GB disponibili, 0.0GB necessari
ğŸš€ Utilizzo GPU per clustering accelerato

ğŸš€ [DEBUG FIT_PREDICT] STEP 3: Avvio clustering...
   ğŸ–¥ï¸  ModalitÃ : GPU
ï¿½ [GPU CLUSTERING] Inizializzazione cuML HDBSCAN con parametri supportati...

âœ… [DEBUG FIT_PREDICT] CLUSTERING COMPLETATO in 0.11s con ğŸš€ GPU!
ğŸ“Š Risultati finali:
   ğŸ¯ Cluster trovati: 57
   ğŸ” Outlier: 253 (19.3%)
   ğŸ“ˆ Silhouette score: 0.649

ğŸ“‹ [DEBUG FIT_PREDICT] RIEPILOGO TRASFORMAZIONI:
   ğŸ”¤ Input originale: (1313, 768)
   ğŸ—‚ï¸  Dopo UMAP: (1313, 17)
   ğŸ”§ Dopo normalizzazione: (1313, 17)
   ğŸ¯ Utilizzato per clustering: (1313, 17) con metrica euclidean
   ğŸ“ˆ Cluster HDBSCAN trovati: 57
   ğŸ” Outliers: 253
ğŸ‘¥ Fase 2: Selezione rappresentanti per cluster...
   ï¿½ Cluster 0: 39 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 1: 22 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 2: 15 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 3: 68 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 4: 11 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 5: 17 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 6: 117 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 7: 36 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 8: 60 sessioni, 5 rappresentanti selezionati
   ï¿½ Cluster 9: 7 sessioni, 3 rappresentanti selezionati
   ï¿½ Cluster 10: 16 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 11: 15 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 12: 50 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 13: 35 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 14: 7 sessioni, 3 rappresentanti selezionati
   ï¿½ Cluster 15: 16 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 16: 15 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 17: 16 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 18: 10 sessioni, 3 rappresentanti selezionati
   ï¿½ Cluster 19: 6 sessioni, 3 rappresentanti selezionati
   ï¿½ Cluster 20: 6 sessioni, 3 rappresentanti selezionati
   ï¿½ Cluster 21: 13 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 22: 12 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 23: 5 sessioni, 3 rappresentanti selezionati
   ï¿½ Cluster 24: 41 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 25: 27 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 26: 18 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 27: 11 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 28: 10 sessioni, 3 rappresentanti selezionati
   ï¿½ Cluster 29: 9 sessioni, 3 rappresentanti selezionati
   ï¿½ Cluster 30: 8 sessioni, 3 rappresentanti selezionati
   ï¿½ Cluster 31: 20 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 32: 5 sessioni, 3 rappresentanti selezionati
   ï¿½ Cluster 33: 5 sessioni, 3 rappresentanti selezionati
   ï¿½ Cluster 34: 5 sessioni, 3 rappresentanti selezionati
   ï¿½ Cluster 35: 17 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 36: 24 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 37: 13 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 38: 17 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 39: 17 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 40: 10 sessioni, 3 rappresentanti selezionati
   ï¿½ Cluster 41: 8 sessioni, 3 rappresentanti selezionati
   ï¿½ Cluster 42: 6 sessioni, 3 rappresentanti selezionati
   ï¿½ Cluster 43: 12 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 44: 11 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 45: 17 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 46: 7 sessioni, 3 rappresentanti selezionati
   ï¿½ Cluster 47: 11 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 48: 8 sessioni, 3 rappresentanti selezionati
   ï¿½ Cluster 49: 24 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 50: 16 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 51: 11 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 52: 18 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 53: 16 sessioni, 4 rappresentanti selezionati
   ï¿½ Cluster 54: 7 sessioni, 3 rappresentanti selezionati
   ï¿½ Cluster 55: 9 sessioni, 3 rappresentanti selezionati
   ï¿½ Cluster 56: 8 sessioni, 3 rappresentanti selezionati
ğŸ¤– Fase 3: Analisi LLM di 211 rappresentanti...
ğŸ¤– Analisi LLM di 211 conversazioni...
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 26
   ğŸ“Š Token totali: 440
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 440 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 26
   ğŸ“Š Token conversazione finale: 26
   ğŸ“Š Token totali: 440
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 70 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2518 chars (debug_prompt=False)
ğŸ”§ Creazione MongoClassificationReader per cliente: 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ” Risoluzione tenant da UUID: 16c222a9-f293-11ef-9315-96000228e7fe
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
âœ… Tenant risolto (DB TAG locale): Wopta (wopta) UUID=16c222a9-f293-11ef-9315-96000228e7fe
âœ… Tenant risolto: Wopta (16c222a9-f293-11ef-9315-96000228e7fe)
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
âœ… MongoClassificationReader inizializzato per tenant: Wopta
   ğŸ“Š Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   ğŸ¢ Database: classificazioni
âœ… MongoClassificationReader creato per tenant: Wopta (wopta)
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
   ğŸ“Š Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
âœ… Connesso a MongoDB database: classificazioni
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
ğŸ” Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
ğŸ·ï¸ Recupero etichette per tenant: Wopta
ğŸ“Š Calcolo statistiche per tenant: Wopta
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 32
   ğŸ“Š Token totali: 446
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 446 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 32
   ğŸ“Š Token conversazione finale: 32
   ğŸ“Š Token totali: 446
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 85 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2533 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 48
   ğŸ“Š Token totali: 462
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 462 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 48
   ğŸ“Š Token conversazione finale: 48
   ğŸ“Š Token totali: 462
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 125 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2573 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 27
   ğŸ“Š Token totali: 441
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 441 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 27
   ğŸ“Š Token conversazione finale: 27
   ğŸ“Š Token totali: 441
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 75 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2523 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 70
   ğŸ“Š Token totali: 484
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 484 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 70
   ğŸ“Š Token conversazione finale: 70
   ğŸ“Š Token totali: 484
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 227 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2712 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 100
   ğŸ“Š Token totali: 514
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 514 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 100
   ğŸ“Š Token conversazione finale: 100
   ğŸ“Š Token totali: 514
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 335 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2729 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 398
   ğŸ“Š Token totali: 832
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 832 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 398
   ğŸ“Š Token conversazione finale: 398
   ğŸ“Š Token totali: 832
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1340 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2728 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 82
   ğŸ“Š Token totali: 496
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 496 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 82
   ğŸ“Š Token conversazione finale: 82
   ğŸ“Š Token totali: 496
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 264 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2749 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 46
   ğŸ“Š Token totali: 460
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 460 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 46
   ğŸ“Š Token conversazione finale: 46
   ğŸ“Š Token totali: 460
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 129 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2580 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 32
   ğŸ“Š Token totali: 446
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 446 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 32
   ğŸ“Š Token conversazione finale: 32
   ğŸ“Š Token totali: 446
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 99 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2569 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 44
   ğŸ“Š Token totali: 458
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 458 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 44
   ğŸ“Š Token conversazione finale: 44
   ğŸ“Š Token totali: 458
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 125 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2582 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 37
   ğŸ“Š Token totali: 451
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 451 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 37
   ğŸ“Š Token conversazione finale: 37
   ğŸ“Š Token totali: 451
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 102 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2569 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 25
   ğŸ“Š Token totali: 439
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 439 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 25
   ğŸ“Š Token conversazione finale: 25
   ğŸ“Š Token totali: 439
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 65 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2513 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 27
   ğŸ“Š Token totali: 441
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 441 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 27
   ğŸ“Š Token conversazione finale: 27
   ğŸ“Š Token totali: 441
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 79 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2537 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 31
   ğŸ“Š Token totali: 445
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 445 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 31
   ğŸ“Š Token conversazione finale: 31
   ğŸ“Š Token totali: 445
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 80 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2528 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 26
   ğŸ“Š Token totali: 440
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 440 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 26
   ğŸ“Š Token conversazione finale: 26
   ğŸ“Š Token totali: 440
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 69 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2517 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 26
   ğŸ“Š Token totali: 440
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 440 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 26
   ğŸ“Š Token conversazione finale: 26
   ğŸ“Š Token totali: 440
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 66 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2514 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 70
   ğŸ“Š Token totali: 484
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 484 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 70
   ğŸ“Š Token conversazione finale: 70
   ğŸ“Š Token totali: 484
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 227 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2712 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 438
   ğŸ’¬ Token conversazione: 121
   ğŸ“Š Token totali: 559
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 559 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 438
   ğŸ“Š Token conversazione originale: 121
   ğŸ“Š Token conversazione finale: 121
   ğŸ“Š Token totali: 559
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 354 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2715 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 62
   ğŸ“Š Token totali: 476
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 476 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 62
   ğŸ“Š Token conversazione finale: 62
   ğŸ“Š Token totali: 476
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 176 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2627 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 95
   ğŸ“Š Token totali: 509
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 509 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 95
   ğŸ“Š Token conversazione finale: 95
   ğŸ“Š Token totali: 509
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 279 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2730 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 22
   ğŸ“Š Token totali: 436
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 436 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 22
   ğŸ“Š Token conversazione finale: 22
   ğŸ“Š Token totali: 436
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 58 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2506 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 30
   ğŸ“Š Token totali: 444
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 444 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 30
   ğŸ“Š Token conversazione finale: 30
   ğŸ“Š Token totali: 444
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 95 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2582 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 25
   ğŸ“Š Token totali: 439
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 439 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 25
   ğŸ“Š Token conversazione finale: 25
   ğŸ“Š Token totali: 439
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 63 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2511 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 24
   ğŸ“Š Token totali: 438
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 438 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 24
   ğŸ“Š Token conversazione finale: 24
   ğŸ“Š Token totali: 438
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 62 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2510 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 174
   ğŸ“Š Token totali: 588
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 588 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 174
   ğŸ“Š Token conversazione finale: 174
   ğŸ“Š Token totali: 588
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 487 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2755 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 186
   ğŸ“Š Token totali: 620
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 620 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 186
   ğŸ“Š Token conversazione finale: 186
   ğŸ“Š Token totali: 620
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 611 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2857 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 121
   ğŸ“Š Token totali: 555
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 555 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 121
   ğŸ“Š Token conversazione finale: 121
   ğŸ“Š Token totali: 555
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 419 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2824 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 63
   ğŸ“Š Token totali: 477
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 477 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 63
   ğŸ“Š Token conversazione finale: 63
   ğŸ“Š Token totali: 477
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 204 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2715 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 57
   ğŸ“Š Token totali: 471
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 471 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 57
   ğŸ“Š Token conversazione finale: 57
   ğŸ“Š Token totali: 471
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 184 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2668 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 239
   ğŸ“Š Token totali: 673
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 673 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 239
   ğŸ“Š Token conversazione finale: 239
   ğŸ“Š Token totali: 673
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 797 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2822 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 117
   ğŸ“Š Token totali: 531
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 531 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 117
   ğŸ“Š Token conversazione finale: 117
   ğŸ“Š Token totali: 531
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 390 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2541 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 435
   ğŸ’¬ Token conversazione: 2443
   ğŸ“Š Token totali: 2878
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 2878 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 435
   ğŸ“Š Token conversazione originale: 2443
   ğŸ“Š Token conversazione finale: 2443
   ğŸ“Š Token totali: 2878
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 8422 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2800 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 438
   ğŸ’¬ Token conversazione: 102
   ğŸ“Š Token totali: 540
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 540 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 438
   ğŸ“Š Token conversazione originale: 102
   ğŸ“Š Token conversazione finale: 102
   ğŸ“Š Token totali: 540
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 316 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2823 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 27
   ğŸ“Š Token totali: 441
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 441 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 27
   ğŸ“Š Token conversazione finale: 27
   ğŸ“Š Token totali: 441
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 70 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2518 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 28
   ğŸ“Š Token totali: 442
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 442 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 28
   ğŸ“Š Token conversazione finale: 28
   ğŸ“Š Token totali: 442
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 71 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2519 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 27
   ğŸ“Š Token totali: 441
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 441 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 27
   ğŸ“Š Token conversazione finale: 27
   ğŸ“Š Token totali: 441
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 70 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2518 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 27
   ğŸ“Š Token totali: 441
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 441 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 27
   ğŸ“Š Token conversazione finale: 27
   ğŸ“Š Token totali: 441
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 70 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2518 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 27
   ğŸ“Š Token totali: 441
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 441 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 27
   ğŸ“Š Token conversazione finale: 27
   ğŸ“Š Token totali: 441
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 70 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2518 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 209
   ğŸ“Š Token totali: 623
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 623 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 209
   ğŸ“Š Token conversazione finale: 209
   ğŸ“Š Token totali: 623
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 697 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2690 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 581
   ğŸ“Š Token totali: 1015
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 1015 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 581
   ğŸ“Š Token conversazione finale: 581
   ğŸ“Š Token totali: 1015
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1870 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2800 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 435
   ğŸ’¬ Token conversazione: 604
   ğŸ“Š Token totali: 1039
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 1039 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 435
   ğŸ“Š Token conversazione originale: 604
   ğŸ“Š Token conversazione finale: 604
   ğŸ“Š Token totali: 1039
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 2028 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2777 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 435
   ğŸ’¬ Token conversazione: 493
   ğŸ“Š Token totali: 928
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 928 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 435
   ğŸ“Š Token conversazione originale: 493
   ğŸ“Š Token conversazione finale: 493
   ğŸ“Š Token totali: 928
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1607 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2696 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 149
   ğŸ“Š Token totali: 563
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 563 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 149
   ğŸ“Š Token conversazione finale: 149
   ğŸ“Š Token totali: 563
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 483 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2782 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 229
   ğŸ“Š Token totali: 663
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 663 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 229
   ğŸ“Š Token conversazione finale: 229
   ğŸ“Š Token totali: 663
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 719 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2855 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 460
   ğŸ“Š Token totali: 894
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 894 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 460
   ğŸ“Š Token conversazione finale: 460
   ğŸ“Š Token totali: 894
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1541 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2781 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 50
   ğŸ“Š Token totali: 464
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 464 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 50
   ğŸ“Š Token conversazione finale: 50
   ğŸ“Š Token totali: 464
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 127 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2575 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 29
   ğŸ“Š Token totali: 443
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 443 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 29
   ğŸ“Š Token conversazione finale: 29
   ğŸ“Š Token totali: 443
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 81 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2529 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 30
   ğŸ“Š Token totali: 444
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 444 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 30
   ğŸ“Š Token conversazione finale: 30
   ğŸ“Š Token totali: 444
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 76 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2524 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 28
   ğŸ“Š Token totali: 442
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 442 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 28
   ğŸ“Š Token conversazione finale: 28
   ğŸ“Š Token totali: 442
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 73 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2521 chars (debug_prompt=False)
   ğŸ“ˆ Progresso LLM: 50/211
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 252
   ğŸ“Š Token totali: 686
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 686 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 252
   ğŸ“Š Token conversazione finale: 252
   ğŸ“Š Token totali: 686
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 784 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2757 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 88
   ğŸ“Š Token totali: 502
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 502 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 88
   ğŸ“Š Token conversazione finale: 88
   ğŸ“Š Token totali: 502
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 248 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2638 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 440
   ğŸ’¬ Token conversazione: 2934
   ğŸ“Š Token totali: 3374
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 3374 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 440
   ğŸ“Š Token conversazione originale: 2934
   ğŸ“Š Token conversazione finale: 2934
   ğŸ“Š Token totali: 3374
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 10029 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2765 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 927
   ğŸ“Š Token totali: 1361
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 1361 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 927
   ğŸ“Š Token conversazione finale: 927
   ğŸ“Š Token totali: 1361
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 3131 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2819 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 86
   ğŸ“Š Token totali: 500
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 500 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 86
   ğŸ“Š Token conversazione finale: 86
   ğŸ“Š Token totali: 500
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 285 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2722 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 123
   ğŸ“Š Token totali: 537
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 537 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 123
   ğŸ“Š Token conversazione finale: 123
   ğŸ“Š Token totali: 537
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 417 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2624 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 114
   ğŸ“Š Token totali: 528
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 528 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 114
   ğŸ“Š Token conversazione finale: 114
   ğŸ“Š Token totali: 528
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 387 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2777 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 135
   ğŸ“Š Token totali: 549
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 549 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 135
   ğŸ“Š Token conversazione finale: 135
   ğŸ“Š Token totali: 549
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 417 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2752 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 3072
   ğŸ“Š Token totali: 3486
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 3486 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 3072
   ğŸ“Š Token conversazione finale: 3072
   ğŸ“Š Token totali: 3486
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 10047 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2758 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 272
   ğŸ“Š Token totali: 686
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 686 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 272
   ğŸ“Š Token conversazione finale: 272
   ğŸ“Š Token totali: 686
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 910 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2740 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 435
   ğŸ’¬ Token conversazione: 243
   ğŸ“Š Token totali: 678
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 678 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 435
   ğŸ“Š Token conversazione originale: 243
   ğŸ“Š Token conversazione finale: 243
   ğŸ“Š Token totali: 678
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 821 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2789 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 33
   ğŸ“Š Token totali: 447
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 447 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 33
   ğŸ“Š Token conversazione finale: 33
   ğŸ“Š Token totali: 447
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 93 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2545 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 438
   ğŸ’¬ Token conversazione: 49
   ğŸ“Š Token totali: 487
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 487 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 438
   ğŸ“Š Token conversazione originale: 49
   ğŸ“Š Token conversazione finale: 49
   ğŸ“Š Token totali: 487
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 155 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2694 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 49
   ğŸ“Š Token totali: 463
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 463 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 49
   ğŸ“Š Token conversazione finale: 49
   ğŸ“Š Token totali: 463
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 151 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2603 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 32
   ğŸ“Š Token totali: 446
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 446 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 32
   ğŸ“Š Token conversazione finale: 32
   ğŸ“Š Token totali: 446
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 95 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2547 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 242
   ğŸ“Š Token totali: 656
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 656 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 242
   ğŸ“Š Token conversazione finale: 242
   ğŸ“Š Token totali: 656
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 773 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2642 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 90
   ğŸ“Š Token totali: 524
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 524 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 90
   ğŸ“Š Token conversazione finale: 90
   ğŸ“Š Token totali: 524
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 290 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2847 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 77
   ğŸ“Š Token totali: 511
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 511 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 77
   ğŸ“Š Token conversazione finale: 77
   ğŸ“Š Token totali: 511
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 268 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2820 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 115
   ğŸ“Š Token totali: 529
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 529 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 115
   ğŸ“Š Token conversazione finale: 115
   ğŸ“Š Token totali: 529
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 386 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2626 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 74
   ğŸ“Š Token totali: 488
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 488 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 74
   ğŸ“Š Token conversazione finale: 74
   ğŸ“Š Token totali: 488
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 248 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2721 chars (debug_prompt=False)
ğŸ”§ Inizializzazione QualityGateEngine per cliente: sga (con lock)
âŒ ERRORE: identifier deve essere un UUID valido. Ricevuto: 'sga'
ğŸ’¡ SOLUZIONE: Il frontend deve inviare tenant_id (UUID), non nomi o slug
âŒ Errore risoluzione tenant UUID 'sga': âŒ ERRORE: identifier deve essere un UUID valido. Ricevuto: 'sga'
ğŸ’¡ Verifica che:
   1. Il tenant_id esista nel database TAG locale
   2. Il tenant sia attivo (is_active = 1)
   3. L'UUID sia nel formato corretto
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 148
   ğŸ“Š Token totali: 582
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 582 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 148
   ğŸ“Š Token conversazione finale: 148
   ğŸ“Š Token totali: 582
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 509 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2779 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 66
   ğŸ“Š Token totali: 480
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 480 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 66
   ğŸ“Š Token conversazione finale: 66
   ğŸ“Š Token totali: 480
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 225 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2700 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 72
   ğŸ“Š Token totali: 486
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 486 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 72
   ğŸ“Š Token conversazione finale: 72
   ğŸ“Š Token totali: 486
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 252 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2725 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 267
   ğŸ“Š Token totali: 681
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 681 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 267
   ğŸ“Š Token conversazione finale: 267
   ğŸ“Š Token totali: 681
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 894 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2755 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 435
   ğŸ’¬ Token conversazione: 162
   ğŸ“Š Token totali: 597
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 597 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 435
   ğŸ“Š Token conversazione originale: 162
   ğŸ“Š Token conversazione finale: 162
   ğŸ“Š Token totali: 597
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 582 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2851 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 323
   ğŸ“Š Token totali: 737
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 737 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 323
   ğŸ“Š Token conversazione finale: 323
   ğŸ“Š Token totali: 737
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1091 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2716 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 212
   ğŸ“Š Token totali: 646
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 646 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 212
   ğŸ“Š Token conversazione finale: 212
   ğŸ“Š Token totali: 646
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 675 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2705 chars (debug_prompt=False)
ğŸ”§ Creazione MongoClassificationReader per cliente: 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ” Risoluzione tenant da UUID: 16c222a9-f293-11ef-9315-96000228e7fe
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
âœ… Tenant risolto (DB TAG locale): Wopta (wopta) UUID=16c222a9-f293-11ef-9315-96000228e7fe
âœ… Tenant risolto: Wopta (16c222a9-f293-11ef-9315-96000228e7fe)
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
âœ… MongoClassificationReader inizializzato per tenant: Wopta
   ğŸ“Š Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   ğŸ¢ Database: classificazioni
âœ… MongoClassificationReader creato per tenant: Wopta (wopta)
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
   ğŸ“Š Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
âœ… Connesso a MongoDB database: classificazioni
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
ğŸ” Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
ğŸ·ï¸ Recupero etichette per tenant: Wopta
ğŸ“Š Calcolo statistiche per tenant: Wopta
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 559
   ğŸ“Š Token totali: 993
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 993 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 559
   ğŸ“Š Token conversazione finale: 559
   ğŸ“Š Token totali: 993
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1897 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2777 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 67
   ğŸ“Š Token totali: 481
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 481 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 67
   ğŸ“Š Token conversazione finale: 67
   ğŸ“Š Token totali: 481
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 215 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2700 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 438
   ğŸ“Š Token totali: 872
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 872 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 438
   ğŸ“Š Token conversazione finale: 438
   ğŸ“Š Token totali: 872
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1435 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2821 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 142
   ğŸ“Š Token totali: 556
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 556 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 142
   ğŸ“Š Token conversazione finale: 142
   ğŸ“Š Token totali: 556
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 407 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2709 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 1034
   ğŸ“Š Token totali: 1448
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 1448 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 1034
   ğŸ“Š Token conversazione finale: 1034
   ğŸ“Š Token totali: 1448
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 3426 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2785 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 166
   ğŸ“Š Token totali: 580
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 580 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 166
   ğŸ“Š Token conversazione finale: 166
   ğŸ“Š Token totali: 580
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 566 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2701 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 127
   ğŸ“Š Token totali: 541
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 541 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 127
   ğŸ“Š Token conversazione finale: 127
   ğŸ“Š Token totali: 541
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 421 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2746 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 229
   ğŸ“Š Token totali: 643
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 643 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 229
   ğŸ“Š Token conversazione finale: 229
   ğŸ“Š Token totali: 643
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 701 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2730 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 136
   ğŸ“Š Token totali: 550
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 550 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 136
   ğŸ“Š Token conversazione finale: 136
   ğŸ“Š Token totali: 550
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 426 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2596 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 435
   ğŸ’¬ Token conversazione: 2766
   ğŸ“Š Token totali: 3201
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 3201 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 435
   ğŸ“Š Token conversazione originale: 2766
   ğŸ“Š Token conversazione finale: 2766
   ğŸ“Š Token totali: 3201
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 8721 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2830 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 95
   ğŸ“Š Token totali: 529
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 529 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 95
   ğŸ“Š Token conversazione finale: 95
   ğŸ“Š Token totali: 529
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 305 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2883 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 227
   ğŸ“Š Token totali: 641
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 641 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 227
   ğŸ“Š Token conversazione finale: 227
   ğŸ“Š Token totali: 641
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 726 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2658 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 811
   ğŸ“Š Token totali: 1225
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 1225 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 811
   ğŸ“Š Token conversazione finale: 811
   ğŸ“Š Token totali: 1225
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 2653 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2516 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 613
   ğŸ“Š Token totali: 1047
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 1047 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 613
   ğŸ“Š Token conversazione finale: 613
   ğŸ“Š Token totali: 1047
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 2000 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2715 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 95
   ğŸ“Š Token totali: 529
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 529 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 95
   ğŸ“Š Token conversazione finale: 95
   ğŸ“Š Token totali: 529
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 335 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2759 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 435
   ğŸ’¬ Token conversazione: 119
   ğŸ“Š Token totali: 554
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 554 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 435
   ğŸ“Š Token conversazione originale: 119
   ğŸ“Š Token conversazione finale: 119
   ğŸ“Š Token totali: 554
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 419 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2878 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 56
   ğŸ“Š Token totali: 470
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 470 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 56
   ğŸ“Š Token conversazione finale: 56
   ğŸ“Š Token totali: 470
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 144 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2592 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 46
   ğŸ“Š Token totali: 480
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 480 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 46
   ğŸ“Š Token conversazione finale: 46
   ğŸ“Š Token totali: 480
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 140 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2670 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 52
   ğŸ“Š Token totali: 486
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 486 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 52
   ğŸ“Š Token conversazione finale: 52
   ğŸ“Š Token totali: 486
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 147 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2667 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 68
   ğŸ“Š Token totali: 482
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 482 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 68
   ğŸ“Š Token conversazione finale: 68
   ğŸ“Š Token totali: 482
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 203 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2639 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 52
   ğŸ“Š Token totali: 466
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 466 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 52
   ğŸ“Š Token conversazione finale: 52
   ğŸ“Š Token totali: 466
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 139 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2587 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 32
   ğŸ“Š Token totali: 446
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 446 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 32
   ğŸ“Š Token conversazione finale: 32
   ğŸ“Š Token totali: 446
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 89 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2576 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 49
   ğŸ“Š Token totali: 463
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 463 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 49
   ğŸ“Š Token conversazione finale: 49
   ğŸ“Š Token totali: 463
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 130 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2578 chars (debug_prompt=False)
   ğŸ“ˆ Progresso LLM: 100/211
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 48
   ğŸ“Š Token totali: 462
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 462 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 48
   ğŸ“Š Token conversazione finale: 48
   ğŸ“Š Token totali: 462
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 128 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2576 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 293
   ğŸ“Š Token totali: 707
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 707 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 293
   ğŸ“Š Token conversazione finale: 293
   ğŸ“Š Token totali: 707
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 930 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2798 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 146
   ğŸ“Š Token totali: 580
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 580 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 146
   ğŸ“Š Token conversazione finale: 146
   ğŸ“Š Token totali: 580
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 443 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2880 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 160
   ğŸ“Š Token totali: 574
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 574 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 160
   ğŸ“Š Token conversazione finale: 160
   ğŸ“Š Token totali: 574
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 518 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2653 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 438
   ğŸ’¬ Token conversazione: 2364
   ğŸ“Š Token totali: 2802
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 2802 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 438
   ğŸ“Š Token conversazione originale: 2364
   ğŸ“Š Token conversazione finale: 2364
   ğŸ“Š Token totali: 2802
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 7946 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2863 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 140
   ğŸ“Š Token totali: 554
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 554 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 140
   ğŸ“Š Token conversazione finale: 140
   ğŸ“Š Token totali: 554
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 431 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2695 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 182
   ğŸ“Š Token totali: 596
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 596 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 182
   ğŸ“Š Token conversazione finale: 182
   ğŸ“Š Token totali: 596
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 588 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2716 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 145
   ğŸ“Š Token totali: 559
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 559 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 145
   ğŸ“Š Token conversazione finale: 145
   ğŸ“Š Token totali: 559
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 432 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2688 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 334
   ğŸ“Š Token totali: 768
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 768 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 334
   ğŸ“Š Token conversazione finale: 334
   ğŸ“Š Token totali: 768
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 980 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2808 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 34
   ğŸ“Š Token totali: 448
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 448 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 34
   ğŸ“Š Token conversazione finale: 34
   ğŸ“Š Token totali: 448
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 98 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2550 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 47
   ğŸ“Š Token totali: 461
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 461 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 47
   ğŸ“Š Token conversazione finale: 47
   ğŸ“Š Token totali: 461
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 145 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2597 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 68
   ğŸ“Š Token totali: 482
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 482 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 68
   ğŸ“Š Token conversazione finale: 68
   ğŸ“Š Token totali: 482
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 201 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2653 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 40
   ğŸ“Š Token totali: 454
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 454 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 40
   ğŸ“Š Token conversazione finale: 40
   ğŸ“Š Token totali: 454
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 112 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2597 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 82
   ğŸ“Š Token totali: 496
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 496 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 82
   ğŸ“Š Token conversazione finale: 82
   ğŸ“Š Token totali: 496
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 252 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2737 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 48
   ğŸ“Š Token totali: 462
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 462 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 48
   ğŸ“Š Token conversazione finale: 48
   ğŸ“Š Token totali: 462
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 129 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2614 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 299
   ğŸ“Š Token totali: 733
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 733 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 299
   ğŸ“Š Token conversazione finale: 299
   ğŸ“Š Token totali: 733
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1016 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2660 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 104
   ğŸ“Š Token totali: 538
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 538 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 104
   ğŸ“Š Token conversazione finale: 104
   ğŸ“Š Token totali: 538
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 335 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2729 chars (debug_prompt=False)
ğŸ” [DEBUG] GET /api/tenants - Avvio richiesta tenant con oggetti Tenant
ğŸ” [DEBUG] Chiamo get_available_tenants() per oggetti Tenant...
ğŸ¢ Recuperati 22 oggetti Tenant dalla tabella TAG.tenants
ğŸ” [DEBUG] Recuperati 22 oggetti Tenant dal database
ğŸ” [DEBUG] Primi 3 tenant convertiti: [{'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'tenant_name': 'Alleanza', 'tenant_slug': 'alleanza', 'is_active': True}, {'tenant_id': '6bc4f06f-742e-11f0-acb8-96000228e7fe', 'tenant_name': 'BluPantheon', 'tenant_slug': 'blupantheon', 'is_active': True}, {'tenant_id': '0f9d6e90-d319-11ef-86a5-96000228e7fe', 'tenant_name': 'Boots', 'tenant_slug': 'boots', 'is_active': True}]
ğŸ” [DEBUG] Invio risposta con 22 tenant
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 373
   ğŸ“Š Token totali: 807
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 807 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 373
   ğŸ“Š Token conversazione finale: 373
   ğŸ“Š Token totali: 807
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1226 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2713 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 94
   ğŸ“Š Token totali: 508
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 508 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 94
   ğŸ“Š Token conversazione finale: 94
   ğŸ“Š Token totali: 508
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 292 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2737 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 78
   ğŸ“Š Token totali: 492
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 492 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 78
   ğŸ“Š Token conversazione finale: 78
   ğŸ“Š Token totali: 492
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 258 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2703 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 489
   ğŸ“Š Token totali: 903
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 903 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 489
   ğŸ“Š Token conversazione finale: 489
   ğŸ“Š Token totali: 903
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1588 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2788 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 218
   ğŸ“Š Token totali: 632
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 632 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 218
   ğŸ“Š Token conversazione finale: 218
   ğŸ“Š Token totali: 632
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 644 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2745 chars (debug_prompt=False)
ğŸ” [DEBUG] GET /api/tenants - Avvio richiesta tenant con oggetti Tenant
ğŸ” [DEBUG] Chiamo get_available_tenants() per oggetti Tenant...
ğŸ¢ Recuperati 22 oggetti Tenant dalla tabella TAG.tenants
ğŸ” [DEBUG] Recuperati 22 oggetti Tenant dal database
ğŸ” [DEBUG] Primi 3 tenant convertiti: [{'tenant_id': 'a0fd7600-f4f7-11ef-9315-96000228e7fe', 'tenant_name': 'Alleanza', 'tenant_slug': 'alleanza', 'is_active': True}, {'tenant_id': '6bc4f06f-742e-11f0-acb8-96000228e7fe', 'tenant_name': 'BluPantheon', 'tenant_slug': 'blupantheon', 'is_active': True}, {'tenant_id': '0f9d6e90-d319-11ef-86a5-96000228e7fe', 'tenant_name': 'Boots', 'tenant_slug': 'boots', 'is_active': True}]
ğŸ” [DEBUG] Invio risposta con 22 tenant
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 199
   ğŸ“Š Token totali: 613
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 613 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 199
   ğŸ“Š Token conversazione finale: 199
   ğŸ“Š Token totali: 613
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 614 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2698 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 435
   ğŸ’¬ Token conversazione: 339
   ğŸ“Š Token totali: 774
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 774 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 435
   ğŸ“Š Token conversazione originale: 339
   ğŸ“Š Token conversazione finale: 339
   ğŸ“Š Token totali: 774
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1101 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2827 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 273
   ğŸ“Š Token totali: 707
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 707 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 273
   ğŸ“Š Token conversazione finale: 273
   ğŸ“Š Token totali: 707
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 820 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2812 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 77
   ğŸ“Š Token totali: 491
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 491 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 77
   ğŸ“Š Token conversazione finale: 77
   ğŸ“Š Token totali: 491
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 199 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2647 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 53
   ğŸ“Š Token totali: 467
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 467 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 53
   ğŸ“Š Token conversazione finale: 53
   ğŸ“Š Token totali: 467
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 140 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2588 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 59
   ğŸ“Š Token totali: 473
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 473 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 59
   ğŸ“Š Token conversazione finale: 59
   ğŸ“Š Token totali: 473
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 157 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2605 chars (debug_prompt=False)
ğŸ”§ Inizializzazione QualityGateEngine per cliente: 16c222a9-f293-11ef-9315-96000228e7fe (con lock)
ğŸ” Risoluzione tenant da UUID: 16c222a9-f293-11ef-9315-96000228e7fe
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
âœ… Tenant risolto (DB TAG locale): Wopta (wopta) UUID=16c222a9-f293-11ef-9315-96000228e7fe
âœ… Tenant risolto: Wopta (16c222a9-f293-11ef-9315-96000228e7fe)
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
âœ… MongoClassificationReader inizializzato per tenant: Wopta
   ğŸ“Š Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   ğŸ¢ Database: classificazioni
âœ… Connesso a MongoDB database: classificazioni
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
âœ… MongoClassificationReader inizializzato per tenant: Wopta
   ğŸ“Š Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   ğŸ¢ Database: classificazioni
ğŸ”§ TokenizationManager inizializzato:
   ğŸ“Š Modello tokenizer: cl100k_base
   ğŸ”¢ Limite massimo token: 8000
   âœ‚ï¸  Strategia troncamento: start
âœ… TokenizationManager integrato in LaBSE per gestione conversazioni lunghe
ğŸš€ Inizializzazione LaBSE embedder su device: cuda
ğŸ“¥ Caricamento modello sentence-transformers/LaBSE...
ğŸš€ Caricamento diretto su GPU...
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 210
   ğŸ“Š Token totali: 644
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 644 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 210
   ğŸ“Š Token conversazione finale: 210
   ğŸ“Š Token totali: 644
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 598 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2857 chars (debug_prompt=False)
âœ… Modello caricato con successo!
ğŸ“Š Dimensione embedding: 768
ğŸ”§ Device: cuda
ğŸ® GPU: NVIDIA A10G
ğŸ’¾ GPU Memory: 23.7 GB
ğŸ“ˆ GPU Memory utilizzata: 3.88 GB
ï¿½ Primo parametro su device: cuda:0
ğŸ§ª Test del modello LaBSE...
ğŸ” Encoding 3 testi con LaBSE su device cuda...

ğŸ” TOKENIZZAZIONE PREVENTIVA LABSE CLUSTERING
============================================================
ğŸ” ELABORAZIONE CONVERSAZIONI PER CLUSTERING
   ğŸ“Š Numero conversazioni: 3
   ğŸ†” Session IDs forniti: No

ğŸ“Š STATISTICHE ELABORAZIONE:
   ğŸ”¢ Conversazioni totali: 3
   âœ‚ï¸  Conversazioni troncate: 0
   ğŸ“ Token originali totali: 20
   ğŸ“ Token finali totali: 20
   ğŸ“Š Range token: 6 - 7
âœ… Tokenizzazione LaBSE completata:
   ğŸ“Š Conversazioni processate: 3
   ğŸ“Š Conversazioni troncate: 0
   ğŸ“Š Token limite configurato: 8000
   âœ… Tutte le conversazioni entro i limiti, nessun troncamento
============================================================
âœ… Embedding generati: shape (3, 768)
âœ… Test modello completato con successo!
   Shape: (3, 768)
   Norme: [0.99999994 1.         1.        ]
   Device: cuda
ğŸ¯ Modello pronto per l'uso!
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
âœ… MongoClassificationReader inizializzato per tenant: Wopta
   ğŸ“Š Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   ğŸ¢ Database: classificazioni
ğŸ§  SemanticMemoryManager inizializzato
  ğŸ¯ Soglia riutilizzo etichette: 0.8
  ğŸ” Soglia similaritÃ  semantica: 0.8
  ğŸ’¾ Cache path: semantic_cache/wopta_16c222a9_memory
ğŸ”„ Caricamento memoria semantica dal database...
ğŸ”„ Caricamento memoria semantica da MongoDB...
âŒ Errore caricamento memoria semantica: MongoClassificationReader.get_all_sessions() got an unexpected keyword argument 'client_name'
ğŸ“­ Inizializzata memoria semantica vuota
âœ… QualityGateEngine 16c222a9-f293-11ef-9315-96000228e7fe inizializzato con soglie: confidence=0.9, disagreement=0.3
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 87
   ğŸ“Š Token totali: 501
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 501 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 87
   ğŸ“Š Token conversazione finale: 87
   ğŸ“Š Token totali: 501
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 243 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2725 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 177
   ğŸ“Š Token totali: 611
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 611 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 177
   ğŸ“Š Token conversazione finale: 177
   ğŸ“Š Token totali: 611
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 510 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2860 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 225
   ğŸ“Š Token totali: 639
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 639 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 225
   ğŸ“Š Token conversazione finale: 225
   ğŸ“Š Token totali: 639
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 755 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2762 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 139
   ğŸ“Š Token totali: 553
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 553 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 139
   ğŸ“Š Token conversazione finale: 139
   ğŸ“Š Token totali: 553
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 451 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2785 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 779
   ğŸ“Š Token totali: 1193
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 1193 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 779
   ğŸ“Š Token conversazione finale: 779
   ğŸ“Š Token totali: 1193
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 2550 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2570 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 514
   ğŸ“Š Token totali: 928
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 928 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 514
   ğŸ“Š Token conversazione finale: 514
   ğŸ“Š Token totali: 928
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1636 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2724 chars (debug_prompt=False)
ğŸ”§ Creazione MongoClassificationReader per cliente: 16c222a9-f293-11ef-9315-96000228e7fe
ğŸ” Risoluzione tenant da UUID: 16c222a9-f293-11ef-9315-96000228e7fe
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
âœ… Tenant risolto (DB TAG locale): Wopta (wopta) UUID=16c222a9-f293-11ef-9315-96000228e7fe
âœ… Tenant risolto: Wopta (16c222a9-f293-11ef-9315-96000228e7fe)
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
âœ… MongoClassificationReader inizializzato per tenant: Wopta
   ğŸ“Š Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
   ğŸ¢ Database: classificazioni
âœ… MongoClassificationReader creato per tenant: Wopta (wopta)
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
   ğŸ“Š Collection: wopta_16c222a9-f293-11ef-9315-96000228e7fe
âœ… Connesso a MongoDB database: classificazioni
ğŸ“Š Collection generata: wopta_16c222a9-f293-11ef-9315-96000228e7fe per tenant Wopta
ğŸ” Review Queue recuperate 0 sessioni (representatives: True, propagated: True, outliers: True)
ğŸ·ï¸ Recupero etichette per tenant: Wopta
ğŸ“Š Calcolo statistiche per tenant: Wopta
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 84
   ğŸ“Š Token totali: 518
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 518 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 84
   ğŸ“Š Token conversazione finale: 84
   ğŸ“Š Token totali: 518
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 276 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2800 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 435
   ğŸ’¬ Token conversazione: 1460
   ğŸ“Š Token totali: 1895
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 1895 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 435
   ğŸ“Š Token conversazione originale: 1460
   ğŸ“Š Token conversazione finale: 1460
   ğŸ“Š Token totali: 1895
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 4869 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2638 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 81
   ğŸ“Š Token totali: 515
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 515 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 81
   ğŸ“Š Token conversazione finale: 81
   ğŸ“Š Token totali: 515
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 252 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2764 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 99
   ğŸ“Š Token totali: 513
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 513 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 99
   ğŸ“Š Token conversazione finale: 99
   ğŸ“Š Token totali: 513
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 325 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2548 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 85
   ğŸ“Š Token totali: 499
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 499 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 85
   ğŸ“Š Token conversazione finale: 85
   ğŸ“Š Token totali: 499
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 214 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2671 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 65
   ğŸ“Š Token totali: 499
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 499 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 65
   ğŸ“Š Token conversazione finale: 65
   ğŸ“Š Token totali: 499
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 183 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2712 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 200
   ğŸ“Š Token totali: 614
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 614 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 200
   ğŸ“Š Token conversazione finale: 200
   ğŸ“Š Token totali: 614
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 551 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2646 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 433
   ğŸ’¬ Token conversazione: 81
   ğŸ“Š Token totali: 514
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 514 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 433
   ğŸ“Š Token conversazione originale: 81
   ğŸ“Š Token conversazione finale: 81
   ğŸ“Š Token totali: 514
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 216 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2737 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 28
   ğŸ“Š Token totali: 442
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 442 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 28
   ğŸ“Š Token conversazione finale: 28
   ğŸ“Š Token totali: 442
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 71 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2519 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 27
   ğŸ“Š Token totali: 441
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 441 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 27
   ğŸ“Š Token conversazione finale: 27
   ğŸ“Š Token totali: 441
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 66 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2514 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 29
   ğŸ“Š Token totali: 443
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 443 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 29
   ğŸ“Š Token conversazione finale: 29
   ğŸ“Š Token totali: 443
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 71 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2519 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 28
   ğŸ“Š Token totali: 442
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 442 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 28
   ğŸ“Š Token conversazione finale: 28
   ğŸ“Š Token totali: 442
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 73 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2521 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 225
   ğŸ“Š Token totali: 639
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 639 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 225
   ğŸ“Š Token conversazione finale: 225
   ğŸ“Š Token totali: 639
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 674 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2772 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 244
   ğŸ“Š Token totali: 658
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 658 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 244
   ğŸ“Š Token conversazione finale: 244
   ğŸ“Š Token totali: 658
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 804 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2785 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 135
   ğŸ“Š Token totali: 549
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 549 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 135
   ğŸ“Š Token conversazione finale: 135
   ğŸ“Š Token totali: 549
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 423 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2778 chars (debug_prompt=False)
   ğŸ“ˆ Progresso LLM: 150/211
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 312
   ğŸ“Š Token totali: 746
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 746 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 312
   ğŸ“Š Token conversazione finale: 312
   ğŸ“Š Token totali: 746
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 994 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2825 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 434
   ğŸ’¬ Token conversazione: 762
   ğŸ“Š Token totali: 1196
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 1196 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 434
   ğŸ“Š Token conversazione originale: 762
   ğŸ“Š Token conversazione finale: 762
   ğŸ“Š Token totali: 1196
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 2381 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2698 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 268
   ğŸ“Š Token totali: 682
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 682 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 268
   ğŸ“Š Token conversazione finale: 268
   ğŸ“Š Token totali: 682
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 848 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2758 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 248
   ğŸ“Š Token totali: 662
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 662 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 248
   ğŸ“Š Token conversazione finale: 248
   ğŸ“Š Token totali: 662
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 793 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2703 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 251
   ğŸ“Š Token totali: 665
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 665 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 251
   ğŸ“Š Token conversazione finale: 251
   ğŸ“Š Token totali: 665
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 822 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2778 chars (debug_prompt=False)
Connessione al database TAG stabilita con successo
Connessione al database TAG chiusa
ğŸ¤– System prompt caricato per tenant 16c222a9-f293-11ef-9315-96000228e7fe (debug_prompt=False)

ğŸ” TOKENIZZAZIONE PREVENTIVA LLM CLASSIFICATION
============================================================
ğŸ¤– ELABORAZIONE CONVERSAZIONE PER LLM
   ğŸ†” Session ID: llm_conversation
   ğŸ“ Token prompt: 414
   ğŸ’¬ Token conversazione: 414
   ğŸ“Š Token totali: 828
   ğŸ¯ Limite massimo: 8000
   âœ… Conversazione OK: 828 â‰¤ 8000
âœ… Tokenizzazione LLM completata:
   ğŸ“Š Token prompt base: 414
   ğŸ“Š Token conversazione originale: 414
   ğŸ“Š Token conversazione finale: 414
   ğŸ“Š Token totali: 828
   ğŸ“Š Limite configurato: 8000
   âœ… Conversazione entro i limiti, nessun troncamento
============================================================
ğŸ‘¤ User prompt generato per conversazione 1287 chars (debug_prompt=False)
ğŸš€ Prompt finale generato per LLM gpt-oss:20b - 2779 chars (debug_prompt=False)
