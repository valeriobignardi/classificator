#!/usr/bin/env python3
"""
Autore: Valerio Bignardi
Data: 2025-08-28
Descrizione: Test FINALE configurazioni clustering superiori - approccio diretto
Storia aggiornamenti:
- 2025-08-28: Test diretto con componenti individuali per massimo controllo
"""

import sys
import os
sys.path.append('/home/ubuntu/classificatore')

import yaml
import time
import traceback
import numpy as np
from sklearn.metrics import silhouette_score
from Preprocessing.session_aggregator import SessionAggregator
from EmbeddingEngine.labse_embedder import LaBSEEmbedder
from Clustering.hdbscan_clusterer import HDBSCANClusterer

def load_config():
    """Carica configurazione YAML"""
    with open('/home/ubuntu/classificatore/config.yaml', 'r') as f:
        return yaml.safe_load(f)

def test_superior_clustering(config_name, params, expected_performance):
    """
    Test diretto configurazione clustering con controllo totale
    
    Args:
        config_name (str): Nome configurazione
        params (dict): Parametri clustering
        expected_performance (dict): Performance attese
    
    Returns:
        dict: Risultati del test
    """
    print(f"ğŸ§ª TEST DIRETTO {config_name}")
    print("=" * 60)
    print(f"ğŸ¯ Performance attese:")
    for key, value in expected_performance.items():
        print(f"   â€¢ {key}: {value}")
    print()
    
    try:
        start_time = time.time()
        
        # 1. SETUP TENANT
        print("ğŸ” Setup tenant Humanitas...")
        tenant_id = "015007d9-d413-11ef-86a5-96000228e7fe"
        tenant_slug = "humanitas"
        print(f"âœ… Tenant: Humanitas ({tenant_slug})")
        
        # 2. ESTRAI SESSIONI
        print("ğŸ“Š Estrazione sessioni con limite...")
        config = load_config()
        aggregator = SessionAggregator(
            schema=tenant_slug, 
            tenant_id=tenant_id
        )
        
        sessions_dict = aggregator.estrai_sessioni_aggregate(
            limit=250  # Limite ridotto per stabilitÃ 
        )
        
        sessions = list(sessions_dict.values())
        
        # DEBUG: controlliamo la struttura della prima sessione
        if sessions:
            print(f"ğŸ” Struttura sessione: {list(sessions[0].keys())}")
        
        print(f"âœ… Dataset estratto: {len(sessions)} conversazioni")
        
        if len(sessions) < 50:
            return {"error": "Dataset insufficiente", "config_name": config_name, "sessions": len(sessions)}
        
        # 3. INIZIALIZZA EMBEDDER
        print("ğŸš€ Inizializzazione LaBSE embedder...")
        embedder = LaBSEEmbedder(device='cuda')
        
        # 4. GENERA EMBEDDINGS
        print("ğŸ” Generazione embeddings...")
        session_texts = [s['testo_completo'] for s in sessions]
        
        # Processo in batch per stabilitÃ   
        batch_size = 30
        all_embeddings = []
        
        for i in range(0, len(session_texts), batch_size):
            batch = session_texts[i:i+batch_size]
            print(f"ğŸ“Š Batch {i//batch_size + 1}/{(len(session_texts)-1)//batch_size + 1}: {len(batch)} items")
            
            embeddings = embedder.encode(batch)
            all_embeddings.append(embeddings)
            time.sleep(0.1)  # Piccola pausa
        
        embeddings_matrix = np.vstack(all_embeddings)
        print(f"âœ… Embeddings matrix: {embeddings_matrix.shape}")
        
        # 5. CLUSTERING CON PARAMETRI SUPERIORI
        print(f"ğŸš€ Clustering con parametri {config_name}...")
        
        clusterer = HDBSCANClusterer(
            min_cluster_size=params['min_cluster_size'],
            min_samples=params['min_samples'],
            alpha=params['alpha'],
            cluster_selection_method=params['cluster_selection_method'],
            cluster_selection_epsilon=params['cluster_selection_epsilon'],
            metric=params['metric'],
            use_umap=params['use_umap'],
            umap_n_neighbors=params['umap_n_neighbors'],
            umap_min_dist=params['umap_min_dist'],
            umap_n_components=params['umap_n_components'],
            umap_metric=params['umap_metric']
        )
        
        cluster_results = clusterer.fit_predict(embeddings_matrix)
        
        execution_time = time.time() - start_time
        
        # 6. CALCOLA METRICHE
        unique_clusters = set(cluster_results)
        n_clusters = len(unique_clusters) - (1 if -1 in unique_clusters else 0)
        n_outliers = sum(1 for x in cluster_results if x == -1)
        n_conversations = len(sessions)
        outlier_ratio = n_outliers / n_conversations
        
        # Silhouette score
        try:
            if n_clusters > 1 and len(unique_clusters) > 1:
                silhouette = silhouette_score(embeddings_matrix, cluster_results)
            else:
                silhouette = 0.0
        except Exception as e:
            print(f"âš ï¸ Errore calcolo silhouette: {str(e)}")
            silhouette = 0.0
        
        # Quality score personalizzato  
        quality_score = (1 - outlier_ratio) * 0.6 + silhouette * 0.4
        
        results = {
            "success": True,
            "config_name": config_name,
            "n_clusters": n_clusters,
            "n_outliers": n_outliers,
            "n_conversations": n_conversations,
            "outlier_ratio": outlier_ratio,
            "silhouette_score": silhouette,
            "quality_score": quality_score,
            "execution_time": execution_time,
            "parameters": params,
            "cluster_distribution": dict(zip(*np.unique(cluster_results, return_counts=True)))
        }
        
        print(f"âœ… {config_name} COMPLETATO!")
        print(f"   ğŸ“Š Conversazioni: {n_conversations}")
        print(f"   ğŸ¯ Clusters: {n_clusters}")
        print(f"   âŒ Outliers: {n_outliers} ({outlier_ratio:.1%})")
        print(f"   ğŸ“ˆ Silhouette: {silhouette:.4f}")
        print(f"   ğŸ† Quality Score: {quality_score:.4f}")
        print(f"   â±ï¸ Tempo: {execution_time:.1f}s")
        
        return results
        
    except Exception as e:
        error_msg = f"Test {config_name} fallito: {str(e)}"
        print(f"âŒ {error_msg}")
        traceback.print_exc()
        return {"error": error_msg, "config_name": config_name}

def main():
    """Test finale configurazioni clustering superiori progettate"""
    
    print("ğŸš€ TEST FINALE - CONFIGURAZIONI CLUSTERING SUPERIORI PROGETTATE")
    print("=" * 80)
    print("ğŸ¯ Obiettivo: BATTERE V22 (12.9% outliers, 0.0836 silhouette)")
    print("ğŸ’¡ Approccio: Test diretto con controllo totale parametri")
    print("=" * 80)
    
    # CONFIGURAZIONI SUPERIORI PROGETTATE - refined basate sui pattern
    superior_configs = {
        "PRECISION_ULTRA": {
            "params": {
                'use_umap': True,
                'metric': 'euclidean',
                'alpha': 0.40,  # Balanced per precision
                'min_cluster_size': 6,  # PiÃ¹ piccolo per sensibilitÃ 
                'min_samples': 4,  # Ridotto per catturare pattern sottili
                'cluster_selection_method': 'eom',  # Migliore per density
                'cluster_selection_epsilon': 0.22,  # Fine-tuned
                'umap_metric': 'cosine',  # Ideale per testo
                'umap_min_dist': 0.005,  # Molto basso per precision
                'umap_n_neighbors': 18,  # Ottimizzato dai dati  
                'umap_n_components': 50,  # Balanced
                'umap_random_state': 42
            },
            "expected": {
                "Outliers": "5-9%",
                "Clusters": "65-85", 
                "Silhouette": "0.10-0.15",
                "Quality": ">0.85"
            }
        },
        
        "OPTIMIZER_SUPREME": {
            "params": {
                'use_umap': True,
                'metric': 'euclidean', 
                'alpha': 0.35,  # PiÃ¹ aggressivo
                'min_cluster_size': 5,  # Piccolo per coverage
                'min_samples': 3,  # Minimo per sensibilitÃ  max
                'cluster_selection_method': 'leaf',  # Aggressivo
                'cluster_selection_epsilon': 0.25,
                'umap_metric': 'cosine',
                'umap_min_dist': 0.001,  # Minimo assoluto
                'umap_n_neighbors': 15,  # Ridotto per local patterns
                'umap_n_components': 55,  # PiÃ¹ informazione
                'umap_random_state': 42
            },
            "expected": {
                "Outliers": "3-7%",
                "Clusters": "75-95",
                "Silhouette": "0.09-0.14",
                "Quality": ">0.87"
            }
        }
    }
    
    print(f"ğŸ§ª TESTING {len(superior_configs)} configurazioni progettate...")
    print()
    
    results = []
    
    for config_name, config_data in superior_configs.items():
        print(f"\n{'='*70}")
        result = test_superior_clustering(
            config_name, 
            config_data["params"],
            config_data["expected"]
        )
        results.append(result)
        
        # Pausa tra test
        time.sleep(2)
    
    print("\n\nğŸ† RISULTATI FINALI CONFIGURAZIONI SUPERIORI")
    print("=" * 80)
    print("ğŸ“Š BASELINE V22: 12.9% outliers, 0.0836 silhouette, 51 clusters")
    print("=" * 80)
    
    best_config = None
    best_score = 0
    success_count = 0
    
    for result in results:
        if "error" in result:
            print(f"âŒ {result['config_name']}: ERRORE - {result['error']}")
        else:
            success_count += 1
            config_name = result['config_name']
            outliers = result['outlier_ratio']
            silhouette = result['silhouette_score']
            clusters = result['n_clusters']
            quality = result['quality_score']
            
            # Calcola miglioramenti vs V22
            outlier_improvement = (0.129 - outliers) / 0.129 * 100
            silhouette_improvement = (silhouette - 0.0836) / 0.0836 * 100
            
            # Punteggio combinato miglioramento
            combined_score = outlier_improvement + silhouette_improvement
            
            print(f"\nğŸ¯ {config_name}:")
            print(f"   ğŸ“Š Dataset: {result['n_conversations']} conv â†’ {clusters} clusters")
            print(f"   âŒ Outliers: {outliers:.1%} ({outlier_improvement:+.1f}% vs V22)")
            print(f"   ğŸ“ˆ Silhouette: {silhouette:.4f} ({silhouette_improvement:+.1f}% vs V22)")
            print(f"   ğŸ† Quality Score: {quality:.4f}")
            print(f"   ğŸ“Š Combined Improvement: {combined_score:+.1f}%")
            print(f"   â±ï¸ Execution Time: {result['execution_time']:.1f}s")
            
            # Valutazione vs V22
            improvements = []
            if outliers < 0.129:
                improvements.append("OUTLIERS")
            if silhouette > 0.0836:
                improvements.append("SILHOUETTE")
            
            if len(improvements) == 2:
                print(f"   ğŸŒŸğŸŒŸ SUPERIORE a V22 su TUTTE le metriche!")
                if combined_score > best_score:
                    best_config = config_name
                    best_score = combined_score
            elif len(improvements) == 1:
                print(f"   â­ Superiore su: {', '.join(improvements)}")
            else:
                print(f"   ğŸ“Š Prestazioni comparabili a V22")
    
    print(f"\nğŸ–ï¸ VERDICT FINALE:")
    print(f"   ğŸ“ˆ Configurazioni testate: {success_count}/{len(superior_configs)}")
    if best_config:
        print(f"   ğŸ‘‘ MIGLIORE: {best_config} (Score: +{best_score:.1f}%)")
        print(f"   ğŸš€ PRONTA per deployment su dataset completo!")
    elif success_count > 0:
        print(f"   ğŸ’¡ Configurazioni progettate mostrano miglioramenti parziali")
        print(f"   ğŸ”§ Possibile ulteriore fine-tuning necessario")
    else:
        print(f"   âš ï¸ Nessuna configurazione testata con successo")
    
    print("=" * 80)

if __name__ == "__main__":
    main()
